{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":262932592,"sourceType":"kernelVersion"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Conversion to the onnx","metadata":{}},{"cell_type":"code","source":"!pip install rfdetr -q\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T18:50:50.341655Z","iopub.execute_input":"2025-09-24T18:50:50.341893Z","iopub.status.idle":"2025-09-24T18:50:53.946805Z","shell.execute_reply.started":"2025-09-24T18:50:50.341864Z","shell.execute_reply":"2025-09-24T18:50:53.946032Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install rfdetr[onnxexport] -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T18:43:11.806619Z","iopub.execute_input":"2025-09-24T18:43:11.806888Z","iopub.status.idle":"2025-09-24T18:44:55.281408Z","shell.execute_reply.started":"2025-09-24T18:43:11.806860Z","shell.execute_reply":"2025-09-24T18:44:55.280514Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.8/372.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.7/220.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m855.6/855.6 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 6.32.1 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.32.1 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.1 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.1 which is incompatible.\nlangchain-core 0.3.66 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from rfdetr import RFDETRMedium","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T18:50:58.936149Z","iopub.execute_input":"2025-09-24T18:50:58.936406Z","iopub.status.idle":"2025-09-24T18:51:24.675675Z","shell.execute_reply.started":"2025-09-24T18:50:58.936381Z","shell.execute_reply":"2025-09-24T18:51:24.675157Z"}},"outputs":[{"name":"stderr","text":"2025-09-24 18:51:11.448082: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758739871.640525      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758739871.694001      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"%%writefile export.py\nfrom rfdetr import RFDETRMedium\nmodel = RFDETRMedium(pretrain_weights='/kaggle/input/rf_detr_medium_training/checkpoint_best_total.pth') #load your model path\n\n\nmodel.export()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T18:57:43.717745Z","iopub.execute_input":"2025-09-24T18:57:43.718064Z","iopub.status.idle":"2025-09-24T18:57:43.723376Z","shell.execute_reply.started":"2025-09-24T18:57:43.718040Z","shell.execute_reply":"2025-09-24T18:57:43.722571Z"}},"outputs":[{"name":"stdout","text":"Writing export.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!python /kaggle/working/export.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T18:58:08.665991Z","iopub.execute_input":"2025-09-24T18:58:08.666249Z","iopub.status.idle":"2025-09-24T18:58:27.592582Z","shell.execute_reply.started":"2025-09-24T18:58:08.666231Z","shell.execute_reply":"2025-09-24T18:58:27.591642Z"}},"outputs":[{"name":"stdout","text":"2025-09-24 18:58:14.484257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758740294.506217     167 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758740294.512865     167 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nUsing a different number of positional encodings than DINOv2, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\nUsing patch size 16 instead of 14, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\nLoading pretrain weights\nExporting model to ONNX format\nUserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\nPyTorch inference output shapes - Boxes: torch.Size([1, 3900, 4]), Labels: torch.Size([1, 3900, 13])\nTracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\nTracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\nTracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\nTracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\nTracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\nTracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\nTracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\nTracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\nTracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\nTracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\nTracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\nTracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\nTracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\nTracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\nTracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\nExported graph: graph(%input : Float(1, 3, 576, 576, strides=[995328, 331776, 576, 1], requires_grad=0, device=cpu),\n      %transformer.decoder.layers.0.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.0.self_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.0.norm1.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.0.norm1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.0.cross_attn.sampling_offsets.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.0.cross_attn.attention_weights.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.0.cross_attn.value_proj.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.0.cross_attn.output_proj.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.0.linear1.bias : Float(2048, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.0.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.0.norm2.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.0.norm2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.0.norm3.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.0.norm3.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.1.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.1.self_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.1.norm1.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.1.norm1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.1.cross_attn.sampling_offsets.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.1.cross_attn.attention_weights.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.1.cross_attn.value_proj.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.1.cross_attn.output_proj.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.1.linear1.bias : Float(2048, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.1.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.1.norm2.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.1.norm2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.1.norm3.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.1.norm3.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.2.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.2.self_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.2.norm1.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.2.norm1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.2.cross_attn.sampling_offsets.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.2.cross_attn.attention_weights.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.2.cross_attn.value_proj.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.2.cross_attn.output_proj.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.2.linear1.bias : Float(2048, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.2.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.2.norm2.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.2.norm2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.2.norm3.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.2.norm3.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.3.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.3.self_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.3.norm1.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.3.norm1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.3.cross_attn.sampling_offsets.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.3.cross_attn.attention_weights.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.3.cross_attn.value_proj.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.3.cross_attn.output_proj.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.3.linear1.bias : Float(2048, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.3.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.3.norm2.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.3.norm2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.3.norm3.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.layers.3.norm3.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.norm.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.norm.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.ref_point_head.layers.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.decoder.ref_point_head.layers.1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.enc_output.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.enc_output_norm.0.weight : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.enc_output_norm.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.enc_out_bbox_embed.0.layers.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.enc_out_bbox_embed.0.layers.1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %transformer.enc_out_bbox_embed.0.layers.2.bias : Float(4, strides=[1], requires_grad=1, device=cpu),\n      %transformer.enc_out_class_embed.0.bias : Float(13, strides=[1], requires_grad=1, device=cpu),\n      %bbox_embed.layers.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %bbox_embed.layers.1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n      %bbox_embed.layers.2.bias : Float(4, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.embeddings.cls_token : Float(1, 1, 384, strides=[384, 384, 1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.embeddings.position_embeddings : Float(1, 1297, 384, strides=[498048, 384, 1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.embeddings.patch_embeddings.projection.weight : Float(384, 3, 16, 16, strides=[768, 256, 16, 1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.embeddings.patch_embeddings.projection.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.0.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.0.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.0.attention.attention.query.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.0.attention.attention.key.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.0.attention.attention.value.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.0.attention.output.dense.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.0.layer_scale1.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.0.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.0.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.0.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.0.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.0.layer_scale2.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.1.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.1.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.1.attention.attention.query.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.1.attention.attention.key.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.1.attention.attention.value.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.1.attention.output.dense.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.1.layer_scale1.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.1.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.1.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.1.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.1.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.1.layer_scale2.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.2.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.2.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.2.attention.attention.query.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.2.attention.attention.key.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.2.attention.attention.value.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.2.attention.output.dense.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.2.layer_scale1.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.2.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.2.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.2.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.2.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.2.layer_scale2.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.3.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.3.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.3.attention.attention.query.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.3.attention.attention.key.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.3.attention.attention.value.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.3.attention.output.dense.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.3.layer_scale1.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.3.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.3.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.3.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.3.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.3.layer_scale2.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.4.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.4.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.4.attention.attention.query.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.4.attention.attention.key.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.4.attention.attention.value.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.4.attention.output.dense.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.4.layer_scale1.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.4.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.4.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.4.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.4.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.4.layer_scale2.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.5.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.5.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.5.attention.attention.query.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.5.attention.attention.key.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.5.attention.attention.value.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.5.attention.output.dense.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.5.layer_scale1.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.5.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.5.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.5.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.5.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.5.layer_scale2.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.6.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.6.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.6.attention.attention.query.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.6.attention.attention.key.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.6.attention.attention.value.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.6.attention.output.dense.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.6.layer_scale1.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.6.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.6.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.6.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.6.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.6.layer_scale2.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.7.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.7.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.7.attention.attention.query.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.7.attention.attention.key.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.7.attention.attention.value.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.7.attention.output.dense.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.7.layer_scale1.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.7.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.7.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.7.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.7.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.7.layer_scale2.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.8.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.8.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.8.attention.attention.query.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.8.attention.attention.key.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.8.attention.attention.value.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.8.attention.output.dense.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.8.layer_scale1.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.8.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.8.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.8.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.8.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.8.layer_scale2.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.9.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.9.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.9.attention.attention.query.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.9.attention.attention.key.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.9.attention.attention.value.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.9.attention.output.dense.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.9.layer_scale1.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.9.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.9.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.9.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.9.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.9.layer_scale2.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.10.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.10.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.10.attention.attention.query.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.10.attention.attention.key.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.10.attention.attention.value.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.10.attention.output.dense.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.10.layer_scale1.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.10.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.10.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.10.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.10.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.10.layer_scale2.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.11.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.11.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.11.attention.attention.query.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.11.attention.attention.key.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.11.attention.attention.value.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.11.attention.output.dense.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.11.layer_scale1.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.11.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.11.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.11.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.11.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.encoder.layer.11.layer_scale2.lambda1 : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.layernorm.weight : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.encoder.encoder.layernorm.bias : Float(384, strides=[1], requires_grad=1, device=cpu),\n      %backbone.0.projector.stages.0.0.cv1.conv.weight : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cpu),\n      %backbone.0.projector.stages.0.0.cv2.conv.weight : Float(256, 640, 1, 1, strides=[640, 1, 1, 1], requires_grad=1, device=cpu),\n      %backbone.0.projector.stages.0.0.m.0.cv1.conv.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n      %backbone.0.projector.stages.0.0.m.0.cv2.conv.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n      %backbone.0.projector.stages.0.0.m.1.cv1.conv.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n      %backbone.0.projector.stages.0.0.m.1.cv2.conv.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n      %backbone.0.projector.stages.0.0.m.2.cv1.conv.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n      %backbone.0.projector.stages.0.0.m.2.cv2.conv.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n      %class_embed.bias : Float(13, strides=[1], requires_grad=1, device=cpu),\n      %onnx::MatMul_4289 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4290 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4296 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4311 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4312 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4313 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cpu),\n      %onnx::MatMul_4314 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4315 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4321 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4336 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4337 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4338 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cpu),\n      %onnx::MatMul_4339 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4340 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4346 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4361 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4362 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4363 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cpu),\n      %onnx::MatMul_4368 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4369 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4375 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4390 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4395 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4396 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cpu),\n      %onnx::MatMul_4397 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4398 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4404 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4419 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4420 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4421 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cpu),\n      %onnx::MatMul_4422 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4423 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4429 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4444 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4445 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4446 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cpu),\n      %onnx::MatMul_4451 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4452 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4458 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4473 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4478 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4479 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cpu),\n      %onnx::MatMul_4480 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4481 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4487 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4502 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4503 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4504 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cpu),\n      %onnx::MatMul_4505 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4506 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4512 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4527 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4528 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4529 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cpu),\n      %onnx::MatMul_4534 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4535 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4541 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4556 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4561 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4562 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cpu),\n      %onnx::MatMul_4563 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4564 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4570 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4585 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4586 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4587 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cpu),\n      %onnx::MatMul_4588 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4589 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4595 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4610 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4611 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cpu),\n      %onnx::MatMul_4612 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cpu),\n      %onnx::Mul_4694 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Add_4696 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Mul_4698 : Float(128, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Add_4700 : Float(128, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Mul_4702 : Float(128, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Add_4704 : Float(128, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Mul_4706 : Float(128, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Add_4708 : Float(128, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Mul_4710 : Float(128, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Add_4712 : Float(128, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Mul_4714 : Float(128, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Add_4716 : Float(128, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Mul_4718 : Float(128, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Add_4720 : Float(128, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Mul_4722 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Add_4724 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Mul_4726 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::Add_4728 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n      %onnx::MatMul_4757 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4758 : Float(256, 13, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4759 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4760 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4761 : Float(256, 4, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::Expand_4780 : Float(1, 300, 256, strides=[76800, 256, 1], requires_grad=0, device=cpu),\n      %onnx::Expand_4798 : Float(1, 300, 4, strides=[1200, 4, 1], requires_grad=0, device=cpu),\n      %onnx::MatMul_4858 : Float(512, 256, strides=[1, 512], requires_grad=0, device=cpu),\n      %onnx::MatMul_4859 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::Add_4875 : Float(256, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Add_4877 : Float(256, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Add_4879 : Float(256, strides=[1], requires_grad=0, device=cpu),\n      %onnx::MatMul_4880 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4881 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4882 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4887 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4888 : Float(256, 64, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4894 : Float(256, 32, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4929 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4930 : Float(256, 2048, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4931 : Float(2048, 256, strides=[1, 2048], requires_grad=0, device=cpu),\n      %onnx::Add_4947 : Float(256, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Add_4949 : Float(256, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Add_4951 : Float(256, strides=[1], requires_grad=0, device=cpu),\n      %onnx::MatMul_4952 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4953 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4954 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4958 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4959 : Float(256, 64, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4965 : Float(256, 32, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4972 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4973 : Float(256, 2048, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4974 : Float(2048, 256, strides=[1, 2048], requires_grad=0, device=cpu),\n      %onnx::Add_4990 : Float(256, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Add_4992 : Float(256, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Add_4994 : Float(256, strides=[1], requires_grad=0, device=cpu),\n      %onnx::MatMul_4995 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4996 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_4997 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5001 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5002 : Float(256, 64, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5008 : Float(256, 32, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5015 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5016 : Float(256, 2048, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5017 : Float(2048, 256, strides=[1, 2048], requires_grad=0, device=cpu),\n      %onnx::Add_5033 : Float(256, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Add_5035 : Float(256, strides=[1], requires_grad=0, device=cpu),\n      %onnx::Add_5037 : Float(256, strides=[1], requires_grad=0, device=cpu),\n      %onnx::MatMul_5038 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5039 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5040 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5044 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5045 : Float(256, 64, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5051 : Float(256, 32, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5058 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5059 : Float(256, 2048, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5060 : Float(2048, 256, strides=[1, 2048], requires_grad=0, device=cpu),\n      %onnx::MatMul_5061 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5062 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5063 : Float(256, 4, strides=[1, 256], requires_grad=0, device=cpu),\n      %onnx::MatMul_5080 : Float(256, 13, strides=[1, 256], requires_grad=0, device=cpu)):\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings\n  %/backbone/backbone.0/encoder/encoder/embeddings/Cast_output_0 : Float(1, 3, 576, 576, strides=[995328, 331776, 576, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Cast\"](%input), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:291:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/projection/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/projection/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersPatchEmbeddings::patch_embeddings/torch.nn.modules.conv.Conv2d::projection\n  %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/projection/Conv_output_0 : Float(1, 384, 36, 36, strides=[497664, 1296, 36, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[16, 16], pads=[0, 0, 0, 0], strides=[16, 16], onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/projection/Conv\"](%/backbone/backbone.0/encoder/encoder/embeddings/Cast_output_0, %backbone.0.encoder.encoder.embeddings.patch_embeddings.projection.weight, %backbone.0.encoder.encoder.embeddings.patch_embeddings.projection.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersPatchEmbeddings::patch_embeddings/torch.nn.modules.conv.Conv2d::projection # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:549:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Shape\"](%/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/projection/Conv_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersPatchEmbeddings::patch_embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:212:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersPatchEmbeddings::patch_embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:212:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Constant_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersPatchEmbeddings::patch_embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:212:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersPatchEmbeddings::patch_embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:212:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Slice_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Slice\"](%/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Shape_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Constant_1_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Constant_2_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersPatchEmbeddings::patch_embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:212:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersPatchEmbeddings::patch_embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:212:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Concat\"](%/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Slice_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Constant_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersPatchEmbeddings::patch_embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:212:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Reshape_output_0 : Float(1, 384, 1296, strides=[497664, 1296, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Reshape\"](%/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/projection/Conv_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Concat_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersPatchEmbeddings::patch_embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:212:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Transpose_output_0 : Float(1, 1296, 384, strides=[497664, 1, 1296], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Transpose\"](%/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersPatchEmbeddings::patch_embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:212:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_3_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1 -1 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:299:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:299:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/ConstantOfShape_output_0 : Long(3, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/ConstantOfShape\"](%/backbone/backbone.0/encoder/encoder/embeddings/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:299:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:299:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Mul_output_0 : Long(3, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Mul\"](%/backbone/backbone.0/encoder/encoder/embeddings/ConstantOfShape_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:299:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Equal_output_0 : Bool(3, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Equal\"](%/backbone/backbone.0/encoder/encoder/embeddings/Constant_3_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Mul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:299:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Where_output_0 : Long(3, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Where\"](%/backbone/backbone.0/encoder/encoder/embeddings/Equal_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/ConstantOfShape_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:299:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Expand_output_0 : Float(1, 1, 384, strides=[384, 384, 1], requires_grad=1, device=cpu) = onnx::Expand[onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Expand\"](%backbone.0.encoder.encoder.embeddings.cls_token, %/backbone/backbone.0/encoder/encoder/embeddings/Where_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:299:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Concat_output_0 : Float(1, 1297, 384, strides=[498048, 384, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Concat\"](%/backbone/backbone.0/encoder/encoder/embeddings/Expand_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:300:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Add_output_0 : Float(1, 1297, 384, strides=[498048, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Add\"](%/backbone/backbone.0/encoder/encoder/embeddings/Concat_output_0, %backbone.0.encoder.encoder.embeddings.position_embeddings), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:303:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:309:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_7\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:309:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_8\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:309:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_9\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:309:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Slice_output_0 : Float(1, 1, 384, strides=[498048, 384, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Slice\"](%/backbone/backbone.0/encoder/encoder/embeddings/Add_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_7_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_8_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_6_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_9_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:309:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_10\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:310:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_11\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:310:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_12\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:310:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_13\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:310:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Slice_1_output_0 : Float(1, 1296, 384, strides=[498048, 384, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Slice_1\"](%/backbone/backbone.0/encoder/encoder/embeddings/Add_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_11_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_12_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_10_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_13_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:310:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_14_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1  36  36  -1 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_14\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:311:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Reshape_output_0 : Float(1, 36, 36, 384, strides=[497664, 13824, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Reshape\"](%/backbone/backbone.0/encoder/encoder/embeddings/Slice_1_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_14_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:311:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_15_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   2  18   2  18  -1 [ CPULongType{6} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_15\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:315:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Reshape_1_output_0 : Float(1, 2, 18, 2, 18, 384, strides=[497664, 248832, 13824, 6912, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/embeddings/Reshape_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_15_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:315:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Transpose_output_0 : Float(1, 2, 2, 18, 18, 384, strides=[497664, 248832, 6912, 13824, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Transpose\"](%/backbone/backbone.0/encoder/encoder/embeddings/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:316:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_16_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  324   -1 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_16\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:317:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Reshape_2_output_0 : Float(4, 324, 384, strides=[124416, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Reshape_2\"](%/backbone/backbone.0/encoder/encoder/embeddings/Transpose_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_16_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:317:0\n  %onnx::Tile_603 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 4  1  1 [ CPULongType{3} ]]()\n  %/backbone/backbone.0/encoder/encoder/embeddings/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Constant_17\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:318:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/ConstantOfShape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/ConstantOfShape_1\"](%/backbone/backbone.0/encoder/encoder/embeddings/Constant_17_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:318:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Expand_1_output_0 : Float(1, 1, 384, strides=[384, 384, 1], device=cpu) = onnx::Expand[onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Expand_1\"](%/backbone/backbone.0/encoder/encoder/embeddings/Slice_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/ConstantOfShape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:318:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Tile_output_0 : Float(4, 1, 384, strides=[384, 384, 1], requires_grad=1, device=cpu) = onnx::Tile[onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Tile\"](%/backbone/backbone.0/encoder/encoder/embeddings/Expand_1_output_0, %onnx::Tile_603), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:318:0\n  %/backbone/backbone.0/encoder/encoder/embeddings/Concat_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/embeddings/Concat_1\"](%/backbone/backbone.0/encoder/encoder/embeddings/Tile_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEmbeddings::embeddings # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:319:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/norm1/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/norm1/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/embeddings/Concat_1_output_0, %backbone.0.encoder.encoder.encoder.layer.0.norm1.weight, %backbone.0.encoder.encoder.encoder.layer.0.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/query/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/query/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/norm1/LayerNormalization_output_0, %onnx::MatMul_4289), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/query/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/query/Add\"](%backbone.0.encoder.encoder.encoder.layer.0.attention.attention.query.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/query/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/key/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/key/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/norm1/LayerNormalization_output_0, %onnx::MatMul_4290), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/key/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/key/Add\"](%backbone.0.encoder.encoder.encoder.layer.0.attention.attention.key.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/key/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Reshape_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/key/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/value/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/value/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/norm1/LayerNormalization_output_0, %onnx::MatMul_4296), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/value/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/value/Add\"](%backbone.0.encoder.encoder.encoder.layer.0.attention.attention.value.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/value/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Reshape_1_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/value/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Transpose_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Transpose\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Reshape_2_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Reshape_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/query/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Transpose_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Transpose_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Shape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Slice\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Shape_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Cast_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Cast\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Sqrt\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_5_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_5_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Cast_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Transpose_2_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Transpose_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Sqrt_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Mul_output_0 : Float(4, 6, 325, 64, strides=[124800, 20800, 64, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Transpose_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Sqrt_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Mul_1_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Transpose_2_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/MatMul_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Softmax_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Softmax\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/MatMul_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/MatMul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Softmax_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Transpose_3_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Transpose_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:425:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_6_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325  384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Reshape_3_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Reshape_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Transpose_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/output/dense/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/output/dense/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/attention/Reshape_3_output_0, %onnx::MatMul_4311), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/output/dense/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/output/dense/Add\"](%backbone.0.encoder.encoder.encoder.layer.0.attention.output.dense.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/output/dense/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/layer_scale1/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/layer_scale1/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/attention/output/dense/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.0.layer_scale1.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/layer_scale1/Mul_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Concat_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:637:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/norm2/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/norm2/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.0.norm2.weight, %backbone.0.encoder.encoder.encoder.layer.0.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/fc1/MatMul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/fc1/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/norm2/LayerNormalization_output_0, %onnx::MatMul_4312), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/fc1/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/fc1/Add\"](%backbone.0.encoder.encoder.encoder.layer.0.mlp.fc1.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/fc1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Div_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Erf_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Erf[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Erf\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Erf_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Mul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Mul_1_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/fc2/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/fc2/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/activation/Mul_1_output_0, %onnx::MatMul_4313), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/fc2/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/fc2/Add\"](%backbone.0.encoder.encoder.encoder.layer.0.mlp.fc2.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/fc2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/layer_scale2/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/layer_scale2/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/mlp/fc2/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.0.layer_scale2.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.0/Add_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.0/Add_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/layer_scale2/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.0 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:645:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/norm1/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/norm1/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.0/Add_1_output_0, %backbone.0.encoder.encoder.encoder.layer.1.norm1.weight, %backbone.0.encoder.encoder.encoder.layer.1.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/query/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/query/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/norm1/LayerNormalization_output_0, %onnx::MatMul_4314), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/query/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/query/Add\"](%backbone.0.encoder.encoder.encoder.layer.1.attention.attention.query.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/query/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/key/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/key/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/norm1/LayerNormalization_output_0, %onnx::MatMul_4315), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/key/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/key/Add\"](%backbone.0.encoder.encoder.encoder.layer.1.attention.attention.key.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/key/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Reshape_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/key/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/value/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/value/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/norm1/LayerNormalization_output_0, %onnx::MatMul_4321), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/value/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/value/Add\"](%backbone.0.encoder.encoder.encoder.layer.1.attention.attention.value.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/value/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Reshape_1_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/value/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Transpose_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Transpose\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Reshape_2_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Reshape_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/query/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Transpose_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Transpose_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Shape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Slice\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Shape_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Cast_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Cast\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Sqrt\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_5_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_5_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Cast_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Transpose_2_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Transpose_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Sqrt_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Mul_output_0 : Float(4, 6, 325, 64, strides=[124800, 20800, 64, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Transpose_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Sqrt_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Mul_1_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Transpose_2_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/MatMul_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Softmax_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Softmax\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/MatMul_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/MatMul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Softmax_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Transpose_3_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Transpose_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:425:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_6_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325  384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Reshape_3_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Reshape_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Transpose_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/output/dense/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/output/dense/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/attention/Reshape_3_output_0, %onnx::MatMul_4336), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/output/dense/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/output/dense/Add\"](%backbone.0.encoder.encoder.encoder.layer.1.attention.output.dense.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/output/dense/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/layer_scale1/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/layer_scale1/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/attention/output/dense/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.1.layer_scale1.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/layer_scale1/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.0/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:637:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/norm2/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/norm2/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.1.norm2.weight, %backbone.0.encoder.encoder.encoder.layer.1.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/fc1/MatMul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/fc1/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/norm2/LayerNormalization_output_0, %onnx::MatMul_4337), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/fc1/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/fc1/Add\"](%backbone.0.encoder.encoder.encoder.layer.1.mlp.fc1.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/fc1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Div_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Erf_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Erf[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Erf\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Erf_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Mul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Mul_1_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/fc2/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/fc2/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/activation/Mul_1_output_0, %onnx::MatMul_4338), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/fc2/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/fc2/Add\"](%backbone.0.encoder.encoder.encoder.layer.1.mlp.fc2.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/fc2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/layer_scale2/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/layer_scale2/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/mlp/fc2/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.1.layer_scale2.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.1/Add_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.1/Add_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/layer_scale2/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:645:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/norm1/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/norm1/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.1/Add_1_output_0, %backbone.0.encoder.encoder.encoder.layer.2.norm1.weight, %backbone.0.encoder.encoder.encoder.layer.2.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/query/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/query/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/norm1/LayerNormalization_output_0, %onnx::MatMul_4339), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/query/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/query/Add\"](%backbone.0.encoder.encoder.encoder.layer.2.attention.attention.query.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/query/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/key/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/key/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/norm1/LayerNormalization_output_0, %onnx::MatMul_4340), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/key/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/key/Add\"](%backbone.0.encoder.encoder.encoder.layer.2.attention.attention.key.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/key/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Reshape_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/key/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/value/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/value/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/norm1/LayerNormalization_output_0, %onnx::MatMul_4346), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/value/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/value/Add\"](%backbone.0.encoder.encoder.encoder.layer.2.attention.attention.value.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/value/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Reshape_1_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/value/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Transpose_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Transpose\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Reshape_2_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Reshape_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/query/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Transpose_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Transpose_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Shape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Slice\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Shape_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Cast_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Cast\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Sqrt\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_5_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_5_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Cast_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Transpose_2_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Transpose_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Sqrt_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Mul_output_0 : Float(4, 6, 325, 64, strides=[124800, 20800, 64, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Transpose_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Sqrt_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Mul_1_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Transpose_2_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/MatMul_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Softmax_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Softmax\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/MatMul_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/MatMul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Softmax_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Transpose_3_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Transpose_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:425:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_6_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325  384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Reshape_3_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Reshape_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Transpose_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/output/dense/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/output/dense/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/attention/Reshape_3_output_0, %onnx::MatMul_4361), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/output/dense/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/output/dense/Add\"](%backbone.0.encoder.encoder.encoder.layer.2.attention.output.dense.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/output/dense/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/layer_scale1/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/layer_scale1/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/attention/output/dense/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.2.layer_scale1.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/layer_scale1/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.1/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:637:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/norm2/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/norm2/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.2.norm2.weight, %backbone.0.encoder.encoder.encoder.layer.2.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/fc1/MatMul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/fc1/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/norm2/LayerNormalization_output_0, %onnx::MatMul_4362), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/fc1/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/fc1/Add\"](%backbone.0.encoder.encoder.encoder.layer.2.mlp.fc1.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/fc1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Div_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Erf_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Erf[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Erf\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Erf_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Mul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Mul_1_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/fc2/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/fc2/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/activation/Mul_1_output_0, %onnx::MatMul_4363), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/fc2/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/fc2/Add\"](%backbone.0.encoder.encoder.encoder.layer.2.mlp.fc2.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/fc2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/layer_scale2/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/layer_scale2/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/mlp/fc2/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.2.layer_scale2.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.2/Add_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.2/Add_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/layer_scale2/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:645:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/Constant_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300   384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:617:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/Reshape_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/Add_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:617:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/norm1/LayerNormalization_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/norm1/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/Reshape_output_0, %backbone.0.encoder.encoder.encoder.layer.3.norm1.weight, %backbone.0.encoder.encoder.encoder.layer.3.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/query/MatMul_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/query/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/norm1/LayerNormalization_output_0, %onnx::MatMul_4368), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/query/Add_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/query/Add\"](%backbone.0.encoder.encoder.encoder.layer.3.attention.attention.query.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/query/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/key/MatMul_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/key/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/norm1/LayerNormalization_output_0, %onnx::MatMul_4369), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/key/Add_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/key/Add\"](%backbone.0.encoder.encoder.encoder.layer.3.attention.attention.key.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/key/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300     6    64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Reshape_output_0 : Float(1, 1300, 6, 64, strides=[499200, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/key/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/value/MatMul_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/value/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/norm1/LayerNormalization_output_0, %onnx::MatMul_4375), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/value/Add_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/value/Add\"](%backbone.0.encoder.encoder.encoder.layer.3.attention.attention.value.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/value/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300     6    64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Reshape_1_output_0 : Float(1, 1300, 6, 64, strides=[499200, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/value/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Transpose_output_0 : Float(1, 6, 1300, 64, strides=[499200, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Transpose\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300     6    64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Reshape_2_output_0 : Float(1, 1300, 6, 64, strides=[499200, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Reshape_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/query/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Transpose_1_output_0 : Float(1, 6, 1300, 64, strides=[499200, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Transpose_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Shape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Slice\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Shape_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Cast_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Cast\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Sqrt\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_5_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_5_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Cast_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Transpose_2_output_0 : Float(1, 6, 64, 1300, strides=[499200, 83200, 1300, 1], device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Transpose_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Sqrt_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Mul_output_0 : Float(1, 6, 1300, 64, strides=[499200, 83200, 64, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Transpose_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Sqrt_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Mul_1_output_0 : Float(1, 6, 64, 1300, strides=[499200, 83200, 1300, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Transpose_2_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/MatMul_output_0 : Float(1, 6, 1300, 1300, strides=[10140000, 1690000, 1300, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Softmax_output_0 : Float(1, 6, 1300, 1300, strides=[10140000, 1690000, 1300, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Softmax\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/MatMul_1_output_0 : Float(1, 6, 1300, 64, strides=[499200, 64, 384, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/MatMul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Softmax_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Transpose_3_output_0 : Float(1, 1300, 6, 64, strides=[499200, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Transpose_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:425:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_6_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300   384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Reshape_3_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Reshape_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Transpose_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/output/dense/MatMul_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/output/dense/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/attention/Reshape_3_output_0, %onnx::MatMul_4390), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/output/dense/Add_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/output/dense/Add\"](%backbone.0.encoder.encoder.encoder.layer.3.attention.output.dense.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/output/dense/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/Constant_1_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325  384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:631:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/Reshape_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/attention/output/dense/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:631:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/layer_scale1/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/layer_scale1/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/Reshape_1_output_0, %backbone.0.encoder.encoder.encoder.layer.3.layer_scale1.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/layer_scale1/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.2/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:637:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/norm2/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/norm2/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.3.norm2.weight, %backbone.0.encoder.encoder.encoder.layer.3.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/fc1/MatMul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/fc1/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/norm2/LayerNormalization_output_0, %onnx::MatMul_4395), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/fc1/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/fc1/Add\"](%backbone.0.encoder.encoder.encoder.layer.3.mlp.fc1.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/fc1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Div_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Erf_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Erf[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Erf\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Erf_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Mul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Mul_1_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/fc2/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/fc2/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/activation/Mul_1_output_0, %onnx::MatMul_4396), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/fc2/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/fc2/Add\"](%backbone.0.encoder.encoder.encoder.layer.3.mlp.fc2.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/fc2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/layer_scale2/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/layer_scale2/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/mlp/fc2/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.3.layer_scale2.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.3/Add_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.3/Add_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/layer_scale2/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.3 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:645:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/norm1/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/norm1/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.3/Add_1_output_0, %backbone.0.encoder.encoder.encoder.layer.4.norm1.weight, %backbone.0.encoder.encoder.encoder.layer.4.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/query/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/query/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/norm1/LayerNormalization_output_0, %onnx::MatMul_4397), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/query/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/query/Add\"](%backbone.0.encoder.encoder.encoder.layer.4.attention.attention.query.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/query/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/key/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/key/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/norm1/LayerNormalization_output_0, %onnx::MatMul_4398), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/key/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/key/Add\"](%backbone.0.encoder.encoder.encoder.layer.4.attention.attention.key.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/key/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Reshape_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/key/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/value/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/value/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/norm1/LayerNormalization_output_0, %onnx::MatMul_4404), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/value/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/value/Add\"](%backbone.0.encoder.encoder.encoder.layer.4.attention.attention.value.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/value/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Reshape_1_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/value/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Transpose_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Transpose\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Reshape_2_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Reshape_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/query/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Transpose_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Transpose_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Shape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Slice\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Shape_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Cast_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Cast\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Sqrt\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_5_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_5_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Cast_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Transpose_2_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Transpose_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Sqrt_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Mul_output_0 : Float(4, 6, 325, 64, strides=[124800, 20800, 64, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Transpose_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Sqrt_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Mul_1_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Transpose_2_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/MatMul_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Softmax_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Softmax\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/MatMul_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/MatMul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Softmax_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Transpose_3_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Transpose_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:425:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_6_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325  384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Reshape_3_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Reshape_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Transpose_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/output/dense/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/output/dense/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/attention/Reshape_3_output_0, %onnx::MatMul_4419), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/output/dense/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/output/dense/Add\"](%backbone.0.encoder.encoder.encoder.layer.4.attention.output.dense.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/output/dense/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/layer_scale1/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/layer_scale1/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/attention/output/dense/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.4.layer_scale1.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/layer_scale1/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.3/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:637:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/norm2/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/norm2/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.4.norm2.weight, %backbone.0.encoder.encoder.encoder.layer.4.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/fc1/MatMul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/fc1/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/norm2/LayerNormalization_output_0, %onnx::MatMul_4420), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/fc1/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/fc1/Add\"](%backbone.0.encoder.encoder.encoder.layer.4.mlp.fc1.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/fc1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Div_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Erf_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Erf[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Erf\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Erf_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Mul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Mul_1_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/fc2/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/fc2/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/activation/Mul_1_output_0, %onnx::MatMul_4421), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/fc2/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/fc2/Add\"](%backbone.0.encoder.encoder.encoder.layer.4.mlp.fc2.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/fc2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/layer_scale2/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/layer_scale2/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/mlp/fc2/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.4.layer_scale2.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.4/Add_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.4/Add_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/layer_scale2/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.4 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:645:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/norm1/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/norm1/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.4/Add_1_output_0, %backbone.0.encoder.encoder.encoder.layer.5.norm1.weight, %backbone.0.encoder.encoder.encoder.layer.5.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/query/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/query/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/norm1/LayerNormalization_output_0, %onnx::MatMul_4422), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/query/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/query/Add\"](%backbone.0.encoder.encoder.encoder.layer.5.attention.attention.query.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/query/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/key/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/key/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/norm1/LayerNormalization_output_0, %onnx::MatMul_4423), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/key/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/key/Add\"](%backbone.0.encoder.encoder.encoder.layer.5.attention.attention.key.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/key/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Reshape_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/key/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/value/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/value/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/norm1/LayerNormalization_output_0, %onnx::MatMul_4429), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/value/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/value/Add\"](%backbone.0.encoder.encoder.encoder.layer.5.attention.attention.value.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/value/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Reshape_1_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/value/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Transpose_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Transpose\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Reshape_2_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Reshape_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/query/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Transpose_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Transpose_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Shape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Slice\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Shape_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Cast_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Cast\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Sqrt\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_5_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_5_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Cast_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Transpose_2_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Transpose_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Sqrt_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Mul_output_0 : Float(4, 6, 325, 64, strides=[124800, 20800, 64, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Transpose_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Sqrt_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Mul_1_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Transpose_2_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/MatMul_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Softmax_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Softmax\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/MatMul_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/MatMul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Softmax_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Transpose_3_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Transpose_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:425:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_6_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325  384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Reshape_3_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Reshape_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Transpose_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/output/dense/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/output/dense/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/attention/Reshape_3_output_0, %onnx::MatMul_4444), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/output/dense/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/output/dense/Add\"](%backbone.0.encoder.encoder.encoder.layer.5.attention.output.dense.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/output/dense/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/layer_scale1/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/layer_scale1/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/attention/output/dense/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.5.layer_scale1.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/layer_scale1/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.4/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:637:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/norm2/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/norm2/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.5.norm2.weight, %backbone.0.encoder.encoder.encoder.layer.5.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/fc1/MatMul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/fc1/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/norm2/LayerNormalization_output_0, %onnx::MatMul_4445), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/fc1/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/fc1/Add\"](%backbone.0.encoder.encoder.encoder.layer.5.mlp.fc1.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/fc1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Div_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Erf_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Erf[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Erf\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Erf_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Mul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Mul_1_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/fc2/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/fc2/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/activation/Mul_1_output_0, %onnx::MatMul_4446), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/fc2/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/fc2/Add\"](%backbone.0.encoder.encoder.encoder.layer.5.mlp.fc2.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/fc2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/layer_scale2/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/layer_scale2/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/mlp/fc2/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.5.layer_scale2.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.5/Add_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.5/Add_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/layer_scale2/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.5 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:645:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/Constant_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300   384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:617:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/Reshape_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/Add_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:617:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/norm1/LayerNormalization_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/norm1/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/Reshape_output_0, %backbone.0.encoder.encoder.encoder.layer.6.norm1.weight, %backbone.0.encoder.encoder.encoder.layer.6.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/query/MatMul_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/query/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/norm1/LayerNormalization_output_0, %onnx::MatMul_4451), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/query/Add_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/query/Add\"](%backbone.0.encoder.encoder.encoder.layer.6.attention.attention.query.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/query/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/key/MatMul_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/key/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/norm1/LayerNormalization_output_0, %onnx::MatMul_4452), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/key/Add_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/key/Add\"](%backbone.0.encoder.encoder.encoder.layer.6.attention.attention.key.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/key/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300     6    64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Reshape_output_0 : Float(1, 1300, 6, 64, strides=[499200, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/key/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/value/MatMul_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/value/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/norm1/LayerNormalization_output_0, %onnx::MatMul_4458), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/value/Add_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/value/Add\"](%backbone.0.encoder.encoder.encoder.layer.6.attention.attention.value.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/value/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300     6    64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Reshape_1_output_0 : Float(1, 1300, 6, 64, strides=[499200, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/value/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Transpose_output_0 : Float(1, 6, 1300, 64, strides=[499200, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Transpose\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300     6    64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Reshape_2_output_0 : Float(1, 1300, 6, 64, strides=[499200, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Reshape_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/query/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Transpose_1_output_0 : Float(1, 6, 1300, 64, strides=[499200, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Transpose_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Shape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Slice\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Shape_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Cast_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Cast\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Sqrt\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_5_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_5_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Cast_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Transpose_2_output_0 : Float(1, 6, 64, 1300, strides=[499200, 83200, 1300, 1], device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Transpose_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Sqrt_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Mul_output_0 : Float(1, 6, 1300, 64, strides=[499200, 83200, 64, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Transpose_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Sqrt_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Mul_1_output_0 : Float(1, 6, 64, 1300, strides=[499200, 83200, 1300, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Transpose_2_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/MatMul_output_0 : Float(1, 6, 1300, 1300, strides=[10140000, 1690000, 1300, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Softmax_output_0 : Float(1, 6, 1300, 1300, strides=[10140000, 1690000, 1300, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Softmax\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/MatMul_1_output_0 : Float(1, 6, 1300, 64, strides=[499200, 64, 384, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/MatMul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Softmax_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Transpose_3_output_0 : Float(1, 1300, 6, 64, strides=[499200, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Transpose_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:425:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_6_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300   384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Reshape_3_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Reshape_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Transpose_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/output/dense/MatMul_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/output/dense/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/attention/Reshape_3_output_0, %onnx::MatMul_4473), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/output/dense/Add_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/output/dense/Add\"](%backbone.0.encoder.encoder.encoder.layer.6.attention.output.dense.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/output/dense/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/Constant_1_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325  384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:631:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/Reshape_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/attention/output/dense/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:631:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/layer_scale1/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/layer_scale1/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/Reshape_1_output_0, %backbone.0.encoder.encoder.encoder.layer.6.layer_scale1.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/layer_scale1/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.5/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:637:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/norm2/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/norm2/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.6.norm2.weight, %backbone.0.encoder.encoder.encoder.layer.6.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/fc1/MatMul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/fc1/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/norm2/LayerNormalization_output_0, %onnx::MatMul_4478), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/fc1/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/fc1/Add\"](%backbone.0.encoder.encoder.encoder.layer.6.mlp.fc1.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/fc1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Div_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Erf_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Erf[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Erf\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Erf_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Mul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Mul_1_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/fc2/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/fc2/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/activation/Mul_1_output_0, %onnx::MatMul_4479), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/fc2/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/fc2/Add\"](%backbone.0.encoder.encoder.encoder.layer.6.mlp.fc2.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/fc2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/layer_scale2/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/layer_scale2/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/mlp/fc2/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.6.layer_scale2.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.6/Add_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.6/Add_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/layer_scale2/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.6 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:645:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/norm1/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/norm1/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.6/Add_1_output_0, %backbone.0.encoder.encoder.encoder.layer.7.norm1.weight, %backbone.0.encoder.encoder.encoder.layer.7.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/query/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/query/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/norm1/LayerNormalization_output_0, %onnx::MatMul_4480), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/query/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/query/Add\"](%backbone.0.encoder.encoder.encoder.layer.7.attention.attention.query.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/query/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/key/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/key/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/norm1/LayerNormalization_output_0, %onnx::MatMul_4481), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/key/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/key/Add\"](%backbone.0.encoder.encoder.encoder.layer.7.attention.attention.key.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/key/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Reshape_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/key/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/value/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/value/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/norm1/LayerNormalization_output_0, %onnx::MatMul_4487), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/value/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/value/Add\"](%backbone.0.encoder.encoder.encoder.layer.7.attention.attention.value.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/value/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Reshape_1_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/value/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Transpose_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Transpose\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Reshape_2_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Reshape_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/query/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Transpose_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Transpose_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Shape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Slice\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Shape_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Cast_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Cast\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Sqrt\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_5_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_5_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Cast_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Transpose_2_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Transpose_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Sqrt_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Mul_output_0 : Float(4, 6, 325, 64, strides=[124800, 20800, 64, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Transpose_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Sqrt_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Mul_1_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Transpose_2_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/MatMul_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Softmax_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Softmax\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/MatMul_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/MatMul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Softmax_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Transpose_3_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Transpose_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:425:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_6_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325  384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Reshape_3_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Reshape_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Transpose_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/output/dense/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/output/dense/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/attention/Reshape_3_output_0, %onnx::MatMul_4502), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/output/dense/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/output/dense/Add\"](%backbone.0.encoder.encoder.encoder.layer.7.attention.output.dense.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/output/dense/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/layer_scale1/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/layer_scale1/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/attention/output/dense/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.7.layer_scale1.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/layer_scale1/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.6/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:637:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/norm2/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/norm2/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.7.norm2.weight, %backbone.0.encoder.encoder.encoder.layer.7.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/fc1/MatMul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/fc1/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/norm2/LayerNormalization_output_0, %onnx::MatMul_4503), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/fc1/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/fc1/Add\"](%backbone.0.encoder.encoder.encoder.layer.7.mlp.fc1.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/fc1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Div_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Erf_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Erf[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Erf\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Erf_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Mul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Mul_1_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/fc2/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/fc2/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/activation/Mul_1_output_0, %onnx::MatMul_4504), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/fc2/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/fc2/Add\"](%backbone.0.encoder.encoder.encoder.layer.7.mlp.fc2.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/fc2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/layer_scale2/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/layer_scale2/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/mlp/fc2/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.7.layer_scale2.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.7/Add_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.7/Add_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/layer_scale2/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.7 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:645:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/norm1/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/norm1/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.7/Add_1_output_0, %backbone.0.encoder.encoder.encoder.layer.8.norm1.weight, %backbone.0.encoder.encoder.encoder.layer.8.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/query/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/query/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/norm1/LayerNormalization_output_0, %onnx::MatMul_4505), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/query/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/query/Add\"](%backbone.0.encoder.encoder.encoder.layer.8.attention.attention.query.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/query/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/key/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/key/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/norm1/LayerNormalization_output_0, %onnx::MatMul_4506), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/key/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/key/Add\"](%backbone.0.encoder.encoder.encoder.layer.8.attention.attention.key.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/key/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Reshape_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/key/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/value/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/value/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/norm1/LayerNormalization_output_0, %onnx::MatMul_4512), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/value/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/value/Add\"](%backbone.0.encoder.encoder.encoder.layer.8.attention.attention.value.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/value/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Reshape_1_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/value/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Transpose_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Transpose\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Reshape_2_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Reshape_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/query/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Transpose_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Transpose_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Shape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Slice\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Shape_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Cast_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Cast\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Sqrt\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_5_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_5_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Cast_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Transpose_2_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Transpose_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Sqrt_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Mul_output_0 : Float(4, 6, 325, 64, strides=[124800, 20800, 64, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Transpose_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Sqrt_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Mul_1_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Transpose_2_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/MatMul_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Softmax_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Softmax\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/MatMul_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/MatMul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Softmax_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Transpose_3_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Transpose_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:425:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_6_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325  384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Reshape_3_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Reshape_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Transpose_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/output/dense/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/output/dense/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/attention/Reshape_3_output_0, %onnx::MatMul_4527), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/output/dense/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/output/dense/Add\"](%backbone.0.encoder.encoder.encoder.layer.8.attention.output.dense.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/output/dense/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/layer_scale1/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/layer_scale1/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/attention/output/dense/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.8.layer_scale1.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/layer_scale1/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.7/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:637:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/norm2/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/norm2/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.8.norm2.weight, %backbone.0.encoder.encoder.encoder.layer.8.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/fc1/MatMul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/fc1/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/norm2/LayerNormalization_output_0, %onnx::MatMul_4528), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/fc1/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/fc1/Add\"](%backbone.0.encoder.encoder.encoder.layer.8.mlp.fc1.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/fc1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Div_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Erf_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Erf[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Erf\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Erf_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Mul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Mul_1_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/fc2/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/fc2/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/activation/Mul_1_output_0, %onnx::MatMul_4529), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/fc2/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/fc2/Add\"](%backbone.0.encoder.encoder.encoder.layer.8.mlp.fc2.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/fc2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/layer_scale2/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/layer_scale2/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/mlp/fc2/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.8.layer_scale2.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.8/Add_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.8/Add_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/layer_scale2/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.8 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:645:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/Constant_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300   384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:617:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/Reshape_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/Add_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:617:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/norm1/LayerNormalization_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/norm1/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/Reshape_output_0, %backbone.0.encoder.encoder.encoder.layer.9.norm1.weight, %backbone.0.encoder.encoder.encoder.layer.9.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/query/MatMul_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/query/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/norm1/LayerNormalization_output_0, %onnx::MatMul_4534), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/query/Add_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/query/Add\"](%backbone.0.encoder.encoder.encoder.layer.9.attention.attention.query.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/query/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/key/MatMul_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/key/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/norm1/LayerNormalization_output_0, %onnx::MatMul_4535), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/key/Add_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/key/Add\"](%backbone.0.encoder.encoder.encoder.layer.9.attention.attention.key.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/key/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300     6    64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Reshape_output_0 : Float(1, 1300, 6, 64, strides=[499200, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/key/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/value/MatMul_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/value/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/norm1/LayerNormalization_output_0, %onnx::MatMul_4541), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/value/Add_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/value/Add\"](%backbone.0.encoder.encoder.encoder.layer.9.attention.attention.value.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/value/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300     6    64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Reshape_1_output_0 : Float(1, 1300, 6, 64, strides=[499200, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/value/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Transpose_output_0 : Float(1, 6, 1300, 64, strides=[499200, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Transpose\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300     6    64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Reshape_2_output_0 : Float(1, 1300, 6, 64, strides=[499200, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Reshape_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/query/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Transpose_1_output_0 : Float(1, 6, 1300, 64, strides=[499200, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Transpose_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Shape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Slice\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Shape_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Cast_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Cast\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Sqrt\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_5_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_5_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Cast_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Transpose_2_output_0 : Float(1, 6, 64, 1300, strides=[499200, 83200, 1300, 1], device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Transpose_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Sqrt_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Mul_output_0 : Float(1, 6, 1300, 64, strides=[499200, 83200, 64, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Transpose_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Sqrt_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Mul_1_output_0 : Float(1, 6, 64, 1300, strides=[499200, 83200, 1300, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Transpose_2_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/MatMul_output_0 : Float(1, 6, 1300, 1300, strides=[10140000, 1690000, 1300, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Softmax_output_0 : Float(1, 6, 1300, 1300, strides=[10140000, 1690000, 1300, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Softmax\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/MatMul_1_output_0 : Float(1, 6, 1300, 64, strides=[499200, 64, 384, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/MatMul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Softmax_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Transpose_3_output_0 : Float(1, 1300, 6, 64, strides=[499200, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Transpose_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:425:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_6_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1300   384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Reshape_3_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Reshape_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Transpose_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/output/dense/MatMul_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/output/dense/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/attention/Reshape_3_output_0, %onnx::MatMul_4556), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/output/dense/Add_output_0 : Float(1, 1300, 384, strides=[499200, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/output/dense/Add\"](%backbone.0.encoder.encoder.encoder.layer.9.attention.output.dense.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/output/dense/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/Constant_1_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325  384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:631:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/Reshape_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/attention/output/dense/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:631:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/layer_scale1/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/layer_scale1/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/Reshape_1_output_0, %backbone.0.encoder.encoder.encoder.layer.9.layer_scale1.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/layer_scale1/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.8/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:637:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/norm2/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/norm2/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.9.norm2.weight, %backbone.0.encoder.encoder.encoder.layer.9.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/fc1/MatMul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/fc1/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/norm2/LayerNormalization_output_0, %onnx::MatMul_4561), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/fc1/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/fc1/Add\"](%backbone.0.encoder.encoder.encoder.layer.9.mlp.fc1.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/fc1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Div_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Erf_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Erf[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Erf\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Erf_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Mul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Mul_1_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/fc2/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/fc2/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/activation/Mul_1_output_0, %onnx::MatMul_4562), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/fc2/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/fc2/Add\"](%backbone.0.encoder.encoder.encoder.layer.9.mlp.fc2.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/fc2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/layer_scale2/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/layer_scale2/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/mlp/fc2/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.9.layer_scale2.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.9/Add_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.9/Add_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/layer_scale2/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.9 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:645:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/norm1/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/norm1/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.9/Add_1_output_0, %backbone.0.encoder.encoder.encoder.layer.10.norm1.weight, %backbone.0.encoder.encoder.encoder.layer.10.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/query/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/query/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/norm1/LayerNormalization_output_0, %onnx::MatMul_4563), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/query/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/query/Add\"](%backbone.0.encoder.encoder.encoder.layer.10.attention.attention.query.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/query/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/key/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/key/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/norm1/LayerNormalization_output_0, %onnx::MatMul_4564), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/key/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/key/Add\"](%backbone.0.encoder.encoder.encoder.layer.10.attention.attention.key.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/key/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Reshape_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/key/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/value/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/value/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/norm1/LayerNormalization_output_0, %onnx::MatMul_4570), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/value/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/value/Add\"](%backbone.0.encoder.encoder.encoder.layer.10.attention.attention.value.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/value/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Reshape_1_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/value/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Transpose_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Transpose\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Reshape_2_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Reshape_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/query/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Transpose_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Transpose_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Shape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Slice\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Shape_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Cast_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Cast\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Sqrt\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_5_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_5_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Cast_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Transpose_2_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Transpose_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Sqrt_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Mul_output_0 : Float(4, 6, 325, 64, strides=[124800, 20800, 64, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Transpose_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Sqrt_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Mul_1_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Transpose_2_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/MatMul_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Softmax_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Softmax\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/MatMul_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/MatMul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Softmax_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Transpose_3_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Transpose_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:425:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_6_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325  384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Reshape_3_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Reshape_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Transpose_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/output/dense/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/output/dense/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/attention/Reshape_3_output_0, %onnx::MatMul_4585), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/output/dense/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/output/dense/Add\"](%backbone.0.encoder.encoder.encoder.layer.10.attention.output.dense.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/output/dense/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/layer_scale1/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/layer_scale1/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/attention/output/dense/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.10.layer_scale1.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/layer_scale1/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.9/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:637:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/norm2/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/norm2/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.10.norm2.weight, %backbone.0.encoder.encoder.encoder.layer.10.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/fc1/MatMul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/fc1/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/norm2/LayerNormalization_output_0, %onnx::MatMul_4586), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/fc1/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/fc1/Add\"](%backbone.0.encoder.encoder.encoder.layer.10.mlp.fc1.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/fc1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Div_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Erf_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Erf[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Erf\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Erf_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Mul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Mul_1_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/fc2/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/fc2/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/activation/Mul_1_output_0, %onnx::MatMul_4587), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/fc2/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/fc2/Add\"](%backbone.0.encoder.encoder.encoder.layer.10.mlp.fc2.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/fc2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/layer_scale2/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/layer_scale2/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/mlp/fc2/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.10.layer_scale2.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.10/Add_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.10/Add_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/layer_scale2/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.10 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:645:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/norm1/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/norm1/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.10/Add_1_output_0, %backbone.0.encoder.encoder.encoder.layer.11.norm1.weight, %backbone.0.encoder.encoder.encoder.layer.11.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/query/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/query/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/norm1/LayerNormalization_output_0, %onnx::MatMul_4588), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/query/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/query/Add\"](%backbone.0.encoder.encoder.encoder.layer.11.attention.attention.query.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/query/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::query # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/key/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/key/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/norm1/LayerNormalization_output_0, %onnx::MatMul_4589), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/key/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/key/Add\"](%backbone.0.encoder.encoder.encoder.layer.11.attention.attention.key.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/key/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::key # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Reshape_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Reshape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/key/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/value/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/value/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/norm1/LayerNormalization_output_0, %onnx::MatMul_4595), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/value/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/value/Add\"](%backbone.0.encoder.encoder.encoder.layer.11.attention.attention.value.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/value/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention/torch.nn.modules.linear.Linear::value # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Reshape_1_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/value/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Transpose_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Transpose\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325    6   64 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Reshape_2_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Reshape_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/query/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:352:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Transpose_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Transpose_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:353:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Shape\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Slice\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Shape_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Cast_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Cast\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Sqrt\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_5_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_5_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Cast_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Transpose_2_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Transpose_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Sqrt_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Mul_output_0 : Float(4, 6, 325, 64, strides=[124800, 20800, 64, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Transpose_1_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Sqrt_2\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Cast_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Mul_1_output_0 : Float(4, 6, 64, 325, strides=[124800, 20800, 325, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Transpose_2_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/MatMul_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Softmax_output_0 : Float(4, 6, 325, 325, strides=[633750, 105625, 325, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Softmax\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/MatMul_1_output_0 : Float(4, 6, 325, 64, strides=[124800, 64, 384, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/MatMul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Softmax_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:415:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Transpose_3_output_0 : Float(4, 325, 6, 64, strides=[124800, 384, 64, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Transpose_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:425:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_6_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   4  325  384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Reshape_3_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Reshape_3\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Transpose_3_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaSelfAttention::attention # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:427:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/output/dense/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/output/dense/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/attention/Reshape_3_output_0, %onnx::MatMul_4610), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/output/dense/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/output/dense/Add\"](%backbone.0.encoder.encoder.encoder.layer.11.attention.output.dense.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/output/dense/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSdpaAttention::attention/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersSelfOutput::output/torch.nn.modules.linear.Linear::dense # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/layer_scale1/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/layer_scale1/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/attention/output/dense/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.11.layer_scale1.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/layer_scale1/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.10/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:637:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/norm2/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/norm2/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.11.norm2.weight, %backbone.0.encoder.encoder.encoder.layer.11.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/fc1/MatMul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/fc1/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/norm2/LayerNormalization_output_0, %onnx::MatMul_4611), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/fc1/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/fc1/Add\"](%backbone.0.encoder.encoder.encoder.layer.11.mlp.fc1.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/fc1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Div_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Div\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Erf_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Erf[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Erf\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Add_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Add\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Erf_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Mul_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/fc1/Add_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Mul_1_output_0 : Float(4, 325, 1536, strides=[499200, 1536, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Mul_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/transformers.activations.GELUActivation::activation # /usr/local/lib/python3.11/dist-packages/transformers/activations.py:69:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/fc2/MatMul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], device=cpu) = onnx::MatMul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/fc2/MatMul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/activation/Mul_1_output_0, %onnx::MatMul_4612), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/fc2/Add_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/fc2/Add\"](%backbone.0.encoder.encoder.encoder.layer.11.mlp.fc2.bias, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/fc2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersMLP::mlp/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/layer_scale2/Mul_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/layer_scale2/Mul\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/mlp/fc2/Add_output_0, %backbone.0.encoder.encoder.encoder.layer.11.layer_scale2.lambda1), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11/rfdetr.models.backbone.dinov2_with_windowed_attn.Dinov2WithRegistersLayerScale::layer_scale2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:501:0\n  %/backbone/backbone.0/encoder/encoder/encoder/layer.11/Add_1_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/encoder/encoder/encoder/layer.11/Add_1\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/layer_scale2/Mul_output_0, %/backbone/backbone.0/encoder/encoder/encoder/layer.11/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersEncoder::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersLayer::layer.11 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:645:0\n  %/backbone/backbone.0/encoder/encoder/layernorm/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/layernorm/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.2/Add_1_output_0, %backbone.0.encoder.encoder.layernorm.weight, %backbone.0.encoder.encoder.layernorm.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/torch.nn.modules.normalization.LayerNorm::layernorm # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_1_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Slice_output_0 : Float(4, 324, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/Slice\"](%/backbone/backbone.0/encoder/encoder/layernorm/LayerNormalization_output_0, %/backbone/backbone.0/encoder/encoder/Constant_1_output_0, %/backbone/backbone.0/encoder/encoder/Constant_2_output_0, %/backbone/backbone.0/encoder/encoder/Constant_output_0, %/backbone/backbone.0/encoder/encoder/Constant_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_4_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1296   384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1102:0\n  %/backbone/backbone.0/encoder/encoder/Reshape_output_0 : Float(1, 1296, 384, strides=[497664, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/Reshape\"](%/backbone/backbone.0/encoder/encoder/Slice_output_0, %/backbone/backbone.0/encoder/encoder/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1102:0\n  %/backbone/backbone.0/encoder/encoder/Constant_5_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    2    2   18   18  384 [ CPULongType{6} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1103:0\n  %/backbone/backbone.0/encoder/encoder/Reshape_1_output_0 : Float(1, 2, 2, 18, 18, 384, strides=[497664, 248832, 124416, 6912, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/Reshape_1\"](%/backbone/backbone.0/encoder/encoder/Reshape_output_0, %/backbone/backbone.0/encoder/encoder/Constant_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1103:0\n  %/backbone/backbone.0/encoder/encoder/Transpose_output_0 : Float(1, 2, 18, 2, 18, 384, strides=[497664, 248832, 6912, 124416, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/backbone/backbone.0/encoder/encoder/Transpose\"](%/backbone/backbone.0/encoder/encoder/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1104:0\n  %/backbone/backbone.0/encoder/encoder/Constant_6_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1  36  36  -1 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1106:0\n  %/backbone/backbone.0/encoder/encoder/Reshape_2_output_0 : Float(1, 36, 36, 384, strides=[497664, 13824, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/Reshape_2\"](%/backbone/backbone.0/encoder/encoder/Transpose_output_0, %/backbone/backbone.0/encoder/encoder/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1106:0\n  %/backbone/backbone.0/encoder/encoder/Transpose_1_output_0 : Float(1, 384, 36, 36, strides=[497664, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 3, 1, 2], onnx_name=\"/backbone/backbone.0/encoder/encoder/Transpose_1\"](%/backbone/backbone.0/encoder/encoder/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1107:0\n  %/backbone/backbone.0/encoder/encoder/layernorm_1/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/layernorm_1/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.5/Add_1_output_0, %backbone.0.encoder.encoder.layernorm.weight, %backbone.0.encoder.encoder.layernorm.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/torch.nn.modules.normalization.LayerNorm::layernorm # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_7\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_8\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_9\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_10\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Slice_1_output_0 : Float(4, 324, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/Slice_1\"](%/backbone/backbone.0/encoder/encoder/layernorm_1/LayerNormalization_output_0, %/backbone/backbone.0/encoder/encoder/Constant_8_output_0, %/backbone/backbone.0/encoder/encoder/Constant_9_output_0, %/backbone/backbone.0/encoder/encoder/Constant_7_output_0, %/backbone/backbone.0/encoder/encoder/Constant_10_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_11_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1296   384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_11\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1102:0\n  %/backbone/backbone.0/encoder/encoder/Reshape_3_output_0 : Float(1, 1296, 384, strides=[497664, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/Reshape_3\"](%/backbone/backbone.0/encoder/encoder/Slice_1_output_0, %/backbone/backbone.0/encoder/encoder/Constant_11_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1102:0\n  %/backbone/backbone.0/encoder/encoder/Constant_12_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    2    2   18   18  384 [ CPULongType{6} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_12\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1103:0\n  %/backbone/backbone.0/encoder/encoder/Reshape_4_output_0 : Float(1, 2, 2, 18, 18, 384, strides=[497664, 248832, 124416, 6912, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/Reshape_4\"](%/backbone/backbone.0/encoder/encoder/Reshape_3_output_0, %/backbone/backbone.0/encoder/encoder/Constant_12_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1103:0\n  %/backbone/backbone.0/encoder/encoder/Transpose_2_output_0 : Float(1, 2, 18, 2, 18, 384, strides=[497664, 248832, 6912, 124416, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/backbone/backbone.0/encoder/encoder/Transpose_2\"](%/backbone/backbone.0/encoder/encoder/Reshape_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1104:0\n  %/backbone/backbone.0/encoder/encoder/Constant_13_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1  36  36  -1 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_13\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1106:0\n  %/backbone/backbone.0/encoder/encoder/Reshape_5_output_0 : Float(1, 36, 36, 384, strides=[497664, 13824, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/Reshape_5\"](%/backbone/backbone.0/encoder/encoder/Transpose_2_output_0, %/backbone/backbone.0/encoder/encoder/Constant_13_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1106:0\n  %/backbone/backbone.0/encoder/encoder/Transpose_3_output_0 : Float(1, 384, 36, 36, strides=[497664, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 3, 1, 2], onnx_name=\"/backbone/backbone.0/encoder/encoder/Transpose_3\"](%/backbone/backbone.0/encoder/encoder/Reshape_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1107:0\n  %/backbone/backbone.0/encoder/encoder/layernorm_2/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/layernorm_2/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.8/Add_1_output_0, %backbone.0.encoder.encoder.layernorm.weight, %backbone.0.encoder.encoder.layernorm.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/torch.nn.modules.normalization.LayerNorm::layernorm # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_14\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_15\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_16\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_17\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Slice_2_output_0 : Float(4, 324, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/Slice_2\"](%/backbone/backbone.0/encoder/encoder/layernorm_2/LayerNormalization_output_0, %/backbone/backbone.0/encoder/encoder/Constant_15_output_0, %/backbone/backbone.0/encoder/encoder/Constant_16_output_0, %/backbone/backbone.0/encoder/encoder/Constant_14_output_0, %/backbone/backbone.0/encoder/encoder/Constant_17_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_18_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1296   384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_18\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1102:0\n  %/backbone/backbone.0/encoder/encoder/Reshape_6_output_0 : Float(1, 1296, 384, strides=[497664, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/Reshape_6\"](%/backbone/backbone.0/encoder/encoder/Slice_2_output_0, %/backbone/backbone.0/encoder/encoder/Constant_18_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1102:0\n  %/backbone/backbone.0/encoder/encoder/Constant_19_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    2    2   18   18  384 [ CPULongType{6} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_19\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1103:0\n  %/backbone/backbone.0/encoder/encoder/Reshape_7_output_0 : Float(1, 2, 2, 18, 18, 384, strides=[497664, 248832, 124416, 6912, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/Reshape_7\"](%/backbone/backbone.0/encoder/encoder/Reshape_6_output_0, %/backbone/backbone.0/encoder/encoder/Constant_19_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1103:0\n  %/backbone/backbone.0/encoder/encoder/Transpose_4_output_0 : Float(1, 2, 18, 2, 18, 384, strides=[497664, 248832, 6912, 124416, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/backbone/backbone.0/encoder/encoder/Transpose_4\"](%/backbone/backbone.0/encoder/encoder/Reshape_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1104:0\n  %/backbone/backbone.0/encoder/encoder/Constant_20_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1  36  36  -1 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_20\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1106:0\n  %/backbone/backbone.0/encoder/encoder/Reshape_8_output_0 : Float(1, 36, 36, 384, strides=[497664, 13824, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/Reshape_8\"](%/backbone/backbone.0/encoder/encoder/Transpose_4_output_0, %/backbone/backbone.0/encoder/encoder/Constant_20_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1106:0\n  %/backbone/backbone.0/encoder/encoder/Transpose_5_output_0 : Float(1, 384, 36, 36, strides=[497664, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 3, 1, 2], onnx_name=\"/backbone/backbone.0/encoder/encoder/Transpose_5\"](%/backbone/backbone.0/encoder/encoder/Reshape_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1107:0\n  %/backbone/backbone.0/encoder/encoder/layernorm_3/LayerNormalization_output_0 : Float(4, 325, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/backbone/backbone.0/encoder/encoder/layernorm_3/LayerNormalization\"](%/backbone/backbone.0/encoder/encoder/encoder/layer.11/Add_1_output_0, %backbone.0.encoder.encoder.layernorm.weight, %backbone.0.encoder.encoder.layernorm.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder/torch.nn.modules.normalization.LayerNorm::layernorm # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/backbone/backbone.0/encoder/encoder/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_21\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_22\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_23\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_24\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Slice_3_output_0 : Float(4, 324, 384, strides=[124800, 384, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/backbone/backbone.0/encoder/encoder/Slice_3\"](%/backbone/backbone.0/encoder/encoder/layernorm_3/LayerNormalization_output_0, %/backbone/backbone.0/encoder/encoder/Constant_22_output_0, %/backbone/backbone.0/encoder/encoder/Constant_23_output_0, %/backbone/backbone.0/encoder/encoder/Constant_21_output_0, %/backbone/backbone.0/encoder/encoder/Constant_24_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1087:0\n  %/backbone/backbone.0/encoder/encoder/Constant_25_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1  1296   384 [ CPULongType{3} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_25\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1102:0\n  %/backbone/backbone.0/encoder/encoder/Reshape_9_output_0 : Float(1, 1296, 384, strides=[497664, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/Reshape_9\"](%/backbone/backbone.0/encoder/encoder/Slice_3_output_0, %/backbone/backbone.0/encoder/encoder/Constant_25_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1102:0\n  %/backbone/backbone.0/encoder/encoder/Constant_26_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    2    2   18   18  384 [ CPULongType{6} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_26\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1103:0\n  %/backbone/backbone.0/encoder/encoder/Reshape_10_output_0 : Float(1, 2, 2, 18, 18, 384, strides=[497664, 248832, 124416, 6912, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/Reshape_10\"](%/backbone/backbone.0/encoder/encoder/Reshape_9_output_0, %/backbone/backbone.0/encoder/encoder/Constant_26_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1103:0\n  %/backbone/backbone.0/encoder/encoder/Transpose_6_output_0 : Float(1, 2, 18, 2, 18, 384, strides=[497664, 248832, 6912, 124416, 384, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/backbone/backbone.0/encoder/encoder/Transpose_6\"](%/backbone/backbone.0/encoder/encoder/Reshape_10_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1104:0\n  %/backbone/backbone.0/encoder/encoder/Constant_27_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1  36  36  -1 [ CPULongType{4} ], onnx_name=\"/backbone/backbone.0/encoder/encoder/Constant_27\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1106:0\n  %/backbone/backbone.0/encoder/encoder/Reshape_11_output_0 : Float(1, 36, 36, 384, strides=[497664, 13824, 384, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/backbone/backbone.0/encoder/encoder/Reshape_11\"](%/backbone/backbone.0/encoder/encoder/Transpose_6_output_0, %/backbone/backbone.0/encoder/encoder/Constant_27_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1106:0\n  %/backbone/backbone.0/encoder/encoder/Transpose_7_output_0 : Float(1, 384, 36, 36, strides=[497664, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 3, 1, 2], onnx_name=\"/backbone/backbone.0/encoder/encoder/Transpose_7\"](%/backbone/backbone.0/encoder/encoder/Reshape_11_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.dinov2.DinoV2::encoder/rfdetr.models.backbone.dinov2_with_windowed_attn.WindowedDinov2WithRegistersBackbone::encoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/dinov2_with_windowed_attn.py:1107:0\n  %/backbone/backbone.0/projector/Concat_output_0 : Float(1, 1536, 36, 36, strides=[1990656, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/backbone.0/projector/Concat\"](%/backbone/backbone.0/encoder/encoder/Transpose_1_output_0, %/backbone/backbone.0/encoder/encoder/Transpose_3_output_0, %/backbone/backbone.0/encoder/encoder/Transpose_5_output_0, %/backbone/backbone.0/encoder/encoder/Transpose_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:268:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/conv/Conv_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/conv/Conv\"](%/backbone/backbone.0/projector/Concat_output_0, %backbone.0.projector.stages.0.0.cv1.conv.weight), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:549:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/ReduceMean_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/ReduceMean\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/conv/Conv_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:46:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Sub_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Sub\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/conv/Conv_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/ReduceMean_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Pow_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Pow[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Pow\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/ReduceMean_1_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/ReduceMean_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Pow_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Add_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Add\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/ReduceMean_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Sqrt_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Sqrt\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Div_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Div\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Mul_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Mul\"](%onnx::Mul_4694, %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Add_1_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Add_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Mul_output_0, %onnx::Add_4696), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/act/Sigmoid_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], device=cpu) = onnx::Sigmoid[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/act/Sigmoid\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv1/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/act/Mul_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/act/Mul\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/bn/Add_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/act/Sigmoid_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv1/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %onnx::Split_2084 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 128  128 [ CPULongType{2} ]]()\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/Split_output_0 : Float(1, 128, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu), %/backbone/backbone.0/projector/stages.0/stages.0.0/Split_output_1 : Float(1, 128, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/Split\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv1/act/Mul_output_0, %onnx::Split_2084), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/conv/Conv_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/conv/Conv\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/Split_output_1, %backbone.0.projector.stages.0.0.m.0.cv1.conv.weight), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:549:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/ReduceMean_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/ReduceMean\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/conv/Conv_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:46:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Sub_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Sub\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/conv/Conv_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/ReduceMean_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Pow_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Pow[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Pow\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/ReduceMean_1_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/ReduceMean_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Pow_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Add_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Add\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/ReduceMean_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Sqrt_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Sqrt\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Div_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Div\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Mul_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Mul\"](%onnx::Mul_4698, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Add_1_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Add_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Mul_output_0, %onnx::Add_4700), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/act/Sigmoid_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], device=cpu) = onnx::Sigmoid[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/act/Sigmoid\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv1/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/act/Mul_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/act/Mul\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/bn/Add_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/act/Sigmoid_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv1/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/conv/Conv_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/conv/Conv\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv1/act/Mul_output_0, %backbone.0.projector.stages.0.0.m.0.cv2.conv.weight), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:549:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/ReduceMean_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/ReduceMean\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/conv/Conv_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:46:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Sub_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Sub\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/conv/Conv_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/ReduceMean_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Pow_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Pow[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Pow\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/ReduceMean_1_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/ReduceMean_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Pow_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Add_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Add\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/ReduceMean_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Sqrt_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Sqrt\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Div_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Div\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Mul_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Mul\"](%onnx::Mul_4702, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Add_1_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Add_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Mul_output_0, %onnx::Add_4704), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/act/Sigmoid_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], device=cpu) = onnx::Sigmoid[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/act/Sigmoid\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv2/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/act/Mul_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/act/Mul\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/bn/Add_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/act/Sigmoid_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.0/rfdetr.models.backbone.projector.ConvX::cv2/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/conv/Conv_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/conv/Conv\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/act/Mul_output_0, %backbone.0.projector.stages.0.0.m.1.cv1.conv.weight), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:549:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/ReduceMean_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/ReduceMean\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/conv/Conv_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:46:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Sub_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Sub\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/conv/Conv_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/ReduceMean_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Pow_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Pow[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Pow\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/ReduceMean_1_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/ReduceMean_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Pow_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Add_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Add\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/ReduceMean_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Sqrt_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Sqrt\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Div_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Div\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Mul_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Mul\"](%onnx::Mul_4706, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Add_1_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Add_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Mul_output_0, %onnx::Add_4708), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/act/Sigmoid_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], device=cpu) = onnx::Sigmoid[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/act/Sigmoid\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv1/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/act/Mul_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/act/Mul\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/bn/Add_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/act/Sigmoid_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv1/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/conv/Conv_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/conv/Conv\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv1/act/Mul_output_0, %backbone.0.projector.stages.0.0.m.1.cv2.conv.weight), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:549:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/ReduceMean_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/ReduceMean\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/conv/Conv_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:46:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Sub_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Sub\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/conv/Conv_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/ReduceMean_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Pow_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Pow[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Pow\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/ReduceMean_1_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/ReduceMean_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Pow_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Add_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Add\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/ReduceMean_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Sqrt_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Sqrt\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Div_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Div\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Mul_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Mul\"](%onnx::Mul_4710, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Add_1_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Add_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Mul_output_0, %onnx::Add_4712), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/act/Sigmoid_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], device=cpu) = onnx::Sigmoid[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/act/Sigmoid\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv2/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/act/Mul_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/act/Mul\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/bn/Add_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/act/Sigmoid_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.1/rfdetr.models.backbone.projector.ConvX::cv2/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/conv/Conv_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/conv/Conv\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/act/Mul_output_0, %backbone.0.projector.stages.0.0.m.2.cv1.conv.weight), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:549:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/ReduceMean_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/ReduceMean\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/conv/Conv_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:46:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Sub_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Sub\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/conv/Conv_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/ReduceMean_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Pow_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Pow[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Pow\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/ReduceMean_1_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/ReduceMean_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Pow_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Add_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Add\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/ReduceMean_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Sqrt_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Sqrt\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Div_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Div\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Mul_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Mul\"](%onnx::Mul_4714, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Add_1_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Add_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Mul_output_0, %onnx::Add_4716), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv1/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/act/Sigmoid_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], device=cpu) = onnx::Sigmoid[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/act/Sigmoid\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv1/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/act/Mul_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/act/Mul\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/bn/Add_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/act/Sigmoid_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv1/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/conv/Conv_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/conv/Conv\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv1/act/Mul_output_0, %backbone.0.projector.stages.0.0.m.2.cv2.conv.weight), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:549:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/ReduceMean_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/ReduceMean\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/conv/Conv_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:46:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Sub_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Sub\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/conv/Conv_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/ReduceMean_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Pow_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Pow[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Pow\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/ReduceMean_1_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/ReduceMean_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Pow_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Add_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Add\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/ReduceMean_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Sqrt_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Sqrt\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Div_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Div\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Mul_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Mul\"](%onnx::Mul_4718, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Add_1_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Add_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Mul_output_0, %onnx::Add_4720), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/act/Sigmoid_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], device=cpu) = onnx::Sigmoid[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/act/Sigmoid\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv2/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/act/Mul_output_0 : Float(1, 128, 36, 36, strides=[165888, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/act/Mul\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/bn/Add_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/act/Sigmoid_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.Bottleneck::m.2/rfdetr.models.backbone.projector.ConvX::cv2/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/Concat_output_0 : Float(1, 640, 36, 36, strides=[829440, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/Concat\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/Split_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/Split_output_1, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.0/cv2/act/Mul_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.1/cv2/act/Mul_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/m.2/cv2/act/Mul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:141:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/conv/Conv_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/conv/Conv\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/Concat_output_0, %backbone.0.projector.stages.0.0.cv2.conv.weight), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:549:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/ReduceMean_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/ReduceMean\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/conv/Conv_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:46:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Sub_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Sub\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/conv/Conv_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/ReduceMean_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Pow_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Pow[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Pow\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/ReduceMean_1_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/ReduceMean_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Pow_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Add_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Add\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/ReduceMean_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Sqrt_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Sqrt\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Div_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Div\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Mul_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Mul\"](%onnx::Mul_4722, %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Add_1_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Add_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Mul_output_0, %onnx::Add_4724), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv2/rfdetr.models.backbone.projector.LayerNorm::bn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/act/Sigmoid_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], device=cpu) = onnx::Sigmoid[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/act/Sigmoid\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv2/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/act/Mul_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/act/Mul\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/bn/Add_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/act/Sigmoid_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.C2f::stages.0.0/rfdetr.models.backbone.projector.ConvX::cv2/torch.nn.modules.activation.SiLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2379:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.1/ReduceMean_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.1/ReduceMean\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/act/Mul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.LayerNorm::stages.0.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:46:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.1/Sub_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.1/Sub\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/act/Mul_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.1/ReduceMean_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.LayerNorm::stages.0.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.1/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.LayerNorm::stages.0.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.1/Pow_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Pow[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.1/Pow\"](%/backbone/backbone.0/projector/stages.0/stages.0.1/Sub_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.1/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.LayerNorm::stages.0.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.1/ReduceMean_1_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.1/ReduceMean_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.1/Pow_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.LayerNorm::stages.0.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:47:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.1/Sub_1_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.1/Sub_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.0/cv2/act/Mul_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.1/ReduceMean_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.LayerNorm::stages.0.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.1/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.LayerNorm::stages.0.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.1/Add_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.1/Add\"](%/backbone/backbone.0/projector/stages.0/stages.0.1/ReduceMean_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.1/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.LayerNorm::stages.0.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.1/Sqrt_output_0 : Float(1, 1, 36, 36, strides=[1296, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Sqrt[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.1/Sqrt\"](%/backbone/backbone.0/projector/stages.0/stages.0.1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.LayerNorm::stages.0.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.1/Div_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.1/Div\"](%/backbone/backbone.0/projector/stages.0/stages.0.1/Sub_1_output_0, %/backbone/backbone.0/projector/stages.0/stages.0.1/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.LayerNorm::stages.0.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:48:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.1/Mul_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.1/Mul\"](%onnx::Mul_4726, %/backbone/backbone.0/projector/stages.0/stages.0.1/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.LayerNorm::stages.0.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/backbone/backbone.0/projector/stages.0/stages.0.1/Add_1_output_0 : Float(1, 256, 36, 36, strides=[331776, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/backbone/backbone.0/projector/stages.0/stages.0.1/Add_1\"](%/backbone/backbone.0/projector/stages.0/stages.0.1/Mul_output_0, %onnx::Add_4728), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.backbone.Joiner::backbone/rfdetr.models.backbone.backbone.Backbone::backbone.0/rfdetr.models.backbone.projector.MultiScaleProjector::projector/torch.nn.modules.container.Sequential::stages.0/rfdetr.models.backbone.projector.LayerNorm::stages.0.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/backbone/projector.py:49:0\n  %/transformer/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/Shape\"](%/backbone/backbone.0/projector/stages.0/stages.0.1/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:210:0\n  %/transformer/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:210:0\n  %/transformer/Constant_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:210:0\n  %/transformer/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:210:0\n  %/transformer/Slice_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/Slice\"](%/transformer/Shape_output_0, %/transformer/Constant_1_output_0, %/transformer/Constant_2_output_0, %/transformer/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:210:0\n  %/transformer/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:210:0\n  %/transformer/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/Concat\"](%/transformer/Slice_output_0, %/transformer/Constant_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:210:0\n  %/transformer/Reshape_output_0 : Float(1, 256, 1296, strides=[331776, 1296, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/Reshape\"](%/backbone/backbone.0/projector/stages.0/stages.0.1/Add_1_output_0, %/transformer/Concat_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:210:0\n  %/transformer/Transpose_output_0 : Float(1, 1296, 256, strides=[331776, 1, 1296], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/transformer/Transpose\"](%/transformer/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:210:0\n  %/transformer/Concat_1_output_0 : Float(1, 1296, 256, strides=[331776, 256, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/transformer/Concat_1\"](%/transformer/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:217:0\n  %/transformer/Constant_4_output_0 : Long(1, 2, strides=[2, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 36  36 [ CPULongType{1,2} ], onnx_name=\"/transformer/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:222:0\n  %/transformer/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/Split_output_0 : Long(1, 2, strides=[2, 1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/Split\"](%/transformer/Constant_4_output_0, %/transformer/Constant_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/Squeeze_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/Squeeze\"](%/transformer/Split_output_0, %/transformer/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/Constant_7_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 1  1 [ CPULongType{2} ], onnx_name=\"/transformer/Constant_7\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/Split_1_output_0 : Long(1, strides=[1], device=cpu), %/transformer/Split_1_output_1 : Long(1, strides=[1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/Split_1\"](%/transformer/Squeeze_output_0, %/transformer/Constant_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/Constant_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_8\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/Squeeze_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/Squeeze_1\"](%/transformer/Split_1_output_0, %/transformer/Constant_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/Constant_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_9\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/Squeeze_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/Squeeze_2\"](%/transformer/Split_1_output_1, %/transformer/Constant_9_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/Constant_10_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_10\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/transformer/Sub\"](%/transformer/Squeeze_1_output_0, %/transformer/Constant_10_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/transformer/Cast\"](%/transformer/Squeeze_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_11\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Constant_12_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_12\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Range_output_0 : Long(*, device=cpu) = onnx::Range[onnx_name=\"/transformer/Range\"](%/transformer/Constant_11_output_0, %/transformer/Cast_output_0, %/transformer/Constant_12_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Constant_13_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_13\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Sub_1_output_0 : Long(device=cpu) = onnx::Sub[onnx_name=\"/transformer/Sub_1\"](%/transformer/Sub_output_0, %/transformer/Constant_13_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Constant_14_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_14\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Sub_2_output_0 : Long(device=cpu) = onnx::Sub[onnx_name=\"/transformer/Sub_2\"](%/transformer/Squeeze_1_output_0, %/transformer/Constant_14_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/Cast_1\"](%/transformer/Sub_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/Cast_2\"](%/transformer/Sub_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Div_output_0 : Float(device=cpu) = onnx::Div[onnx_name=\"/transformer/Div\"](%/transformer/Cast_1_output_0, %/transformer/Cast_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Cast_3_output_0 : Float(*, device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/Cast_3\"](%/transformer/Range_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Mul_output_0 : Float(*, device=cpu) = onnx::Mul[onnx_name=\"/transformer/Mul\"](%/transformer/Cast_3_output_0, %/transformer/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_15\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Add_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/transformer/Add\"](%/transformer/Mul_output_0, %/transformer/Constant_15_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:95:0\n  %/transformer/Constant_16_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_16\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/transformer/Sub_3\"](%/transformer/Squeeze_2_output_0, %/transformer/Constant_16_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/transformer/Cast_4\"](%/transformer/Squeeze_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Constant_17_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_17\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Constant_18_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_18\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Range_1_output_0 : Long(*, device=cpu) = onnx::Range[onnx_name=\"/transformer/Range_1\"](%/transformer/Constant_17_output_0, %/transformer/Cast_4_output_0, %/transformer/Constant_18_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_19\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Sub_4_output_0 : Long(device=cpu) = onnx::Sub[onnx_name=\"/transformer/Sub_4\"](%/transformer/Sub_3_output_0, %/transformer/Constant_19_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Constant_20_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_20\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Sub_5_output_0 : Long(device=cpu) = onnx::Sub[onnx_name=\"/transformer/Sub_5\"](%/transformer/Squeeze_2_output_0, %/transformer/Constant_20_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Cast_5_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/Cast_5\"](%/transformer/Sub_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Cast_6_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/Cast_6\"](%/transformer/Sub_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Div_1_output_0 : Float(device=cpu) = onnx::Div[onnx_name=\"/transformer/Div_1\"](%/transformer/Cast_5_output_0, %/transformer/Cast_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Cast_7_output_0 : Float(*, device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/Cast_7\"](%/transformer/Range_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Mul_1_output_0 : Float(*, device=cpu) = onnx::Mul[onnx_name=\"/transformer/Mul_1\"](%/transformer/Cast_7_output_0, %/transformer/Div_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Constant_21_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_21\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Add_1_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/transformer/Add_1\"](%/transformer/Mul_1_output_0, %/transformer/Constant_21_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:96:0\n  %/transformer/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/Constant_22\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/functional.py:539:0\n  %/transformer/Reshape_1_output_0 : Float(*, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/Reshape_1\"](%/transformer/Add_output_0, %/transformer/Constant_22_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/functional.py:539:0\n  %/transformer/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/Constant_23\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/functional.py:539:0\n  %/transformer/Reshape_2_output_0 : Float(*, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/Reshape_2\"](%/transformer/Add_1_output_0, %/transformer/Constant_23_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/functional.py:539:0\n  %/transformer/Shape_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/Shape_1\"](%/transformer/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/functional.py:539:0\n  %/transformer/Shape_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/Shape_2\"](%/transformer/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/functional.py:539:0\n  %/transformer/Concat_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/Concat_2\"](%/transformer/Shape_1_output_0, %/transformer/Shape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/functional.py:539:0\n  %/transformer/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_24\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/functional.py:539:0\n  %/transformer/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/Concat_3\"](%/transformer/Shape_1_output_0, %/transformer/Constant_24_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/functional.py:539:0\n  %/transformer/Reshape_3_output_0 : Float(*, 1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/Reshape_3\"](%/transformer/Reshape_1_output_0, %/transformer/Concat_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/functional.py:539:0\n  %/transformer/Expand_output_0 : Float(*, *, strides=[1, 0], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/transformer/Expand\"](%/transformer/Reshape_3_output_0, %/transformer/Concat_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer\n  %/transformer/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_25\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/functional.py:539:0\n  %/transformer/Concat_4_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/Concat_4\"](%/transformer/Constant_25_output_0, %/transformer/Shape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/functional.py:539:0\n  %/transformer/Reshape_4_output_0 : Float(1, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/Reshape_4\"](%/transformer/Reshape_2_output_0, %/transformer/Concat_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/torch/functional.py:539:0\n  %/transformer/Expand_1_output_0 : Float(*, *, strides=[0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/transformer/Expand_1\"](%/transformer/Reshape_4_output_0, %/transformer/Concat_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer\n  %/transformer/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/Constant_26\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:97:0\n  %/transformer/Unsqueeze_output_0 : Float(*, *, 1, strides=[0, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/Unsqueeze\"](%/transformer/Expand_1_output_0, %/transformer/Constant_26_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:97:0\n  %/transformer/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/Constant_27\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:97:0\n  %/transformer/Unsqueeze_1_output_0 : Float(*, *, 1, strides=[1, 0, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/Unsqueeze_1\"](%/transformer/Expand_output_0, %/transformer/Constant_27_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:97:0\n  %/transformer/Concat_5_output_0 : Float(*, *, 2, strides=[72, 2, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/transformer/Concat_5\"](%/transformer/Unsqueeze_output_0, %/transformer/Unsqueeze_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:97:0\n  %/transformer/Constant_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_28\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:100:0\n  %/transformer/Unsqueeze_2_output_0 : Float(1, *, *, 2, strides=[2592, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/Unsqueeze_2\"](%/transformer/Concat_5_output_0, %/transformer/Constant_28_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:100:0\n  %/transformer/Constant_29_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1 -1 -1 [ CPULongType{4} ], onnx_name=\"/transformer/Constant_29\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:100:0\n  %/transformer/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name=\"/transformer/Constant_30\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:100:0\n  %/transformer/ConstantOfShape_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/transformer/ConstantOfShape\"](%/transformer/Constant_30_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:100:0\n  %/transformer/Constant_31_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/Constant_31\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:100:0\n  %/transformer/Mul_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/transformer/Mul_2\"](%/transformer/ConstantOfShape_output_0, %/transformer/Constant_31_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:100:0\n  %/transformer/Equal_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/transformer/Equal\"](%/transformer/Constant_29_output_0, %/transformer/Mul_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:100:0\n  %/transformer/Where_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/transformer/Where\"](%/transformer/Equal_output_0, %/transformer/ConstantOfShape_output_0, %/transformer/Constant_29_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:100:0\n  %/transformer/Expand_2_output_0 : Float(1, *, *, 2, strides=[2592, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/transformer/Expand_2\"](%/transformer/Unsqueeze_2_output_0, %/transformer/Where_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:100:0\n  %/transformer/Constant_32_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/transformer/Constant_32\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:100:0\n  %/transformer/Add_2_output_0 : Float(1, *, *, 2, strides=[2592, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/transformer/Add_2\"](%/transformer/Expand_2_output_0, %/transformer/Constant_32_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:100:0\n  %/transformer/Constant_33_output_0 : Float(1, 1, 1, 2, strides=[2, 2, 2, 1], requires_grad=0, device=cpu) = onnx::Constant[value=(1,1,.,.) =    36  36 [ CPUFloatType{1,1,1,2} ], onnx_name=\"/transformer/Constant_33\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:100:0\n  %/transformer/Div_2_output_0 : Float(1, *, *, 2, strides=[2592, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/transformer/Div_2\"](%/transformer/Add_2_output_0, %/transformer/Constant_33_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:100:0\n  %/transformer/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/Shape_3\"](%/transformer/Div_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:102:0\n  %/transformer/ConstantOfShape_1_output_0 : Float(1, *, *, 2, strides=[2592, 72, 2, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/transformer/ConstantOfShape_1\"](%/transformer/Shape_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:102:0\n  %/transformer/Constant_34_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.05}, onnx_name=\"/transformer/Constant_34\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:102:0\n  %/transformer/Mul_3_output_0 : Float(1, *, *, 2, strides=[2592, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/Mul_3\"](%/transformer/ConstantOfShape_1_output_0, %/transformer/Constant_34_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:102:0\n  %/transformer/Constant_35_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_35\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:102:0\n  %/transformer/Mul_4_output_0 : Float(1, *, *, 2, strides=[2592, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/Mul_4\"](%/transformer/Mul_3_output_0, %/transformer/Constant_35_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:102:0\n  %/transformer/Concat_6_output_0 : Float(1, *, *, 4, strides=[5184, 144, 4, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/transformer/Concat_6\"](%/transformer/Div_2_output_0, %/transformer/Mul_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:104:0\n  %/transformer/Constant_36_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1  4 [ CPULongType{3} ], onnx_name=\"/transformer/Constant_36\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:104:0\n  %/transformer/Reshape_5_output_0 : Float(*, *, *, strides=[5184, 4, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/Reshape_5\"](%/transformer/Concat_6_output_0, %/transformer/Constant_36_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:104:0\n  %/transformer/Concat_7_output_0 : Float(*, *, *, strides=[5184, 4, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/transformer/Concat_7\"](%/transformer/Reshape_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:108:0\n  %/transformer/Constant_37_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.01}, onnx_name=\"/transformer/Constant_37\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:109:0\n  %/transformer/Greater_output_0 : Bool(*, *, *, strides=[5184, 4, 1], requires_grad=0, device=cpu) = onnx::Greater[onnx_name=\"/transformer/Greater\"](%/transformer/Concat_7_output_0, %/transformer/Constant_37_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:109:0\n  %/transformer/Constant_38_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.99}, onnx_name=\"/transformer/Constant_38\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:109:0\n  %/transformer/Less_output_0 : Bool(*, *, *, strides=[5184, 4, 1], requires_grad=0, device=cpu) = onnx::Less[onnx_name=\"/transformer/Less\"](%/transformer/Concat_7_output_0, %/transformer/Constant_38_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:109:0\n  %/transformer/And_output_0 : Bool(*, *, *, strides=[5184, 4, 1], requires_grad=0, device=cpu) = onnx::And[onnx_name=\"/transformer/And\"](%/transformer/Greater_output_0, %/transformer/Less_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:109:0\n  %/transformer/Not_output_0 : Bool(*, *, *, device=cpu) = onnx::Not[onnx_name=\"/transformer/Not\"](%/transformer/And_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:109:0\n  %/transformer/Cast_8_output_0 : Long(*, *, *, device=cpu) = onnx::Cast[to=7, onnx_name=\"/transformer/Cast_8\"](%/transformer/Not_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:109:0\n  %/transformer/Constant_39_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/Constant_39\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:109:0\n  %/transformer/ReduceSum_output_0 : Long(*, *, 1, device=cpu) = onnx::ReduceSum[keepdims=1, noop_with_empty_axes=0, onnx_name=\"/transformer/ReduceSum\"](%/transformer/Cast_8_output_0, %/transformer/Constant_39_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:109:0\n  %/transformer/Constant_40_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_40\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:109:0\n  %/transformer/Greater_1_output_0 : Bool(*, *, 1, device=cpu) = onnx::Greater[onnx_name=\"/transformer/Greater_1\"](%/transformer/ReduceSum_output_0, %/transformer/Constant_40_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:109:0\n  %/transformer/Not_1_output_0 : Bool(*, *, 1, strides=[1296, 1, 1], requires_grad=0, device=cpu) = onnx::Not[onnx_name=\"/transformer/Not_1\"](%/transformer/Greater_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:109:0\n  %/transformer/Not_2_output_0 : Bool(*, *, 1, strides=[1296, 1, 1], requires_grad=0, device=cpu) = onnx::Not[onnx_name=\"/transformer/Not_2\"](%/transformer/Not_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:119:0\n  %/transformer/Cast_9_output_0 : Bool(*, *, 1, device=cpu) = onnx::Cast[to=9, onnx_name=\"/transformer/Cast_9\"](%/transformer/Not_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:119:0\n  %/transformer/Constant_41_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_41\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:119:0\n  %/transformer/Where_1_output_0 : Float(*, *, *, strides=[5184, 4, 1], requires_grad=0, device=cpu) = onnx::Where[onnx_name=\"/transformer/Where_1\"](%/transformer/Cast_9_output_0, %/transformer/Constant_41_output_0, %/transformer/Concat_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:119:0\n  %/transformer/Cast_10_output_0 : Bool(*, *, 1, device=cpu) = onnx::Cast[to=9, onnx_name=\"/transformer/Cast_10\"](%/transformer/Not_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:124:0\n  %/transformer/Constant_42_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_42\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:124:0\n  %/transformer/Where_2_output_0 : Float(*, 1296, 256, strides=[331776, 256, 1], requires_grad=1, device=cpu) = onnx::Where[onnx_name=\"/transformer/Where_2\"](%/transformer/Cast_10_output_0, %/transformer/Constant_42_output_0, %/transformer/Concat_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:124:0\n  %/transformer/Cast_11_output_0 : Float(*, 1296, 256, strides=[331776, 256, 1], requires_grad=1, device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/Cast_11\"](%/transformer/Where_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:126:0\n  %/transformer/Cast_12_output_0 : Float(*, *, *, strides=[5184, 4, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/Cast_12\"](%/transformer/Where_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:126:0\n  %/transformer/enc_output.0/MatMul_output_0 : Float(*, 1296, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/enc_output.0/MatMul\"](%/transformer/Cast_11_output_0, %onnx::MatMul_4757), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/torch.nn.modules.linear.Linear::enc_output.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/enc_output.0/Add_output_0 : Float(*, 1296, 256, strides=[331776, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/enc_output.0/Add\"](%transformer.enc_output.0.bias, %/transformer/enc_output.0/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/torch.nn.modules.linear.Linear::enc_output.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/enc_output_norm.0/LayerNormalization_output_0 : Float(*, 1296, 256, strides=[331776, 256, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/transformer/enc_output_norm.0/LayerNormalization\"](%/transformer/enc_output.0/Add_output_0, %transformer.enc_output_norm.0.weight, %transformer.enc_output_norm.0.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/torch.nn.modules.normalization.LayerNorm::enc_output_norm.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/transformer/enc_out_class_embed.0/MatMul_output_0 : Float(*, 1296, 13, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/enc_out_class_embed.0/MatMul\"](%/transformer/enc_output_norm.0/LayerNormalization_output_0, %onnx::MatMul_4758), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/torch.nn.modules.linear.Linear::enc_out_class_embed.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/enc_out_class_embed.0/Add_output_0 : Float(*, 1296, 13, strides=[16848, 13, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/enc_out_class_embed.0/Add\"](%transformer.enc_out_class_embed.0.bias, %/transformer/enc_out_class_embed.0/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/torch.nn.modules.linear.Linear::enc_out_class_embed.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/enc_out_bbox_embed.0/layers.0/MatMul_output_0 : Float(*, 1296, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/enc_out_bbox_embed.0/layers.0/MatMul\"](%/transformer/enc_output_norm.0/LayerNormalization_output_0, %onnx::MatMul_4759), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.lwdetr.MLP::enc_out_bbox_embed.0/torch.nn.modules.linear.Linear::layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/enc_out_bbox_embed.0/layers.0/Add_output_0 : Float(*, 1296, 256, strides=[331776, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/enc_out_bbox_embed.0/layers.0/Add\"](%transformer.enc_out_bbox_embed.0.layers.0.bias, %/transformer/enc_out_bbox_embed.0/layers.0/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.lwdetr.MLP::enc_out_bbox_embed.0/torch.nn.modules.linear.Linear::layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/enc_out_bbox_embed.0/Relu_output_0 : Float(*, 1296, 256, strides=[331776, 256, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/transformer/enc_out_bbox_embed.0/Relu\"](%/transformer/enc_out_bbox_embed.0/layers.0/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.lwdetr.MLP::enc_out_bbox_embed.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n  %/transformer/enc_out_bbox_embed.0/layers.1/MatMul_output_0 : Float(*, 1296, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/enc_out_bbox_embed.0/layers.1/MatMul\"](%/transformer/enc_out_bbox_embed.0/Relu_output_0, %onnx::MatMul_4760), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.lwdetr.MLP::enc_out_bbox_embed.0/torch.nn.modules.linear.Linear::layers.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/enc_out_bbox_embed.0/layers.1/Add_output_0 : Float(*, 1296, 256, strides=[331776, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/enc_out_bbox_embed.0/layers.1/Add\"](%transformer.enc_out_bbox_embed.0.layers.1.bias, %/transformer/enc_out_bbox_embed.0/layers.1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.lwdetr.MLP::enc_out_bbox_embed.0/torch.nn.modules.linear.Linear::layers.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/enc_out_bbox_embed.0/Relu_1_output_0 : Float(*, 1296, 256, strides=[331776, 256, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/transformer/enc_out_bbox_embed.0/Relu_1\"](%/transformer/enc_out_bbox_embed.0/layers.1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.lwdetr.MLP::enc_out_bbox_embed.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n  %/transformer/enc_out_bbox_embed.0/layers.2/MatMul_output_0 : Float(*, 1296, 4, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/enc_out_bbox_embed.0/layers.2/MatMul\"](%/transformer/enc_out_bbox_embed.0/Relu_1_output_0, %onnx::MatMul_4761), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.lwdetr.MLP::enc_out_bbox_embed.0/torch.nn.modules.linear.Linear::layers.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/enc_out_bbox_embed.0/layers.2/Add_output_0 : Float(*, 1296, 4, strides=[5184, 4, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/enc_out_bbox_embed.0/layers.2/Add\"](%transformer.enc_out_bbox_embed.0.layers.2.bias, %/transformer/enc_out_bbox_embed.0/layers.2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.lwdetr.MLP::enc_out_bbox_embed.0/torch.nn.modules.linear.Linear::layers.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_43\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:237:0\n  %/transformer/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_44\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:237:0\n  %/transformer/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_45\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:237:0\n  %/transformer/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_46\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:237:0\n  %/transformer/Slice_1_output_0 : Float(*, 1296, 2, strides=[5184, 4, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/Slice_1\"](%/transformer/enc_out_bbox_embed.0/layers.2/Add_output_0, %/transformer/Constant_44_output_0, %/transformer/Constant_45_output_0, %/transformer/Constant_43_output_0, %/transformer/Constant_46_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:237:0\n  %/transformer/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_47\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:238:0\n  %/transformer/Constant_48_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_48\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:238:0\n  %/transformer/Constant_49_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/Constant_49\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:238:0\n  %/transformer/Constant_50_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_50\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:238:0\n  %/transformer/Slice_2_output_0 : Float(*, *, *, strides=[5184, 4, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/transformer/Slice_2\"](%/transformer/Cast_12_output_0, %/transformer/Constant_48_output_0, %/transformer/Constant_49_output_0, %/transformer/Constant_47_output_0, %/transformer/Constant_50_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:238:0\n  %/transformer/Mul_5_output_0 : Float(*, *, *, strides=[2592, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/Mul_5\"](%/transformer/Slice_1_output_0, %/transformer/Slice_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:237:0\n  %/transformer/Constant_51_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_51\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:238:0\n  %/transformer/Constant_52_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_52\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:238:0\n  %/transformer/Constant_53_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_53\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:238:0\n  %/transformer/Constant_54_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_54\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:238:0\n  %/transformer/Slice_3_output_0 : Float(*, *, *, strides=[5184, 4, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/transformer/Slice_3\"](%/transformer/Cast_12_output_0, %/transformer/Constant_52_output_0, %/transformer/Constant_53_output_0, %/transformer/Constant_51_output_0, %/transformer/Constant_54_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:238:0\n  %/transformer/Add_3_output_0 : Float(*, *, *, strides=[2592, 2, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/Add_3\"](%/transformer/Mul_5_output_0, %/transformer/Slice_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:237:0\n  %/transformer/Constant_55_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_55\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:239:0\n  %/transformer/Constant_56_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_56\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:239:0\n  %/transformer/Constant_57_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/Constant_57\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:239:0\n  %/transformer/Constant_58_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_58\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:239:0\n  %/transformer/Slice_4_output_0 : Float(*, 1296, 2, strides=[5184, 4, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/Slice_4\"](%/transformer/enc_out_bbox_embed.0/layers.2/Add_output_0, %/transformer/Constant_56_output_0, %/transformer/Constant_57_output_0, %/transformer/Constant_55_output_0, %/transformer/Constant_58_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:239:0\n  %/transformer/Exp_output_0 : Float(*, 1296, 2, strides=[2592, 2, 1], requires_grad=1, device=cpu) = onnx::Exp[onnx_name=\"/transformer/Exp\"](%/transformer/Slice_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:239:0\n  %/transformer/Mul_6_output_0 : Float(*, *, *, strides=[2592, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/Mul_6\"](%/transformer/Exp_output_0, %/transformer/Slice_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:239:0\n  %/transformer/Concat_8_output_0 : Float(*, *, *, strides=[5184, 4, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/transformer/Concat_8\"](%/transformer/Add_3_output_0, %/transformer/Mul_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:240:0\n  %/transformer/ReduceMax_output_0 : Float(*, 1296, strides=[1296, 1], requires_grad=1, device=cpu) = onnx::ReduceMax[axes=[-1], keepdims=0, onnx_name=\"/transformer/ReduceMax\"](%/transformer/enc_out_class_embed.0/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:247:0\n  %/transformer/Constant_59_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={300}, onnx_name=\"/transformer/Constant_59\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:247:0\n  %/transformer/TopK_output_0 : Float(*, 300, strides=[300, 1], requires_grad=1, device=cpu), %/transformer/TopK_output_1 : Long(*, 300, strides=[300, 1], requires_grad=0, device=cpu) = onnx::TopK[axis=1, largest=1, sorted=1, onnx_name=\"/transformer/TopK\"](%/transformer/ReduceMax_output_0, %/transformer/Constant_59_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:247:0\n  %/transformer/Constant_60_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/Constant_60\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:250:0\n  %/transformer/Unsqueeze_3_output_0 : Long(*, 300, 1, strides=[300, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/Unsqueeze_3\"](%/transformer/TopK_output_1, %/transformer/Constant_60_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:250:0\n  %onnx::Tile_2498 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  4 [ CPULongType{3} ]]()\n  %/transformer/Constant_61_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/Constant_61\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:250:0\n  %/transformer/ConstantOfShape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/transformer/ConstantOfShape_2\"](%/transformer/Constant_61_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:250:0\n  %/transformer/Expand_3_output_0 : Long(*, 300, 1, device=cpu) = onnx::Expand[onnx_name=\"/transformer/Expand_3\"](%/transformer/Unsqueeze_3_output_0, %/transformer/ConstantOfShape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:250:0\n  %/transformer/Tile_output_0 : Long(*, 300, 4, strides=[1200, 4, 1], requires_grad=0, device=cpu) = onnx::Tile[onnx_name=\"/transformer/Tile\"](%/transformer/Expand_3_output_0, %onnx::Tile_2498), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:250:0\n  %/transformer/GatherElements_output_0 : Float(*, 300, 4, strides=[1200, 4, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=1, onnx_name=\"/transformer/GatherElements\"](%/transformer/Concat_8_output_0, %/transformer/Tile_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:249:0\n  %/transformer/Concat_9_output_0 : Float(*, 300, 4, strides=[1200, 4, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/transformer/Concat_9\"](%/transformer/GatherElements_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:262:0\n  %/transformer/Constant_62_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/transformer/Constant_62\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:268:0\n  %/transformer/Constant_63_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/transformer/Constant_63\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:269:0\n  %/transformer/Constant_64_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/Constant_64\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:268:0\n  %/transformer/ConstantOfShape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/transformer/ConstantOfShape_3\"](%/transformer/Constant_64_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:268:0\n  %/transformer/Expand_4_output_0 : Float(1, 300, 256, strides=[76800, 256, 1], device=cpu) = onnx::Expand[onnx_name=\"/transformer/Expand_4\"](%onnx::Expand_4780, %/transformer/ConstantOfShape_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:268:0\n  %/transformer/Tile_1_output_0 : Float(1, 300, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Tile[onnx_name=\"/transformer/Tile_1\"](%/transformer/Expand_4_output_0, %/transformer/Constant_62_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:268:0\n  %/transformer/Constant_65_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/Constant_65\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:269:0\n  %/transformer/ConstantOfShape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/transformer/ConstantOfShape_4\"](%/transformer/Constant_65_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:269:0\n  %/transformer/Expand_5_output_0 : Float(1, 300, 4, strides=[1200, 4, 1], device=cpu) = onnx::Expand[onnx_name=\"/transformer/Expand_5\"](%onnx::Expand_4798, %/transformer/ConstantOfShape_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:269:0\n  %/transformer/Tile_2_output_0 : Float(1, 300, 4, strides=[1200, 4, 1], requires_grad=1, device=cpu) = onnx::Tile[onnx_name=\"/transformer/Tile_2\"](%/transformer/Expand_5_output_0, %/transformer/Constant_63_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:269:0\n  %/transformer/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/Shape_4\"](%/transformer/Concat_9_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:271:0\n  %/transformer/Constant_66_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_66\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:271:0\n  %/transformer/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/Gather\"](%/transformer/Shape_4_output_0, %/transformer/Constant_66_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:271:0\n  %/transformer/Constant_67_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_67\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:272:0\n  %/transformer/Constant_68_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_68\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:272:0\n  %/transformer/Constant_69_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_69\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:272:0\n  %/transformer/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/Unsqueeze_4\"](%/transformer/Gather_output_0, %/transformer/Constant_69_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:272:0\n  %/transformer/Constant_70_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_70\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:272:0\n  %/transformer/Slice_5_output_0 : Float(1, *, 4, strides=[1200, 4, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/Slice_5\"](%/transformer/Tile_2_output_0, %/transformer/Constant_68_output_0, %/transformer/Unsqueeze_4_output_0, %/transformer/Constant_67_output_0, %/transformer/Constant_70_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:272:0\n  %/transformer/Constant_71_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_71\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:273:0\n  %/transformer/Constant_72_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_72\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:273:0\n  %/transformer/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/Unsqueeze_5\"](%/transformer/Gather_output_0, %/transformer/Constant_72_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:273:0\n  %/transformer/Constant_73_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/Constant_73\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:273:0\n  %/transformer/Constant_74_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_74\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:273:0\n  %/transformer/Slice_6_output_0 : Float(1, *, 4, strides=[1200, 4, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/Slice_6\"](%/transformer/Tile_2_output_0, %/transformer/Unsqueeze_5_output_0, %/transformer/Constant_73_output_0, %/transformer/Constant_71_output_0, %/transformer/Constant_74_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:273:0\n  %/transformer/Constant_75_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_75\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:276:0\n  %/transformer/Constant_76_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_76\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:276:0\n  %/transformer/Constant_77_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_77\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:276:0\n  %/transformer/Constant_78_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_78\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:276:0\n  %/transformer/Slice_7_output_0 : Float(1, *, 2, strides=[1200, 4, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/Slice_7\"](%/transformer/Slice_5_output_0, %/transformer/Constant_76_output_0, %/transformer/Constant_77_output_0, %/transformer/Constant_75_output_0, %/transformer/Constant_78_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:276:0\n  %/transformer/Constant_79_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_79\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:276:0\n  %/transformer/Constant_80_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_80\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:276:0\n  %/transformer/Constant_81_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/Constant_81\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:276:0\n  %/transformer/Constant_82_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_82\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:276:0\n  %/transformer/Slice_8_output_0 : Float(*, 300, 2, strides=[1200, 4, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/transformer/Slice_8\"](%/transformer/Concat_9_output_0, %/transformer/Constant_80_output_0, %/transformer/Constant_81_output_0, %/transformer/Constant_79_output_0, %/transformer/Constant_82_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:276:0\n  %/transformer/Mul_7_output_0 : Float(*, *, 2, strides=[600, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/Mul_7\"](%/transformer/Slice_7_output_0, %/transformer/Slice_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:276:0\n  %/transformer/Constant_83_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_83\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:277:0\n  %/transformer/Constant_84_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/Constant_84\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:277:0\n  %/transformer/Constant_85_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_85\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:277:0\n  %/transformer/Constant_86_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_86\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:277:0\n  %/transformer/Slice_9_output_0 : Float(*, 300, 2, strides=[1200, 4, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/transformer/Slice_9\"](%/transformer/Concat_9_output_0, %/transformer/Constant_84_output_0, %/transformer/Constant_85_output_0, %/transformer/Constant_83_output_0, %/transformer/Constant_86_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:277:0\n  %/transformer/Add_4_output_0 : Float(*, *, 2, strides=[600, 2, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/Add_4\"](%/transformer/Mul_7_output_0, %/transformer/Slice_9_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:277:0\n  %/transformer/Constant_87_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_87\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:278:0\n  %/transformer/Constant_88_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/Constant_88\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:278:0\n  %/transformer/Constant_89_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/Constant_89\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:278:0\n  %/transformer/Constant_90_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/Constant_90\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:278:0\n  %/transformer/Slice_10_output_0 : Float(1, *, 2, strides=[1200, 4, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/Slice_10\"](%/transformer/Slice_5_output_0, %/transformer/Constant_88_output_0, %/transformer/Constant_89_output_0, %/transformer/Constant_87_output_0, %/transformer/Constant_90_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:278:0\n  %/transformer/Exp_1_output_0 : Float(1, *, 2, strides=[600, 2, 1], requires_grad=1, device=cpu) = onnx::Exp[onnx_name=\"/transformer/Exp_1\"](%/transformer/Slice_10_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:278:0\n  %/transformer/Mul_8_output_0 : Float(*, *, 2, strides=[600, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/Mul_8\"](%/transformer/Exp_1_output_0, %/transformer/Slice_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:278:0\n  %/transformer/Concat_10_output_0 : Float(*, *, 4, strides=[1200, 4, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/transformer/Concat_10\"](%/transformer/Add_4_output_0, %/transformer/Mul_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:279:0\n  %/transformer/Concat_11_output_0 : Float(1, *, 4, strides=[1200, 4, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=-2, onnx_name=\"/transformer/Concat_11\"](%/transformer/Concat_10_output_0, %/transformer/Slice_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:285:0\n  %/transformer/decoder/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:361:0\n  %/transformer/decoder/Constant_1_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:361:0\n  %/transformer/decoder/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name=\"/transformer/decoder/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:361:0\n  %/transformer/decoder/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:361:0\n  %/transformer/decoder/Slice_output_0 : Float(1, *, 4, strides=[1200, 4, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/Slice\"](%/transformer/Concat_11_output_0, %/transformer/decoder/Constant_1_output_0, %/transformer/decoder/Constant_2_output_0, %/transformer/decoder/Constant_output_0, %/transformer/decoder/Constant_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:361:0\n  %/transformer/decoder/Gather_output_0 : Float(1, *, strides=[1200, 4], requires_grad=1, device=cpu) = onnx::Gather[axis=2, onnx_name=\"/transformer/decoder/Gather\"](%/transformer/decoder/Slice_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:49:0\n  %/transformer/decoder/Constant_4_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name=\"/transformer/decoder/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:49:0\n  %/transformer/decoder/Mul_output_0 : Float(1, *, strides=[300, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/Mul\"](%/transformer/decoder/Gather_output_0, %/transformer/decoder/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:49:0\n  %/transformer/decoder/Gather_1_output_0 : Float(1, *, strides=[1200, 4], requires_grad=1, device=cpu) = onnx::Gather[axis=2, onnx_name=\"/transformer/decoder/Gather_1\"](%/transformer/decoder/Slice_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/patch_embeddings/projection/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:50:0\n  %/transformer/decoder/Constant_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name=\"/transformer/decoder/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:50:0\n  %/transformer/decoder/Mul_1_output_0 : Float(1, *, strides=[300, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/Mul_1\"](%/transformer/decoder/Gather_1_output_0, %/transformer/decoder/Constant_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:50:0\n  %/transformer/decoder/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:51:0\n  %/transformer/decoder/Unsqueeze_output_0 : Float(1, *, 1, strides=[300, 1, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/Unsqueeze\"](%/transformer/decoder/Mul_output_0, %/transformer/decoder/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:51:0\n  %/transformer/decoder/Constant_7_output_0 : Float(128, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/transformer/decoder/Constant_7\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:51:0\n  %/transformer/decoder/Div_output_0 : Float(1, *, 128, strides=[38400, 128, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/Div\"](%/transformer/decoder/Unsqueeze_output_0, %/transformer/decoder/Constant_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:51:0\n  %/transformer/decoder/Constant_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_8\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:52:0\n  %/transformer/decoder/Unsqueeze_1_output_0 : Float(1, *, 1, strides=[300, 1, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/Unsqueeze_1\"](%/transformer/decoder/Mul_1_output_0, %/transformer/decoder/Constant_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:52:0\n  %/transformer/decoder/Constant_9_output_0 : Float(128, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/transformer/decoder/Constant_9\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:52:0\n  %/transformer/decoder/Div_1_output_0 : Float(1, *, 128, strides=[38400, 128, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/Div_1\"](%/transformer/decoder/Unsqueeze_1_output_0, %/transformer/decoder/Constant_9_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:52:0\n  %/transformer/decoder/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_10\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/Constant_11\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/decoder/Constant_12\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_13\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Slice_1_output_0 : Float(1, *, 64, strides=[38400, 128, 2], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/Slice_1\"](%/transformer/decoder/Div_output_0, %/transformer/decoder/Constant_11_output_0, %/transformer/decoder/Constant_12_output_0, %/transformer/decoder/Constant_10_output_0, %/transformer/decoder/Constant_13_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Sin_output_0 : Float(1, *, 64, strides=[19200, 64, 1], requires_grad=1, device=cpu) = onnx::Sin[onnx_name=\"/transformer/decoder/Sin\"](%/transformer/decoder/Slice_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_14\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/Constant_15\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/decoder/Constant_16\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_17\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Slice_2_output_0 : Float(1, *, 64, strides=[38400, 128, 2], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/Slice_2\"](%/transformer/decoder/Div_output_0, %/transformer/decoder/Constant_15_output_0, %/transformer/decoder/Constant_16_output_0, %/transformer/decoder/Constant_14_output_0, %/transformer/decoder/Constant_17_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Cos_output_0 : Float(1, *, 64, strides=[19200, 64, 1], requires_grad=1, device=cpu) = onnx::Cos[onnx_name=\"/transformer/decoder/Cos\"](%/transformer/decoder/Slice_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/Constant_18\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Unsqueeze_2_output_0 : Float(1, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/Unsqueeze_2\"](%/transformer/decoder/Sin_output_0, %/transformer/decoder/Constant_18_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/Constant_19\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Unsqueeze_3_output_0 : Float(1, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/Unsqueeze_3\"](%/transformer/decoder/Cos_output_0, %/transformer/decoder/Constant_19_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Concat_output_0 : Float(1, *, 64, 2, strides=[38400, 128, 2, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=3, onnx_name=\"/transformer/decoder/Concat\"](%/transformer/decoder/Unsqueeze_2_output_0, %/transformer/decoder/Unsqueeze_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/Shape\"](%/transformer/decoder/Concat_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Constant_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/Constant_20\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/Constant_21\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_22\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Slice_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/Slice_3\"](%/transformer/decoder/Shape_output_0, %/transformer/decoder/Constant_21_output_0, %/transformer/decoder/Constant_22_output_0, %/transformer/decoder/Constant_20_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/Constant_23\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/Concat_1\"](%/transformer/decoder/Slice_3_output_0, %/transformer/decoder/Constant_23_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Reshape_output_0 : Float(*, *, *, strides=[38400, 128, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/Reshape\"](%/transformer/decoder/Concat_output_0, %/transformer/decoder/Concat_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:53:0\n  %/transformer/decoder/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_24\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/Constant_25\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/decoder/Constant_26\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_27\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Slice_4_output_0 : Float(1, *, 64, strides=[38400, 128, 2], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/Slice_4\"](%/transformer/decoder/Div_1_output_0, %/transformer/decoder/Constant_25_output_0, %/transformer/decoder/Constant_26_output_0, %/transformer/decoder/Constant_24_output_0, %/transformer/decoder/Constant_27_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Sin_1_output_0 : Float(1, *, 64, strides=[19200, 64, 1], requires_grad=1, device=cpu) = onnx::Sin[onnx_name=\"/transformer/decoder/Sin_1\"](%/transformer/decoder/Slice_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_28\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/Constant_29\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/decoder/Constant_30\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_31\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Slice_5_output_0 : Float(1, *, 64, strides=[38400, 128, 2], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/Slice_5\"](%/transformer/decoder/Div_1_output_0, %/transformer/decoder/Constant_29_output_0, %/transformer/decoder/Constant_30_output_0, %/transformer/decoder/Constant_28_output_0, %/transformer/decoder/Constant_31_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Cos_1_output_0 : Float(1, *, 64, strides=[19200, 64, 1], requires_grad=1, device=cpu) = onnx::Cos[onnx_name=\"/transformer/decoder/Cos_1\"](%/transformer/decoder/Slice_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Constant_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/Constant_32\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Unsqueeze_4_output_0 : Float(1, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/Unsqueeze_4\"](%/transformer/decoder/Sin_1_output_0, %/transformer/decoder/Constant_32_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/Constant_33\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Unsqueeze_5_output_0 : Float(1, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/Unsqueeze_5\"](%/transformer/decoder/Cos_1_output_0, %/transformer/decoder/Constant_33_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Concat_2_output_0 : Float(1, *, 64, 2, strides=[38400, 128, 2, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=3, onnx_name=\"/transformer/decoder/Concat_2\"](%/transformer/decoder/Unsqueeze_4_output_0, %/transformer/decoder/Unsqueeze_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/Shape_1\"](%/transformer/decoder/Concat_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/Constant_34\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/Constant_35\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_36\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Slice_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/Slice_6\"](%/transformer/decoder/Shape_1_output_0, %/transformer/decoder/Constant_35_output_0, %/transformer/decoder/Constant_36_output_0, %/transformer/decoder/Constant_34_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/Constant_37\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Concat_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/Concat_3\"](%/transformer/decoder/Slice_6_output_0, %/transformer/decoder/Constant_37_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Reshape_1_output_0 : Float(*, *, *, strides=[38400, 128, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/Reshape_1\"](%/transformer/decoder/Concat_2_output_0, %/transformer/decoder/Concat_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:54:0\n  %/transformer/decoder/Gather_2_output_0 : Float(1, *, strides=[1200, 4], requires_grad=1, device=cpu) = onnx::Gather[axis=2, onnx_name=\"/transformer/decoder/Gather_2\"](%/transformer/decoder/Slice_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:58:0\n  %/transformer/decoder/Constant_38_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name=\"/transformer/decoder/Constant_38\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:58:0\n  %/transformer/decoder/Mul_2_output_0 : Float(1, *, strides=[300, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/Mul_2\"](%/transformer/decoder/Gather_2_output_0, %/transformer/decoder/Constant_38_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:58:0\n  %/transformer/decoder/Constant_39_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_39\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:59:0\n  %/transformer/decoder/Unsqueeze_6_output_0 : Float(1, *, 1, strides=[300, 1, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/Unsqueeze_6\"](%/transformer/decoder/Mul_2_output_0, %/transformer/decoder/Constant_39_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:59:0\n  %/transformer/decoder/Constant_40_output_0 : Float(128, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/transformer/decoder/Constant_40\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:59:0\n  %/transformer/decoder/Div_2_output_0 : Float(1, *, 128, strides=[38400, 128, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/Div_2\"](%/transformer/decoder/Unsqueeze_6_output_0, %/transformer/decoder/Constant_40_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:59:0\n  %/transformer/decoder/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_41\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Constant_42_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/Constant_42\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/decoder/Constant_43\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_44\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Slice_7_output_0 : Float(1, *, 64, strides=[38400, 128, 2], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/Slice_7\"](%/transformer/decoder/Div_2_output_0, %/transformer/decoder/Constant_42_output_0, %/transformer/decoder/Constant_43_output_0, %/transformer/decoder/Constant_41_output_0, %/transformer/decoder/Constant_44_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Sin_2_output_0 : Float(1, *, 64, strides=[19200, 64, 1], requires_grad=1, device=cpu) = onnx::Sin[onnx_name=\"/transformer/decoder/Sin_2\"](%/transformer/decoder/Slice_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_45\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/Constant_46\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/decoder/Constant_47\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Constant_48_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_48\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Slice_8_output_0 : Float(1, *, 64, strides=[38400, 128, 2], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/Slice_8\"](%/transformer/decoder/Div_2_output_0, %/transformer/decoder/Constant_46_output_0, %/transformer/decoder/Constant_47_output_0, %/transformer/decoder/Constant_45_output_0, %/transformer/decoder/Constant_48_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Cos_2_output_0 : Float(1, *, 64, strides=[19200, 64, 1], requires_grad=1, device=cpu) = onnx::Cos[onnx_name=\"/transformer/decoder/Cos_2\"](%/transformer/decoder/Slice_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Constant_49_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/Constant_49\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Unsqueeze_7_output_0 : Float(1, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/Unsqueeze_7\"](%/transformer/decoder/Sin_2_output_0, %/transformer/decoder/Constant_49_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Constant_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/Constant_50\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Unsqueeze_8_output_0 : Float(1, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/Unsqueeze_8\"](%/transformer/decoder/Cos_2_output_0, %/transformer/decoder/Constant_50_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Concat_4_output_0 : Float(1, *, 64, 2, strides=[38400, 128, 2, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=3, onnx_name=\"/transformer/decoder/Concat_4\"](%/transformer/decoder/Unsqueeze_7_output_0, %/transformer/decoder/Unsqueeze_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/Shape_2\"](%/transformer/decoder/Concat_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Constant_51_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/Constant_51\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Constant_52_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/Constant_52\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Constant_53_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_53\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Slice_9_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/Slice_9\"](%/transformer/decoder/Shape_2_output_0, %/transformer/decoder/Constant_52_output_0, %/transformer/decoder/Constant_53_output_0, %/transformer/decoder/Constant_51_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Constant_54_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/Constant_54\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Concat_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/Concat_5\"](%/transformer/decoder/Slice_9_output_0, %/transformer/decoder/Constant_54_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Reshape_2_output_0 : Float(*, *, *, strides=[38400, 128, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/Reshape_2\"](%/transformer/decoder/Concat_4_output_0, %/transformer/decoder/Concat_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:60:0\n  %/transformer/decoder/Gather_3_output_0 : Float(1, *, strides=[1200, 4], requires_grad=1, device=cpu) = onnx::Gather[axis=2, onnx_name=\"/transformer/decoder/Gather_3\"](%/transformer/decoder/Slice_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:62:0\n  %/transformer/decoder/Constant_55_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name=\"/transformer/decoder/Constant_55\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:62:0\n  %/transformer/decoder/Mul_3_output_0 : Float(1, *, strides=[300, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/Mul_3\"](%/transformer/decoder/Gather_3_output_0, %/transformer/decoder/Constant_55_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:62:0\n  %/transformer/decoder/Constant_56_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_56\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:63:0\n  %/transformer/decoder/Unsqueeze_9_output_0 : Float(1, *, 1, strides=[300, 1, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/Unsqueeze_9\"](%/transformer/decoder/Mul_3_output_0, %/transformer/decoder/Constant_56_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:63:0\n  %/transformer/decoder/Constant_57_output_0 : Float(128, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/transformer/decoder/Constant_57\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:63:0\n  %/transformer/decoder/Div_3_output_0 : Float(1, *, 128, strides=[38400, 128, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/Div_3\"](%/transformer/decoder/Unsqueeze_9_output_0, %/transformer/decoder/Constant_57_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:63:0\n  %/transformer/decoder/Constant_58_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_58\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Constant_59_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/Constant_59\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Constant_60_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/decoder/Constant_60\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Constant_61_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_61\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Slice_10_output_0 : Float(1, *, 64, strides=[38400, 128, 2], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/Slice_10\"](%/transformer/decoder/Div_3_output_0, %/transformer/decoder/Constant_59_output_0, %/transformer/decoder/Constant_60_output_0, %/transformer/decoder/Constant_58_output_0, %/transformer/decoder/Constant_61_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Sin_3_output_0 : Float(1, *, 64, strides=[19200, 64, 1], requires_grad=1, device=cpu) = onnx::Sin[onnx_name=\"/transformer/decoder/Sin_3\"](%/transformer/decoder/Slice_10_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Constant_62_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_62\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Constant_63_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/Constant_63\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Constant_64_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/decoder/Constant_64\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Constant_65_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_65\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Slice_11_output_0 : Float(1, *, 64, strides=[38400, 128, 2], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/Slice_11\"](%/transformer/decoder/Div_3_output_0, %/transformer/decoder/Constant_63_output_0, %/transformer/decoder/Constant_64_output_0, %/transformer/decoder/Constant_62_output_0, %/transformer/decoder/Constant_65_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Cos_3_output_0 : Float(1, *, 64, strides=[19200, 64, 1], requires_grad=1, device=cpu) = onnx::Cos[onnx_name=\"/transformer/decoder/Cos_3\"](%/transformer/decoder/Slice_11_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Constant_66_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/Constant_66\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Unsqueeze_10_output_0 : Float(1, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/Unsqueeze_10\"](%/transformer/decoder/Sin_3_output_0, %/transformer/decoder/Constant_66_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Constant_67_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/Constant_67\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Unsqueeze_11_output_0 : Float(1, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/Unsqueeze_11\"](%/transformer/decoder/Cos_3_output_0, %/transformer/decoder/Constant_67_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Concat_6_output_0 : Float(1, *, 64, 2, strides=[38400, 128, 2, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=3, onnx_name=\"/transformer/decoder/Concat_6\"](%/transformer/decoder/Unsqueeze_10_output_0, %/transformer/decoder/Unsqueeze_11_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/Shape_3\"](%/transformer/decoder/Concat_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Constant_68_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/Constant_68\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Constant_69_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/Constant_69\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Constant_70_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_70\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Slice_12_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/Slice_12\"](%/transformer/decoder/Shape_3_output_0, %/transformer/decoder/Constant_69_output_0, %/transformer/decoder/Constant_70_output_0, %/transformer/decoder/Constant_68_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Constant_71_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/Constant_71\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Concat_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/Concat_7\"](%/transformer/decoder/Slice_12_output_0, %/transformer/decoder/Constant_71_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Reshape_3_output_0 : Float(*, *, *, strides=[38400, 128, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/Reshape_3\"](%/transformer/decoder/Concat_6_output_0, %/transformer/decoder/Concat_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:64:0\n  %/transformer/decoder/Concat_8_output_0 : Float(*, *, *, strides=[153600, 512, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=2, onnx_name=\"/transformer/decoder/Concat_8\"](%/transformer/decoder/Reshape_1_output_0, %/transformer/decoder/Reshape_output_0, %/transformer/decoder/Reshape_2_output_0, %/transformer/decoder/Reshape_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:66:0\n  %/transformer/decoder/Constant_72_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/Constant_72\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:365:0\n  %/transformer/decoder/Unsqueeze_12_output_0 : Float(1, *, 1, 4, strides=[1200, 4, 4, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/Unsqueeze_12\"](%/transformer/decoder/Slice_output_0, %/transformer/decoder/Constant_72_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:365:0\n  %/transformer/decoder/ref_point_head/layers.0/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/ref_point_head/layers.0/MatMul\"](%/transformer/decoder/Concat_8_output_0, %onnx::MatMul_4858), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.MLP::ref_point_head/torch.nn.modules.linear.Linear::layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/ref_point_head/layers.0/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/ref_point_head/layers.0/Add\"](%transformer.decoder.ref_point_head.layers.0.bias, %/transformer/decoder/ref_point_head/layers.0/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.MLP::ref_point_head/torch.nn.modules.linear.Linear::layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/ref_point_head/Relu_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/transformer/decoder/ref_point_head/Relu\"](%/transformer/decoder/ref_point_head/layers.0/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.MLP::ref_point_head # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n  %/transformer/decoder/ref_point_head/layers.1/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/ref_point_head/layers.1/MatMul\"](%/transformer/decoder/ref_point_head/Relu_output_0, %onnx::MatMul_4859), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.MLP::ref_point_head/torch.nn.modules.linear.Linear::layers.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/ref_point_head/layers.1/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/ref_point_head/layers.1/Add\"](%transformer.decoder.ref_point_head.layers.1.bias, %/transformer/decoder/ref_point_head/layers.1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.MLP::ref_point_head/torch.nn.modules.linear.Linear::layers.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.0/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/Add\"](%/transformer/Tile_1_output_0, %/transformer/decoder/ref_point_head/layers.1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:499:0\n  %/transformer/decoder/layers.0/self_attn/Transpose_output_0 : Float(*, *, 256, strides=[256, 76800, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.0/self_attn/Transpose\"](%/transformer/decoder/layers.0/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1344:0\n  %/transformer/decoder/layers.0/self_attn/Transpose_1_output_0 : Float(300, 1, 256, strides=[256, 76800, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.0/self_attn/Transpose_1\"](%/transformer/Tile_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1344:0\n  %/transformer/decoder/layers.0/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.0/self_attn/Shape\"](%/transformer/decoder/layers.0/self_attn/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.0/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.0/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Gather\"](%/transformer/decoder/layers.0/self_attn/Shape_output_0, %/transformer/decoder/layers.0/self_attn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.0/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.0/self_attn/Shape_1\"](%/transformer/decoder/layers.0/self_attn/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.0/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.0/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Gather_1\"](%/transformer/decoder/layers.0/self_attn/Shape_1_output_0, %/transformer/decoder/layers.0/self_attn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.0/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.0/self_attn/Shape_2\"](%/transformer/decoder/layers.0/self_attn/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.0/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.0/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Gather_2\"](%/transformer/decoder/layers.0/self_attn/Shape_2_output_0, %/transformer/decoder/layers.0/self_attn/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.0/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.0/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/layers.0/self_attn/Div\"](%/transformer/decoder/layers.0/self_attn/Gather_2_output_0, %/transformer/decoder/layers.0/self_attn/Constant_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.0/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/transformer/decoder/layers.0/self_attn/Cast\"](%/transformer/decoder/layers.0/self_attn/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.0/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/transformer/decoder/layers.0/self_attn/Cast_1\"](%/transformer/decoder/layers.0/self_attn/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.0/self_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.0/self_attn/MatMul\"](%/transformer/decoder/layers.0/self_attn/Transpose_output_0, %onnx::MatMul_4880), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.0/self_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/self_attn/Add\"](%onnx::Add_4875, %/transformer/decoder/layers.0/self_attn/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.0/self_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.0/self_attn/MatMul_1\"](%/transformer/decoder/layers.0/self_attn/Transpose_output_0, %onnx::MatMul_4881), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.0/self_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/self_attn/Add_1\"](%onnx::Add_4877, %/transformer/decoder/layers.0/self_attn/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.0/self_attn/MatMul_2_output_0 : Float(300, 1, 256, strides=[256, 256, 1], device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.0/self_attn/MatMul_2\"](%/transformer/decoder/layers.0/self_attn/Transpose_1_output_0, %onnx::MatMul_4882), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.0/self_attn/Add_2_output_0 : Float(300, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/self_attn/Add_2\"](%onnx::Add_4879, %/transformer/decoder/layers.0/self_attn/MatMul_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.0/self_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.0/self_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.0/self_attn/Mul\"](%/transformer/decoder/layers.0/self_attn/Gather_1_output_0, %/transformer/decoder/layers.0/self_attn/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %onnx::Unsqueeze_2848 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze\"](%/transformer/decoder/layers.0/self_attn/Gather_output_0, %onnx::Unsqueeze_2848), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2850 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_1\"](%/transformer/decoder/layers.0/self_attn/Mul_output_0, %onnx::Unsqueeze_2850), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2852 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_2\"](%/transformer/decoder/layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_2852), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.0/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Concat\"](%/transformer/decoder/layers.0/self_attn/Unsqueeze_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_1_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.0/self_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Reshape\"](%/transformer/decoder/layers.0/self_attn/Add_output_0, %/transformer/decoder/layers.0/self_attn/Concat_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.0/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.0/self_attn/Transpose_2\"](%/transformer/decoder/layers.0/self_attn/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.0/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.0/self_attn/Shape_3\"](%/transformer/decoder/layers.0/self_attn/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.0/self_attn/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.0/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Gather_3\"](%/transformer/decoder/layers.0/self_attn/Shape_3_output_0, %/transformer/decoder/layers.0/self_attn/Constant_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %onnx::Unsqueeze_2860 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_3\"](%/transformer/decoder/layers.0/self_attn/Gather_3_output_0, %onnx::Unsqueeze_2860), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2862 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_4\"](%/transformer/decoder/layers.0/self_attn/Mul_output_0, %onnx::Unsqueeze_2862), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2864 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_5\"](%/transformer/decoder/layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_2864), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.0/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Concat_1\"](%/transformer/decoder/layers.0/self_attn/Unsqueeze_3_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_4_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.0/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Reshape_1\"](%/transformer/decoder/layers.0/self_attn/Add_1_output_0, %/transformer/decoder/layers.0/self_attn/Concat_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.0/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.0/self_attn/Transpose_3\"](%/transformer/decoder/layers.0/self_attn/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.0/self_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={300}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2872 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_6\"](%/transformer/decoder/layers.0/self_attn/Mul_output_0, %onnx::Unsqueeze_2872), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2874 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_7\"](%/transformer/decoder/layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_2874), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.0/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Concat_2\"](%/transformer/decoder/layers.0/self_attn/Constant_6_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_6_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.0/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Reshape_2\"](%/transformer/decoder/layers.0/self_attn/Add_2_output_0, %/transformer/decoder/layers.0/self_attn/Concat_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.0/self_attn/Transpose_4_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.0/self_attn/Transpose_4\"](%/transformer/decoder/layers.0/self_attn/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.0/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.0/self_attn/Shape_4\"](%/transformer/decoder/layers.0/self_attn/Transpose_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n  %/transformer/decoder/layers.0/self_attn/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant_7\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n  %/transformer/decoder/layers.0/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Gather_4\"](%/transformer/decoder/layers.0/self_attn/Shape_4_output_0, %/transformer/decoder/layers.0/self_attn/Constant_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n  %onnx::Unsqueeze_2883 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_8\"](%/transformer/decoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2883), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.0/self_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant_8\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2887 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_9\"](%/transformer/decoder/layers.0/self_attn/Gather_output_0, %onnx::Unsqueeze_2887), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2889 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_10\"](%/transformer/decoder/layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_2889), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.0/self_attn/Concat_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Concat_3\"](%/transformer/decoder/layers.0/self_attn/Unsqueeze_8_output_0, %/transformer/decoder/layers.0/self_attn/Constant_8_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_9_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_10_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n  %/transformer/decoder/layers.0/self_attn/Reshape_3_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Reshape_3\"](%/transformer/decoder/layers.0/self_attn/Transpose_2_output_0, %/transformer/decoder/layers.0/self_attn/Concat_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n  %onnx::Unsqueeze_2893 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_11\"](%/transformer/decoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2893), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.0/self_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant_9\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2897 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_12\"](%/transformer/decoder/layers.0/self_attn/Gather_4_output_0, %onnx::Unsqueeze_2897), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2899 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_13\"](%/transformer/decoder/layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_2899), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.0/self_attn/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Concat_4\"](%/transformer/decoder/layers.0/self_attn/Unsqueeze_11_output_0, %/transformer/decoder/layers.0/self_attn/Constant_9_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_12_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_13_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n  %onnx::Unsqueeze_2902 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_14\"](%/transformer/decoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2902), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.0/self_attn/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant_10\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2906 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_15\"](%/transformer/decoder/layers.0/self_attn/Gather_4_output_0, %onnx::Unsqueeze_2906), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2908 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_16\"](%/transformer/decoder/layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_2908), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.0/self_attn/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Concat_5\"](%/transformer/decoder/layers.0/self_attn/Unsqueeze_14_output_0, %/transformer/decoder/layers.0/self_attn/Constant_10_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_15_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_16_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n  %/transformer/decoder/layers.0/self_attn/Reshape_4_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Reshape_4\"](%/transformer/decoder/layers.0/self_attn/Transpose_3_output_0, %/transformer/decoder/layers.0/self_attn/Concat_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n  %/transformer/decoder/layers.0/self_attn/Reshape_5_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Reshape_5\"](%/transformer/decoder/layers.0/self_attn/Transpose_4_output_0, %/transformer/decoder/layers.0/self_attn/Concat_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n  %/transformer/decoder/layers.0/self_attn/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.0/self_attn/Shape_5\"](%/transformer/decoder/layers.0/self_attn/Reshape_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant_11\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant_12\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.0/self_attn/Slice\"](%/transformer/decoder/layers.0/self_attn/Shape_5_output_0, %/transformer/decoder/layers.0/self_attn/Constant_11_output_0, %/transformer/decoder/layers.0/self_attn/Constant_12_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Cast_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/decoder/layers.0/self_attn/Cast_2\"](%/transformer/decoder/layers.0/self_attn/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/transformer/decoder/layers.0/self_attn/Sqrt\"](%/transformer/decoder/layers.0/self_attn/Cast_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Constant_13_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant_13\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Div_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/layers.0/self_attn/Div_1\"](%/transformer/decoder/layers.0/self_attn/Constant_13_output_0, %/transformer/decoder/layers.0/self_attn/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Cast_3_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/decoder/layers.0/self_attn/Cast_3\"](%/transformer/decoder/layers.0/self_attn/Div_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Transpose_5_output_0 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/transformer/decoder/layers.0/self_attn/Transpose_5\"](%/transformer/decoder/layers.0/self_attn/Reshape_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/transformer/decoder/layers.0/self_attn/Sqrt_1\"](%/transformer/decoder/layers.0/self_attn/Cast_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Mul_1_output_0 : Float(*, *, *, *, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.0/self_attn/Mul_1\"](%/transformer/decoder/layers.0/self_attn/Reshape_3_output_0, %/transformer/decoder/layers.0/self_attn/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/transformer/decoder/layers.0/self_attn/Sqrt_2\"](%/transformer/decoder/layers.0/self_attn/Cast_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Mul_2_output_0 : Float(*, *, *, *, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.0/self_attn/Mul_2\"](%/transformer/decoder/layers.0/self_attn/Transpose_5_output_0, %/transformer/decoder/layers.0/self_attn/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/MatMul_3_output_0 : Float(*, *, *, *, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.0/self_attn/MatMul_3\"](%/transformer/decoder/layers.0/self_attn/Mul_1_output_0, %/transformer/decoder/layers.0/self_attn/Mul_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Softmax_output_0 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/transformer/decoder/layers.0/self_attn/Softmax\"](%/transformer/decoder/layers.0/self_attn/MatMul_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/MatMul_4_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.0/self_attn/MatMul_4\"](%/transformer/decoder/layers.0/self_attn/Softmax_output_0, %/transformer/decoder/layers.0/self_attn/Reshape_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.0/self_attn/Transpose_6_output_0 : Float(*, *, *, *, strides=[256, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[2, 0, 1, 3], onnx_name=\"/transformer/decoder/layers.0/self_attn/Transpose_6\"](%/transformer/decoder/layers.0/self_attn/MatMul_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %/transformer/decoder/layers.0/self_attn/Mul_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.0/self_attn/Mul_3\"](%/transformer/decoder/layers.0/self_attn/Gather_1_output_0, %/transformer/decoder/layers.0/self_attn/Gather_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %onnx::Unsqueeze_2932 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_17\"](%/transformer/decoder/layers.0/self_attn/Mul_3_output_0, %onnx::Unsqueeze_2932), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2934 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_18\"](%/transformer/decoder/layers.0/self_attn/Gather_2_output_0, %onnx::Unsqueeze_2934), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.0/self_attn/Concat_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Concat_6\"](%/transformer/decoder/layers.0/self_attn/Unsqueeze_17_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_18_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %/transformer/decoder/layers.0/self_attn/Reshape_6_output_0 : Float(*, *, strides=[256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Reshape_6\"](%/transformer/decoder/layers.0/self_attn/Transpose_6_output_0, %/transformer/decoder/layers.0/self_attn/Concat_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %/transformer/decoder/layers.0/self_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/transformer/decoder/layers.0/self_attn/Gemm\"](%/transformer/decoder/layers.0/self_attn/Reshape_6_output_0, %transformer.decoder.layers.0.self_attn.out_proj.weight, %transformer.decoder.layers.0.self_attn.out_proj.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6417:0\n  %/transformer/decoder/layers.0/self_attn/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.0/self_attn/Shape_6\"](%/transformer/decoder/layers.0/self_attn/Gemm_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.0/self_attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/self_attn/Constant_14\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.0/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Gather_5\"](%/transformer/decoder/layers.0/self_attn/Shape_6_output_0, %/transformer/decoder/layers.0/self_attn/Constant_14_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %onnx::Unsqueeze_2942 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_19\"](%/transformer/decoder/layers.0/self_attn/Gather_output_0, %onnx::Unsqueeze_2942), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2944 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_20\"](%/transformer/decoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2944), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_2946 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/self_attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/self_attn/Unsqueeze_21\"](%/transformer/decoder/layers.0/self_attn/Gather_5_output_0, %onnx::Unsqueeze_2946), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.0/self_attn/Concat_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Concat_7\"](%/transformer/decoder/layers.0/self_attn/Unsqueeze_19_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_20_output_0, %/transformer/decoder/layers.0/self_attn/Unsqueeze_21_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.0/self_attn/Reshape_7_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/self_attn/Reshape_7\"](%/transformer/decoder/layers.0/self_attn/Gemm_output_0, %/transformer/decoder/layers.0/self_attn/Concat_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.0/self_attn/Transpose_7_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.0/self_attn/Transpose_7\"](%/transformer/decoder/layers.0/self_attn/Reshape_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1395:0\n  %/transformer/decoder/layers.0/Add_1_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/Add_1\"](%/transformer/Tile_1_output_0, %/transformer/decoder/layers.0/self_attn/Transpose_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:514:0\n  %/transformer/decoder/layers.0/norm1/LayerNormalization_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/transformer/decoder/layers.0/norm1/LayerNormalization\"](%/transformer/decoder/layers.0/Add_1_output_0, %transformer.decoder.layers.0.norm1.weight, %transformer.decoder.layers.0.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/transformer/decoder/layers.0/Add_2_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/Add_2\"](%/transformer/decoder/layers.0/norm1/LayerNormalization_output_0, %/transformer/decoder/ref_point_head/layers.1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:479:0\n  %/transformer/decoder/layers.0/cross_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Shape\"](%/transformer/decoder/layers.0/Add_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:112:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:112:0\n  %/transformer/decoder/layers.0/cross_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Gather\"](%/transformer/decoder/layers.0/cross_attn/Shape_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:112:0\n  %/transformer/decoder/layers.0/cross_attn/value_proj/MatMul_output_0 : Float(1, 1296, 256, strides=[331776, 256, 1], device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.0/cross_attn/value_proj/MatMul\"](%/transformer/Concat_1_output_0, %onnx::MatMul_4887), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::value_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.0/cross_attn/value_proj/Add_output_0 : Float(1, 1296, 256, strides=[331776, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/cross_attn/value_proj/Add\"](%transformer.decoder.layers.0.cross_attn.value_proj.bias, %/transformer/decoder/layers.0/cross_attn/value_proj/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::value_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.0/cross_attn/sampling_offsets/MatMul_output_0 : Float(*, *, 64, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.0/cross_attn/sampling_offsets/MatMul\"](%/transformer/decoder/layers.0/Add_2_output_0, %onnx::MatMul_4888), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::sampling_offsets # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.0/cross_attn/sampling_offsets/Add_output_0 : Float(*, *, 64, strides=[19200, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/cross_attn/sampling_offsets/Add\"](%transformer.decoder.layers.0.cross_attn.sampling_offsets.bias, %/transformer/decoder/layers.0/cross_attn/sampling_offsets/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::sampling_offsets # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_1_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_2967 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/cross_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Unsqueeze\"](%/transformer/decoder/layers.0/cross_attn/Gather_output_0, %onnx::Unsqueeze_2967), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.0/cross_attn/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.0/cross_attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.0/cross_attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.0/cross_attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.0/cross_attn/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Concat\"](%/transformer/decoder/layers.0/cross_attn/Constant_1_output_0, %/transformer/decoder/layers.0/cross_attn/Unsqueeze_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_2_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_3_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_4_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:120:0\n  %/transformer/decoder/layers.0/cross_attn/Reshape_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Reshape\"](%/transformer/decoder/layers.0/cross_attn/sampling_offsets/Add_output_0, %/transformer/decoder/layers.0/cross_attn/Concat_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:120:0\n  %/transformer/decoder/layers.0/cross_attn/attention_weights/MatMul_output_0 : Float(*, *, 32, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.0/cross_attn/attention_weights/MatMul\"](%/transformer/decoder/layers.0/Add_2_output_0, %onnx::MatMul_4894), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::attention_weights # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.0/cross_attn/attention_weights/Add_output_0 : Float(*, *, 32, strides=[9600, 32, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/cross_attn/attention_weights/Add\"](%transformer.decoder.layers.0.cross_attn.attention_weights.bias, %/transformer/decoder/layers.0/cross_attn/attention_weights/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::attention_weights # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_2984 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/cross_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Unsqueeze_1\"](%/transformer/decoder/layers.0/cross_attn/Gather_output_0, %onnx::Unsqueeze_2984), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.0/cross_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_7\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.0/cross_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_8\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.0/cross_attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Concat_1\"](%/transformer/decoder/layers.0/cross_attn/Constant_6_output_0, %/transformer/decoder/layers.0/cross_attn/Unsqueeze_1_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_7_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:121:0\n  %/transformer/decoder/layers.0/cross_attn/Reshape_1_output_0 : Float(1, *, 16, 2, strides=[9600, 32, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Reshape_1\"](%/transformer/decoder/layers.0/cross_attn/attention_weights/Add_output_0, %/transformer/decoder/layers.0/cross_attn/Concat_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:121:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_9\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:129:0\n  %/transformer/decoder/layers.0/cross_attn/Unsqueeze_2_output_0 : Float(1, *, 1, 1, 4, strides=[1200, 4, 4, 4, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Unsqueeze_2\"](%/transformer/decoder/Unsqueeze_12_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_9_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:129:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_10\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:129:0\n  %/transformer/decoder/layers.0/cross_attn/Unsqueeze_3_output_0 : Float(1, *, 1, 1, 1, 4, strides=[1200, 4, 4, 4, 4, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Unsqueeze_3\"](%/transformer/decoder/layers.0/cross_attn/Unsqueeze_2_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_10_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:129:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_11\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:129:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_12\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:129:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_13\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:129:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_14\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:129:0\n  %/transformer/decoder/layers.0/cross_attn/Slice_output_0 : Float(1, *, 1, 1, 1, 2, strides=[1200, 4, 4, 4, 4, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Slice\"](%/transformer/decoder/layers.0/cross_attn/Unsqueeze_3_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_12_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_13_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_11_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_14_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:129:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_15\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.0/cross_attn/Div_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Div\"](%/transformer/decoder/layers.0/cross_attn/Reshape_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_15_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_16\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_17\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_18_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_18\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_19\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.0/cross_attn/Slice_1_output_0 : Float(1, *, 1, 1, 1, 2, strides=[1200, 4, 4, 4, 4, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Slice_1\"](%/transformer/decoder/layers.0/cross_attn/Unsqueeze_3_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_17_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_18_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_16_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_19_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.0/cross_attn/Mul_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Mul\"](%/transformer/decoder/layers.0/cross_attn/Div_output_0, %/transformer/decoder/layers.0/cross_attn/Slice_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_20_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_20\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.0/cross_attn/Mul_1_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Mul_1\"](%/transformer/decoder/layers.0/cross_attn/Mul_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_20_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.0/cross_attn/Add_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Add\"](%/transformer/decoder/layers.0/cross_attn/Slice_output_0, %/transformer/decoder/layers.0/cross_attn/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:129:0\n  %/transformer/decoder/layers.0/cross_attn/Softmax_output_0 : Float(1, *, 16, 2, strides=[9600, 32, 2, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Softmax\"](%/transformer/decoder/layers.0/cross_attn/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2140:0\n  %/transformer/decoder/layers.0/cross_attn/Transpose_output_0 : Float(1, 256, 1296, strides=[331776, 1296, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/transformer/decoder/layers.0/cross_attn/Transpose\"](%/transformer/decoder/layers.0/cross_attn/value_proj/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:136:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_21_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1    16    16  1296 [ CPULongType{4} ], onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_21\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:136:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1    16    16  1296 [ CPULongType{4} ], onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:136:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1    16    16  1296 [ CPULongType{4} ], onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:136:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=    1    16    16  1296 [ CPULongType{4} ], onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:136:0\n  %/transformer/decoder/layers.0/cross_attn/Reshape_2_output_0 : Float(1, 16, 16, 1296, strides=[331776, 20736, 1296, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Reshape_2\"](%/transformer/decoder/layers.0/cross_attn/Transpose_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_21_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:136:0\n  %/transformer/decoder/layers.0/cross_attn/Shape_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Shape_1\"](%/transformer/decoder/layers.0/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_22_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_22\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.0/cross_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Gather_1\"](%/transformer/decoder/layers.0/cross_attn/Shape_1_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_22_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.0/cross_attn/Shape_2_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Shape_2\"](%/transformer/decoder/layers.0/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_23_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_23\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.0/cross_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Gather_2\"](%/transformer/decoder/layers.0/cross_attn/Shape_2_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_23_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.0/cross_attn/Shape_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Shape_3\"](%/transformer/decoder/layers.0/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_24\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.0/cross_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Gather_3\"](%/transformer/decoder/layers.0/cross_attn/Shape_3_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_24_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.0/cross_attn/Shape_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Shape_4\"](%/transformer/decoder/layers.0/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={4}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_25\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.0/cross_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Gather_4\"](%/transformer/decoder/layers.0/cross_attn/Shape_4_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_25_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_26\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Split_output_0 : Long(1, 2, strides=[2, 1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Split\"](%/transformer/Constant_4_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_26_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_27\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Squeeze_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Squeeze\"](%/transformer/decoder/layers.0/cross_attn/Split_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_27_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_28_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 1  1 [ CPULongType{2} ], onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_28\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Split_1_output_0 : Long(1, strides=[1], device=cpu), %/transformer/decoder/layers.0/cross_attn/Split_1_output_1 : Long(1, strides=[1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Split_1\"](%/transformer/decoder/layers.0/cross_attn/Squeeze_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_28_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_29\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Squeeze_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Squeeze_1\"](%/transformer/decoder/layers.0/cross_attn/Split_1_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_29_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_30\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Squeeze_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Squeeze_2\"](%/transformer/decoder/layers.0/cross_attn/Split_1_output_1, %/transformer/decoder/layers.0/cross_attn/Constant_30_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Mul_2\"](%/transformer/decoder/layers.0/cross_attn/Squeeze_1_output_0, %/transformer/decoder/layers.0/cross_attn/Squeeze_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:33:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_31\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.0/cross_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Unsqueeze_4\"](%/transformer/decoder/layers.0/cross_attn/Mul_2_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_31_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_32\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_33\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_34_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_34\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.0/cross_attn/Add_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Add_1\"](%/transformer/decoder/layers.0/cross_attn/Constant_34_output_0, %/transformer/decoder/layers.0/cross_attn/Unsqueeze_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.0/cross_attn/Slice_2_output_0 : Float(1, 16, 16, *, strides=[331776, 20736, 1296, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Slice_2\"](%/transformer/decoder/layers.0/cross_attn/Reshape_2_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_32_output_0, %/transformer/decoder/layers.0/cross_attn/Add_1_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_33_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_35_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_35\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.0/cross_attn/Mul_3_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Mul_3\"](%/transformer/decoder/layers.0/cross_attn/Add_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_35_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_36_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_36\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.0/cross_attn/Sub_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Sub\"](%/transformer/decoder/layers.0/cross_attn/Mul_3_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_36_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_37\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Split_2_output_0 : Long(1, 2, strides=[2, 1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Split_2\"](%/transformer/Constant_4_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_37_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_38\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Squeeze_3_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Squeeze_3\"](%/transformer/decoder/layers.0/cross_attn/Split_2_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_38_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_39_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 1  1 [ CPULongType{2} ], onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_39\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Split_3_output_0 : Long(1, strides=[1], device=cpu), %/transformer/decoder/layers.0/cross_attn/Split_3_output_1 : Long(1, strides=[1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Split_3\"](%/transformer/decoder/layers.0/cross_attn/Squeeze_3_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_39_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_40\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Squeeze_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Squeeze_4\"](%/transformer/decoder/layers.0/cross_attn/Split_3_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_40_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_41_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_41\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Squeeze_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Squeeze_5\"](%/transformer/decoder/layers.0/cross_attn/Split_3_output_1, %/transformer/decoder/layers.0/cross_attn/Constant_41_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_42_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_42\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %/transformer/decoder/layers.0/cross_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Mul_4\"](%/transformer/decoder/layers.0/cross_attn/Constant_42_output_0, %/transformer/decoder/layers.0/cross_attn/Gather_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %onnx::Unsqueeze_3110 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/cross_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Unsqueeze_5\"](%/transformer/decoder/layers.0/cross_attn/Mul_4_output_0, %onnx::Unsqueeze_3110), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.0/cross_attn/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_43\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3114 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/cross_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Unsqueeze_6\"](%/transformer/decoder/layers.0/cross_attn/Squeeze_4_output_0, %onnx::Unsqueeze_3114), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3116 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/cross_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Unsqueeze_7\"](%/transformer/decoder/layers.0/cross_attn/Squeeze_5_output_0, %onnx::Unsqueeze_3116), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.0/cross_attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Concat_2\"](%/transformer/decoder/layers.0/cross_attn/Unsqueeze_5_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_43_output_0, %/transformer/decoder/layers.0/cross_attn/Unsqueeze_6_output_0, %/transformer/decoder/layers.0/cross_attn/Unsqueeze_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %/transformer/decoder/layers.0/cross_attn/Reshape_3_output_0 : Float(*, *, *, *, strides=[20736, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Reshape_3\"](%/transformer/decoder/layers.0/cross_attn/Slice_2_output_0, %/transformer/decoder/layers.0/cross_attn/Concat_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %/transformer/decoder/layers.0/cross_attn/Gather_5_output_0 : Float(1, *, 16, 2, 2, strides=[19200, 64, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=3, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Gather_5\"](%/transformer/decoder/layers.0/cross_attn/Sub_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.0/cross_attn/Transpose_1_output_0 : Float(1, 16, *, 2, 2, strides=[19200, 4, 64, 2, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name=\"/transformer/decoder/layers.0/cross_attn/Transpose_1\"](%/transformer/decoder/layers.0/cross_attn/Gather_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.0/cross_attn/Shape_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Shape_5\"](%/transformer/decoder/layers.0/cross_attn/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_44_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_44\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_45_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_45\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_46\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.0/cross_attn/Slice_3_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Slice_3\"](%/transformer/decoder/layers.0/cross_attn/Shape_5_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_45_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_46_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_44_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_47_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_47\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_48_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_48\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_49_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={5}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_49\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.0/cross_attn/Slice_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Slice_4\"](%/transformer/decoder/layers.0/cross_attn/Shape_5_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_48_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_49_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_47_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_50_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_50\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.0/cross_attn/Concat_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Concat_3\"](%/transformer/decoder/layers.0/cross_attn/Slice_3_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_50_output_0, %/transformer/decoder/layers.0/cross_attn/Slice_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.0/cross_attn/Reshape_4_output_0 : Float(*, *, *, *, strides=[4, 64, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Reshape_4\"](%/transformer/decoder/layers.0/cross_attn/Transpose_1_output_0, %/transformer/decoder/layers.0/cross_attn/Concat_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.0/cross_attn/GridSample_output_0 : Float(*, *, *, *, strides=[9600, 600, 2, 1], requires_grad=1, device=cpu) = onnx::GridSample[align_corners=0, mode=\"bilinear\", padding_mode=\"zeros\", onnx_name=\"/transformer/decoder/layers.0/cross_attn/GridSample\"](%/transformer/decoder/layers.0/cross_attn/Reshape_3_output_0, %/transformer/decoder/layers.0/cross_attn/Reshape_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5023:0\n  %/transformer/decoder/layers.0/cross_attn/Transpose_2_output_0 : Float(1, 16, *, 2, strides=[9600, 2, 32, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/transformer/decoder/layers.0/cross_attn/Transpose_2\"](%/transformer/decoder/layers.0/cross_attn/Softmax_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %/transformer/decoder/layers.0/cross_attn/Mul_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Mul_5\"](%/transformer/decoder/layers.0/cross_attn/Gather_3_output_0, %/transformer/decoder/layers.0/cross_attn/Gather_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %onnx::Unsqueeze_3137 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/cross_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Unsqueeze_8\"](%/transformer/decoder/layers.0/cross_attn/Mul_4_output_0, %onnx::Unsqueeze_3137), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.0/cross_attn/Constant_51_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_51\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3141 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/cross_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Unsqueeze_9\"](%/transformer/decoder/layers.0/cross_attn/Gather_1_output_0, %onnx::Unsqueeze_3141), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3143 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/cross_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Unsqueeze_10\"](%/transformer/decoder/layers.0/cross_attn/Mul_5_output_0, %onnx::Unsqueeze_3143), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.0/cross_attn/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Concat_4\"](%/transformer/decoder/layers.0/cross_attn/Unsqueeze_8_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_51_output_0, %/transformer/decoder/layers.0/cross_attn/Unsqueeze_9_output_0, %/transformer/decoder/layers.0/cross_attn/Unsqueeze_10_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %/transformer/decoder/layers.0/cross_attn/Reshape_5_output_0 : Float(*, *, *, *, strides=[2, 9600, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Reshape_5\"](%/transformer/decoder/layers.0/cross_attn/Transpose_2_output_0, %/transformer/decoder/layers.0/cross_attn/Concat_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_52_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_52\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.0/cross_attn/Unsqueeze_11_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Unsqueeze_11\"](%/transformer/decoder/layers.0/cross_attn/GridSample_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_52_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.0/cross_attn/Concat_5_output_0 : Float(*, *, *, 1, *, strides=[9600, 600, 2, 2, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=-2, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Concat_5\"](%/transformer/decoder/layers.0/cross_attn/Unsqueeze_11_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.0/cross_attn/Shape_6_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Shape_6\"](%/transformer/decoder/layers.0/cross_attn/Concat_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_53_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_53\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_54_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_54\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_55_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_55\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.0/cross_attn/Slice_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Slice_5\"](%/transformer/decoder/layers.0/cross_attn/Shape_6_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_54_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_55_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_53_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_56_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_56\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.0/cross_attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Concat_6\"](%/transformer/decoder/layers.0/cross_attn/Slice_5_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_56_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.0/cross_attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[9600, 600, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Reshape_6\"](%/transformer/decoder/layers.0/cross_attn/Concat_5_output_0, %/transformer/decoder/layers.0/cross_attn/Concat_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.0/cross_attn/Mul_6_output_0 : Float(*, *, *, *, strides=[9600, 600, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Mul_6\"](%/transformer/decoder/layers.0/cross_attn/Reshape_6_output_0, %/transformer/decoder/layers.0/cross_attn/Reshape_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %onnx::ReduceSum_3159 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n  %/transformer/decoder/layers.0/cross_attn/ReduceSum_output_0 : Float(*, *, *, strides=[4800, 300, 1], requires_grad=1, device=cpu) = onnx::ReduceSum[keepdims=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/ReduceSum\"](%/transformer/decoder/layers.0/cross_attn/Mul_6_output_0, %onnx::ReduceSum_3159), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_57_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_57\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.0/cross_attn/Mul_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Mul_7\"](%/transformer/decoder/layers.0/cross_attn/Gather_2_output_0, %/transformer/decoder/layers.0/cross_attn/Constant_57_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.0/cross_attn/Constant_58_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Constant_58\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3165 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/cross_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Unsqueeze_12\"](%/transformer/decoder/layers.0/cross_attn/Mul_7_output_0, %onnx::Unsqueeze_3165), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3167 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.0/cross_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.0/cross_attn/Unsqueeze_13\"](%/transformer/decoder/layers.0/cross_attn/Gather_1_output_0, %onnx::Unsqueeze_3167), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.0/cross_attn/Concat_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Concat_7\"](%/transformer/decoder/layers.0/cross_attn/Constant_58_output_0, %/transformer/decoder/layers.0/cross_attn/Unsqueeze_12_output_0, %/transformer/decoder/layers.0/cross_attn/Unsqueeze_13_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.0/cross_attn/Reshape_7_output_0 : Float(*, *, *, strides=[76800, 300, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.0/cross_attn/Reshape_7\"](%/transformer/decoder/layers.0/cross_attn/ReduceSum_output_0, %/transformer/decoder/layers.0/cross_attn/Concat_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.0/cross_attn/Transpose_3_output_0 : Float(*, *, *, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/transformer/decoder/layers.0/cross_attn/Transpose_3\"](%/transformer/decoder/layers.0/cross_attn/Reshape_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:50:0\n  %/transformer/decoder/layers.0/cross_attn/output_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.0/cross_attn/output_proj/MatMul\"](%/transformer/decoder/layers.0/cross_attn/Transpose_3_output_0, %onnx::MatMul_4929), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::output_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.0/cross_attn/output_proj/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/cross_attn/output_proj/Add\"](%transformer.decoder.layers.0.cross_attn.output_proj.bias, %/transformer/decoder/layers.0/cross_attn/output_proj/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::output_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.0/Add_3_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/Add_3\"](%/transformer/decoder/layers.0/norm1/LayerNormalization_output_0, %/transformer/decoder/layers.0/cross_attn/output_proj/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:528:0\n  %/transformer/decoder/layers.0/norm2/LayerNormalization_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/transformer/decoder/layers.0/norm2/LayerNormalization\"](%/transformer/decoder/layers.0/Add_3_output_0, %transformer.decoder.layers.0.norm2.weight, %transformer.decoder.layers.0.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/transformer/decoder/layers.0/linear1/MatMul_output_0 : Float(*, *, 2048, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.0/linear1/MatMul\"](%/transformer/decoder/layers.0/norm2/LayerNormalization_output_0, %onnx::MatMul_4930), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.linear.Linear::linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.0/linear1/Add_output_0 : Float(*, *, 2048, strides=[614400, 2048, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/linear1/Add\"](%transformer.decoder.layers.0.linear1.bias, %/transformer/decoder/layers.0/linear1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.linear.Linear::linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.0/Relu_output_0 : Float(*, *, 2048, strides=[614400, 2048, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/transformer/decoder/layers.0/Relu\"](%/transformer/decoder/layers.0/linear1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n  %/transformer/decoder/layers.0/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.0/linear2/MatMul\"](%/transformer/decoder/layers.0/Relu_output_0, %onnx::MatMul_4931), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.linear.Linear::linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.0/linear2/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/linear2/Add\"](%transformer.decoder.layers.0.linear2.bias, %/transformer/decoder/layers.0/linear2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.linear.Linear::linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.0/Add_4_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.0/Add_4\"](%/transformer/decoder/layers.0/norm2/LayerNormalization_output_0, %/transformer/decoder/layers.0/linear2/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:531:0\n  %/transformer/decoder/layers.0/norm3/LayerNormalization_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/transformer/decoder/layers.0/norm3/LayerNormalization\"](%/transformer/decoder/layers.0/Add_4_output_0, %transformer.decoder.layers.0.norm3.weight, %transformer.decoder.layers.0.norm3.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/transformer/decoder/layers.1/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/Add\"](%/transformer/decoder/layers.0/norm3/LayerNormalization_output_0, %/transformer/decoder/ref_point_head/layers.1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:499:0\n  %/transformer/decoder/layers.1/self_attn/Transpose_output_0 : Float(*, *, 256, strides=[256, 76800, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.1/self_attn/Transpose\"](%/transformer/decoder/layers.1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1344:0\n  %/transformer/decoder/layers.1/self_attn/Transpose_1_output_0 : Float(*, *, 256, strides=[256, 76800, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.1/self_attn/Transpose_1\"](%/transformer/decoder/layers.0/norm3/LayerNormalization_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1344:0\n  %/transformer/decoder/layers.1/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/self_attn/Shape\"](%/transformer/decoder/layers.1/self_attn/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.1/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.1/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Gather\"](%/transformer/decoder/layers.1/self_attn/Shape_output_0, %/transformer/decoder/layers.1/self_attn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.1/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/self_attn/Shape_1\"](%/transformer/decoder/layers.1/self_attn/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.1/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.1/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Gather_1\"](%/transformer/decoder/layers.1/self_attn/Shape_1_output_0, %/transformer/decoder/layers.1/self_attn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.1/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/self_attn/Shape_2\"](%/transformer/decoder/layers.1/self_attn/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.1/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.1/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Gather_2\"](%/transformer/decoder/layers.1/self_attn/Shape_2_output_0, %/transformer/decoder/layers.1/self_attn/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.1/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.1/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/layers.1/self_attn/Div\"](%/transformer/decoder/layers.1/self_attn/Gather_2_output_0, %/transformer/decoder/layers.1/self_attn/Constant_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.1/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/transformer/decoder/layers.1/self_attn/Cast\"](%/transformer/decoder/layers.1/self_attn/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.1/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/transformer/decoder/layers.1/self_attn/Cast_1\"](%/transformer/decoder/layers.1/self_attn/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.1/self_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.1/self_attn/MatMul\"](%/transformer/decoder/layers.1/self_attn/Transpose_output_0, %onnx::MatMul_4952), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.1/self_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/self_attn/Add\"](%onnx::Add_4947, %/transformer/decoder/layers.1/self_attn/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.1/self_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.1/self_attn/MatMul_1\"](%/transformer/decoder/layers.1/self_attn/Transpose_output_0, %onnx::MatMul_4953), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.1/self_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/self_attn/Add_1\"](%onnx::Add_4949, %/transformer/decoder/layers.1/self_attn/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.1/self_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.1/self_attn/MatMul_2\"](%/transformer/decoder/layers.1/self_attn/Transpose_1_output_0, %onnx::MatMul_4954), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.1/self_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/self_attn/Add_2\"](%onnx::Add_4951, %/transformer/decoder/layers.1/self_attn/MatMul_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.1/self_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.1/self_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.1/self_attn/Mul\"](%/transformer/decoder/layers.1/self_attn/Gather_1_output_0, %/transformer/decoder/layers.1/self_attn/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %onnx::Unsqueeze_3247 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze\"](%/transformer/decoder/layers.1/self_attn/Gather_output_0, %onnx::Unsqueeze_3247), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3249 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_1\"](%/transformer/decoder/layers.1/self_attn/Mul_output_0, %onnx::Unsqueeze_3249), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3251 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_2\"](%/transformer/decoder/layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3251), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.1/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Concat\"](%/transformer/decoder/layers.1/self_attn/Unsqueeze_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_1_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.1/self_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Reshape\"](%/transformer/decoder/layers.1/self_attn/Add_output_0, %/transformer/decoder/layers.1/self_attn/Concat_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.1/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.1/self_attn/Transpose_2\"](%/transformer/decoder/layers.1/self_attn/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.1/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/self_attn/Shape_3\"](%/transformer/decoder/layers.1/self_attn/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.1/self_attn/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.1/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Gather_3\"](%/transformer/decoder/layers.1/self_attn/Shape_3_output_0, %/transformer/decoder/layers.1/self_attn/Constant_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %onnx::Unsqueeze_3259 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_3\"](%/transformer/decoder/layers.1/self_attn/Gather_3_output_0, %onnx::Unsqueeze_3259), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3261 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_4\"](%/transformer/decoder/layers.1/self_attn/Mul_output_0, %onnx::Unsqueeze_3261), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3263 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_5\"](%/transformer/decoder/layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3263), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.1/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Concat_1\"](%/transformer/decoder/layers.1/self_attn/Unsqueeze_3_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_4_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.1/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Reshape_1\"](%/transformer/decoder/layers.1/self_attn/Add_1_output_0, %/transformer/decoder/layers.1/self_attn/Concat_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.1/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.1/self_attn/Transpose_3\"](%/transformer/decoder/layers.1/self_attn/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.1/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/self_attn/Shape_4\"](%/transformer/decoder/layers.1/self_attn/Add_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.1/self_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.1/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Gather_4\"](%/transformer/decoder/layers.1/self_attn/Shape_4_output_0, %/transformer/decoder/layers.1/self_attn/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %onnx::Unsqueeze_3271 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_6\"](%/transformer/decoder/layers.1/self_attn/Gather_4_output_0, %onnx::Unsqueeze_3271), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3273 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_7\"](%/transformer/decoder/layers.1/self_attn/Mul_output_0, %onnx::Unsqueeze_3273), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3275 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_8\"](%/transformer/decoder/layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3275), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.1/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Concat_2\"](%/transformer/decoder/layers.1/self_attn/Unsqueeze_6_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_7_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.1/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Reshape_2\"](%/transformer/decoder/layers.1/self_attn/Add_2_output_0, %/transformer/decoder/layers.1/self_attn/Concat_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.1/self_attn/Transpose_4_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.1/self_attn/Transpose_4\"](%/transformer/decoder/layers.1/self_attn/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.1/self_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/self_attn/Shape_5\"](%/transformer/decoder/layers.1/self_attn/Transpose_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n  %/transformer/decoder/layers.1/self_attn/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant_7\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n  %/transformer/decoder/layers.1/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Gather_5\"](%/transformer/decoder/layers.1/self_attn/Shape_5_output_0, %/transformer/decoder/layers.1/self_attn/Constant_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n  %onnx::Unsqueeze_3283 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_9\"](%/transformer/decoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_3283), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.1/self_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant_8\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3287 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_10\"](%/transformer/decoder/layers.1/self_attn/Gather_output_0, %onnx::Unsqueeze_3287), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3289 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_11\"](%/transformer/decoder/layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3289), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.1/self_attn/Concat_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Concat_3\"](%/transformer/decoder/layers.1/self_attn/Unsqueeze_9_output_0, %/transformer/decoder/layers.1/self_attn/Constant_8_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_10_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_11_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n  %/transformer/decoder/layers.1/self_attn/Reshape_3_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Reshape_3\"](%/transformer/decoder/layers.1/self_attn/Transpose_2_output_0, %/transformer/decoder/layers.1/self_attn/Concat_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n  %onnx::Unsqueeze_3293 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_12\"](%/transformer/decoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_3293), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.1/self_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant_9\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3297 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_13\"](%/transformer/decoder/layers.1/self_attn/Gather_5_output_0, %onnx::Unsqueeze_3297), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3299 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_14\"](%/transformer/decoder/layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3299), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.1/self_attn/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Concat_4\"](%/transformer/decoder/layers.1/self_attn/Unsqueeze_12_output_0, %/transformer/decoder/layers.1/self_attn/Constant_9_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_13_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_14_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n  %onnx::Unsqueeze_3302 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_15\"](%/transformer/decoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_3302), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.1/self_attn/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant_10\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3306 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_16\"](%/transformer/decoder/layers.1/self_attn/Gather_5_output_0, %onnx::Unsqueeze_3306), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3308 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_17\"](%/transformer/decoder/layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3308), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.1/self_attn/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Concat_5\"](%/transformer/decoder/layers.1/self_attn/Unsqueeze_15_output_0, %/transformer/decoder/layers.1/self_attn/Constant_10_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_16_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_17_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n  %/transformer/decoder/layers.1/self_attn/Reshape_4_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Reshape_4\"](%/transformer/decoder/layers.1/self_attn/Transpose_3_output_0, %/transformer/decoder/layers.1/self_attn/Concat_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n  %/transformer/decoder/layers.1/self_attn/Reshape_5_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Reshape_5\"](%/transformer/decoder/layers.1/self_attn/Transpose_4_output_0, %/transformer/decoder/layers.1/self_attn/Concat_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n  %/transformer/decoder/layers.1/self_attn/Shape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/self_attn/Shape_6\"](%/transformer/decoder/layers.1/self_attn/Reshape_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant_11\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant_12\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.1/self_attn/Slice\"](%/transformer/decoder/layers.1/self_attn/Shape_6_output_0, %/transformer/decoder/layers.1/self_attn/Constant_11_output_0, %/transformer/decoder/layers.1/self_attn/Constant_12_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Cast_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/decoder/layers.1/self_attn/Cast_2\"](%/transformer/decoder/layers.1/self_attn/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/transformer/decoder/layers.1/self_attn/Sqrt\"](%/transformer/decoder/layers.1/self_attn/Cast_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Constant_13_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant_13\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Div_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/layers.1/self_attn/Div_1\"](%/transformer/decoder/layers.1/self_attn/Constant_13_output_0, %/transformer/decoder/layers.1/self_attn/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Cast_3_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/decoder/layers.1/self_attn/Cast_3\"](%/transformer/decoder/layers.1/self_attn/Div_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Transpose_5_output_0 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/transformer/decoder/layers.1/self_attn/Transpose_5\"](%/transformer/decoder/layers.1/self_attn/Reshape_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/transformer/decoder/layers.1/self_attn/Sqrt_1\"](%/transformer/decoder/layers.1/self_attn/Cast_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Mul_1_output_0 : Float(*, *, *, *, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.1/self_attn/Mul_1\"](%/transformer/decoder/layers.1/self_attn/Reshape_3_output_0, %/transformer/decoder/layers.1/self_attn/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/transformer/decoder/layers.1/self_attn/Sqrt_2\"](%/transformer/decoder/layers.1/self_attn/Cast_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Mul_2_output_0 : Float(*, *, *, *, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.1/self_attn/Mul_2\"](%/transformer/decoder/layers.1/self_attn/Transpose_5_output_0, %/transformer/decoder/layers.1/self_attn/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/MatMul_3_output_0 : Float(*, *, *, *, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.1/self_attn/MatMul_3\"](%/transformer/decoder/layers.1/self_attn/Mul_1_output_0, %/transformer/decoder/layers.1/self_attn/Mul_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Softmax_output_0 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/transformer/decoder/layers.1/self_attn/Softmax\"](%/transformer/decoder/layers.1/self_attn/MatMul_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/MatMul_4_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.1/self_attn/MatMul_4\"](%/transformer/decoder/layers.1/self_attn/Softmax_output_0, %/transformer/decoder/layers.1/self_attn/Reshape_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.1/self_attn/Transpose_6_output_0 : Float(*, *, *, *, strides=[256, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[2, 0, 1, 3], onnx_name=\"/transformer/decoder/layers.1/self_attn/Transpose_6\"](%/transformer/decoder/layers.1/self_attn/MatMul_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %/transformer/decoder/layers.1/self_attn/Mul_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.1/self_attn/Mul_3\"](%/transformer/decoder/layers.1/self_attn/Gather_1_output_0, %/transformer/decoder/layers.1/self_attn/Gather_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %onnx::Unsqueeze_3332 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_18\"](%/transformer/decoder/layers.1/self_attn/Mul_3_output_0, %onnx::Unsqueeze_3332), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3334 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_19\"](%/transformer/decoder/layers.1/self_attn/Gather_2_output_0, %onnx::Unsqueeze_3334), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.1/self_attn/Concat_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Concat_6\"](%/transformer/decoder/layers.1/self_attn/Unsqueeze_18_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_19_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %/transformer/decoder/layers.1/self_attn/Reshape_6_output_0 : Float(*, *, strides=[256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Reshape_6\"](%/transformer/decoder/layers.1/self_attn/Transpose_6_output_0, %/transformer/decoder/layers.1/self_attn/Concat_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %/transformer/decoder/layers.1/self_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/transformer/decoder/layers.1/self_attn/Gemm\"](%/transformer/decoder/layers.1/self_attn/Reshape_6_output_0, %transformer.decoder.layers.1.self_attn.out_proj.weight, %transformer.decoder.layers.1.self_attn.out_proj.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6417:0\n  %/transformer/decoder/layers.1/self_attn/Shape_7_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/self_attn/Shape_7\"](%/transformer/decoder/layers.1/self_attn/Gemm_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.1/self_attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/self_attn/Constant_14\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.1/self_attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Gather_6\"](%/transformer/decoder/layers.1/self_attn/Shape_7_output_0, %/transformer/decoder/layers.1/self_attn/Constant_14_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %onnx::Unsqueeze_3342 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_20\"](%/transformer/decoder/layers.1/self_attn/Gather_output_0, %onnx::Unsqueeze_3342), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3344 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_21\"](%/transformer/decoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_3344), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3346 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/self_attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/self_attn/Unsqueeze_22\"](%/transformer/decoder/layers.1/self_attn/Gather_6_output_0, %onnx::Unsqueeze_3346), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.1/self_attn/Concat_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Concat_7\"](%/transformer/decoder/layers.1/self_attn/Unsqueeze_20_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_21_output_0, %/transformer/decoder/layers.1/self_attn/Unsqueeze_22_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.1/self_attn/Reshape_7_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/self_attn/Reshape_7\"](%/transformer/decoder/layers.1/self_attn/Gemm_output_0, %/transformer/decoder/layers.1/self_attn/Concat_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.1/self_attn/Transpose_7_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.1/self_attn/Transpose_7\"](%/transformer/decoder/layers.1/self_attn/Reshape_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1395:0\n  %/transformer/decoder/layers.1/Add_1_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/Add_1\"](%/transformer/decoder/layers.0/norm3/LayerNormalization_output_0, %/transformer/decoder/layers.1/self_attn/Transpose_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:514:0\n  %/transformer/decoder/layers.1/norm1/LayerNormalization_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/transformer/decoder/layers.1/norm1/LayerNormalization\"](%/transformer/decoder/layers.1/Add_1_output_0, %transformer.decoder.layers.1.norm1.weight, %transformer.decoder.layers.1.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/transformer/decoder/layers.1/Add_2_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/Add_2\"](%/transformer/decoder/layers.1/norm1/LayerNormalization_output_0, %/transformer/decoder/ref_point_head/layers.1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:479:0\n  %/transformer/decoder/layers.1/cross_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Shape\"](%/transformer/decoder/layers.1/Add_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:112:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:112:0\n  %/transformer/decoder/layers.1/cross_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Gather\"](%/transformer/decoder/layers.1/cross_attn/Shape_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:112:0\n  %/transformer/decoder/layers.1/cross_attn/value_proj/MatMul_output_0 : Float(1, 1296, 256, strides=[331776, 256, 1], device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.1/cross_attn/value_proj/MatMul\"](%/transformer/Concat_1_output_0, %onnx::MatMul_4958), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::value_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.1/cross_attn/value_proj/Add_output_0 : Float(1, 1296, 256, strides=[331776, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/cross_attn/value_proj/Add\"](%transformer.decoder.layers.1.cross_attn.value_proj.bias, %/transformer/decoder/layers.1/cross_attn/value_proj/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::value_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.1/cross_attn/sampling_offsets/MatMul_output_0 : Float(*, *, 64, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.1/cross_attn/sampling_offsets/MatMul\"](%/transformer/decoder/layers.1/Add_2_output_0, %onnx::MatMul_4959), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::sampling_offsets # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.1/cross_attn/sampling_offsets/Add_output_0 : Float(*, *, 64, strides=[19200, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/cross_attn/sampling_offsets/Add\"](%transformer.decoder.layers.1.cross_attn.sampling_offsets.bias, %/transformer/decoder/layers.1/cross_attn/sampling_offsets/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::sampling_offsets # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3365 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/cross_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Unsqueeze\"](%/transformer/decoder/layers.1/cross_attn/Gather_output_0, %onnx::Unsqueeze_3365), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.1/cross_attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.1/cross_attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.1/cross_attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.1/cross_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.1/cross_attn/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Concat\"](%/transformer/decoder/layers.1/cross_attn/Constant_2_output_0, %/transformer/decoder/layers.1/cross_attn/Unsqueeze_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_3_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_4_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_5_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:120:0\n  %/transformer/decoder/layers.1/cross_attn/Reshape_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Reshape\"](%/transformer/decoder/layers.1/cross_attn/sampling_offsets/Add_output_0, %/transformer/decoder/layers.1/cross_attn/Concat_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:120:0\n  %/transformer/decoder/layers.1/cross_attn/attention_weights/MatMul_output_0 : Float(*, *, 32, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.1/cross_attn/attention_weights/MatMul\"](%/transformer/decoder/layers.1/Add_2_output_0, %onnx::MatMul_4965), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::attention_weights # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.1/cross_attn/attention_weights/Add_output_0 : Float(*, *, 32, strides=[9600, 32, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/cross_attn/attention_weights/Add\"](%transformer.decoder.layers.1.cross_attn.attention_weights.bias, %/transformer/decoder/layers.1/cross_attn/attention_weights/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::attention_weights # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_7\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3382 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/cross_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Unsqueeze_1\"](%/transformer/decoder/layers.1/cross_attn/Gather_output_0, %onnx::Unsqueeze_3382), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.1/cross_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_8\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.1/cross_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_9\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.1/cross_attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Concat_1\"](%/transformer/decoder/layers.1/cross_attn/Constant_7_output_0, %/transformer/decoder/layers.1/cross_attn/Unsqueeze_1_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_8_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_9_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:121:0\n  %/transformer/decoder/layers.1/cross_attn/Reshape_1_output_0 : Float(1, *, 16, 2, strides=[9600, 32, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Reshape_1\"](%/transformer/decoder/layers.1/cross_attn/attention_weights/Add_output_0, %/transformer/decoder/layers.1/cross_attn/Concat_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:121:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_10\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.1/cross_attn/Div_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Div\"](%/transformer/decoder/layers.1/cross_attn/Reshape_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_10_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.1/cross_attn/Mul_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Mul\"](%/transformer/decoder/layers.1/cross_attn/Div_output_0, %/transformer/decoder/layers.0/cross_attn/Slice_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_11_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_11\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.1/cross_attn/Mul_1_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Mul_1\"](%/transformer/decoder/layers.1/cross_attn/Mul_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_11_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.1/cross_attn/Add_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Add\"](%/transformer/decoder/layers.0/cross_attn/Slice_output_0, %/transformer/decoder/layers.1/cross_attn/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:129:0\n  %/transformer/decoder/layers.1/cross_attn/Softmax_output_0 : Float(1, *, 16, 2, strides=[9600, 32, 2, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Softmax\"](%/transformer/decoder/layers.1/cross_attn/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2140:0\n  %/transformer/decoder/layers.1/cross_attn/Transpose_output_0 : Float(1, 256, 1296, strides=[331776, 1296, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/transformer/decoder/layers.1/cross_attn/Transpose\"](%/transformer/decoder/layers.1/cross_attn/value_proj/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:136:0\n  %/transformer/decoder/layers.1/cross_attn/Reshape_2_output_0 : Float(1, 16, 16, 1296, strides=[331776, 20736, 1296, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Reshape_2\"](%/transformer/decoder/layers.1/cross_attn/Transpose_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:136:0\n  %/transformer/decoder/layers.1/cross_attn/Shape_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Shape_1\"](%/transformer/decoder/layers.1/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_12_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_12\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.1/cross_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Gather_1\"](%/transformer/decoder/layers.1/cross_attn/Shape_1_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_12_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.1/cross_attn/Shape_2_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Shape_2\"](%/transformer/decoder/layers.1/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_13_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_13\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.1/cross_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Gather_2\"](%/transformer/decoder/layers.1/cross_attn/Shape_2_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_13_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.1/cross_attn/Shape_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Shape_3\"](%/transformer/decoder/layers.1/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_14\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.1/cross_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Gather_3\"](%/transformer/decoder/layers.1/cross_attn/Shape_3_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_14_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.1/cross_attn/Shape_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Shape_4\"](%/transformer/decoder/layers.1/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={4}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_15\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.1/cross_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Gather_4\"](%/transformer/decoder/layers.1/cross_attn/Shape_4_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_15_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_16\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Split_output_0 : Long(1, 2, strides=[2, 1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Split\"](%/transformer/Constant_4_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_16_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_17\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Squeeze_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Squeeze\"](%/transformer/decoder/layers.1/cross_attn/Split_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_17_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 1  1 [ CPULongType{2} ], onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_18\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Split_1_output_0 : Long(1, strides=[1], device=cpu), %/transformer/decoder/layers.1/cross_attn/Split_1_output_1 : Long(1, strides=[1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Split_1\"](%/transformer/decoder/layers.1/cross_attn/Squeeze_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_18_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_19\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Squeeze_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Squeeze_1\"](%/transformer/decoder/layers.1/cross_attn/Split_1_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_19_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_20\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Squeeze_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Squeeze_2\"](%/transformer/decoder/layers.1/cross_attn/Split_1_output_1, %/transformer/decoder/layers.1/cross_attn/Constant_20_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Mul_2\"](%/transformer/decoder/layers.1/cross_attn/Squeeze_1_output_0, %/transformer/decoder/layers.1/cross_attn/Squeeze_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:33:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_21\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.1/cross_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Unsqueeze_2\"](%/transformer/decoder/layers.1/cross_attn/Mul_2_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_21_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_22\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_23\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_24\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.1/cross_attn/Add_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Add_1\"](%/transformer/decoder/layers.1/cross_attn/Constant_24_output_0, %/transformer/decoder/layers.1/cross_attn/Unsqueeze_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.1/cross_attn/Slice_output_0 : Float(1, 16, 16, *, strides=[331776, 20736, 1296, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Slice\"](%/transformer/decoder/layers.1/cross_attn/Reshape_2_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_22_output_0, %/transformer/decoder/layers.1/cross_attn/Add_1_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_23_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_25_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_25\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.1/cross_attn/Mul_3_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Mul_3\"](%/transformer/decoder/layers.1/cross_attn/Add_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_25_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_26_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_26\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.1/cross_attn/Sub_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Sub\"](%/transformer/decoder/layers.1/cross_attn/Mul_3_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_26_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_27\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Split_2_output_0 : Long(1, 2, strides=[2, 1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Split_2\"](%/transformer/Constant_4_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_27_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_28\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Squeeze_3_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Squeeze_3\"](%/transformer/decoder/layers.1/cross_attn/Split_2_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_28_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_29_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 1  1 [ CPULongType{2} ], onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_29\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Split_3_output_0 : Long(1, strides=[1], device=cpu), %/transformer/decoder/layers.1/cross_attn/Split_3_output_1 : Long(1, strides=[1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Split_3\"](%/transformer/decoder/layers.1/cross_attn/Squeeze_3_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_29_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_30\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Squeeze_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Squeeze_4\"](%/transformer/decoder/layers.1/cross_attn/Split_3_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_30_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_31\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Squeeze_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Squeeze_5\"](%/transformer/decoder/layers.1/cross_attn/Split_3_output_1, %/transformer/decoder/layers.1/cross_attn/Constant_31_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_32_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_32\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %/transformer/decoder/layers.1/cross_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Mul_4\"](%/transformer/decoder/layers.1/cross_attn/Constant_32_output_0, %/transformer/decoder/layers.1/cross_attn/Gather_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %onnx::Unsqueeze_3449 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/cross_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Unsqueeze_3\"](%/transformer/decoder/layers.1/cross_attn/Mul_4_output_0, %onnx::Unsqueeze_3449), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.1/cross_attn/Constant_33_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_33\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3453 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/cross_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Unsqueeze_4\"](%/transformer/decoder/layers.1/cross_attn/Squeeze_4_output_0, %onnx::Unsqueeze_3453), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3455 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/cross_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Unsqueeze_5\"](%/transformer/decoder/layers.1/cross_attn/Squeeze_5_output_0, %onnx::Unsqueeze_3455), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.1/cross_attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Concat_2\"](%/transformer/decoder/layers.1/cross_attn/Unsqueeze_3_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_33_output_0, %/transformer/decoder/layers.1/cross_attn/Unsqueeze_4_output_0, %/transformer/decoder/layers.1/cross_attn/Unsqueeze_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %/transformer/decoder/layers.1/cross_attn/Reshape_3_output_0 : Float(*, *, *, *, strides=[20736, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Reshape_3\"](%/transformer/decoder/layers.1/cross_attn/Slice_output_0, %/transformer/decoder/layers.1/cross_attn/Concat_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %/transformer/decoder/layers.1/cross_attn/Gather_5_output_0 : Float(1, *, 16, 2, 2, strides=[19200, 64, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=3, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Gather_5\"](%/transformer/decoder/layers.1/cross_attn/Sub_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.1/cross_attn/Transpose_1_output_0 : Float(1, 16, *, 2, 2, strides=[19200, 4, 64, 2, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name=\"/transformer/decoder/layers.1/cross_attn/Transpose_1\"](%/transformer/decoder/layers.1/cross_attn/Gather_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.1/cross_attn/Shape_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Shape_5\"](%/transformer/decoder/layers.1/cross_attn/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_34\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_35\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_36\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.1/cross_attn/Slice_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Slice_1\"](%/transformer/decoder/layers.1/cross_attn/Shape_5_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_35_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_36_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_34_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_37\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_38\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_39_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={5}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_39\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.1/cross_attn/Slice_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Slice_2\"](%/transformer/decoder/layers.1/cross_attn/Shape_5_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_38_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_39_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_37_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_40\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.1/cross_attn/Concat_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Concat_3\"](%/transformer/decoder/layers.1/cross_attn/Slice_1_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_40_output_0, %/transformer/decoder/layers.1/cross_attn/Slice_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.1/cross_attn/Reshape_4_output_0 : Float(*, *, *, *, strides=[4, 64, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Reshape_4\"](%/transformer/decoder/layers.1/cross_attn/Transpose_1_output_0, %/transformer/decoder/layers.1/cross_attn/Concat_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.1/cross_attn/GridSample_output_0 : Float(*, *, *, *, strides=[9600, 600, 2, 1], requires_grad=1, device=cpu) = onnx::GridSample[align_corners=0, mode=\"bilinear\", padding_mode=\"zeros\", onnx_name=\"/transformer/decoder/layers.1/cross_attn/GridSample\"](%/transformer/decoder/layers.1/cross_attn/Reshape_3_output_0, %/transformer/decoder/layers.1/cross_attn/Reshape_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5023:0\n  %/transformer/decoder/layers.1/cross_attn/Transpose_2_output_0 : Float(1, 16, *, 2, strides=[9600, 2, 32, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/transformer/decoder/layers.1/cross_attn/Transpose_2\"](%/transformer/decoder/layers.1/cross_attn/Softmax_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %/transformer/decoder/layers.1/cross_attn/Mul_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Mul_5\"](%/transformer/decoder/layers.1/cross_attn/Gather_3_output_0, %/transformer/decoder/layers.1/cross_attn/Gather_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %onnx::Unsqueeze_3476 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/cross_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Unsqueeze_6\"](%/transformer/decoder/layers.1/cross_attn/Mul_4_output_0, %onnx::Unsqueeze_3476), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.1/cross_attn/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_41\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3480 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/cross_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Unsqueeze_7\"](%/transformer/decoder/layers.1/cross_attn/Gather_1_output_0, %onnx::Unsqueeze_3480), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3482 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/cross_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Unsqueeze_8\"](%/transformer/decoder/layers.1/cross_attn/Mul_5_output_0, %onnx::Unsqueeze_3482), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.1/cross_attn/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Concat_4\"](%/transformer/decoder/layers.1/cross_attn/Unsqueeze_6_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_41_output_0, %/transformer/decoder/layers.1/cross_attn/Unsqueeze_7_output_0, %/transformer/decoder/layers.1/cross_attn/Unsqueeze_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %/transformer/decoder/layers.1/cross_attn/Reshape_5_output_0 : Float(*, *, *, *, strides=[2, 9600, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Reshape_5\"](%/transformer/decoder/layers.1/cross_attn/Transpose_2_output_0, %/transformer/decoder/layers.1/cross_attn/Concat_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_42\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.1/cross_attn/Unsqueeze_9_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Unsqueeze_9\"](%/transformer/decoder/layers.1/cross_attn/GridSample_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_42_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.1/cross_attn/Concat_5_output_0 : Float(*, *, *, 1, *, strides=[9600, 600, 2, 2, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=-2, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Concat_5\"](%/transformer/decoder/layers.1/cross_attn/Unsqueeze_9_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.1/cross_attn/Shape_6_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Shape_6\"](%/transformer/decoder/layers.1/cross_attn/Concat_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_43_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_43\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_44_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_44\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_45_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_45\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.1/cross_attn/Slice_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Slice_3\"](%/transformer/decoder/layers.1/cross_attn/Shape_6_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_44_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_45_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_43_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_46\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.1/cross_attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Concat_6\"](%/transformer/decoder/layers.1/cross_attn/Slice_3_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_46_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.1/cross_attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[9600, 600, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Reshape_6\"](%/transformer/decoder/layers.1/cross_attn/Concat_5_output_0, %/transformer/decoder/layers.1/cross_attn/Concat_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.1/cross_attn/Mul_6_output_0 : Float(*, *, *, *, strides=[9600, 600, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Mul_6\"](%/transformer/decoder/layers.1/cross_attn/Reshape_6_output_0, %/transformer/decoder/layers.1/cross_attn/Reshape_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.1/cross_attn/ReduceSum_output_0 : Float(*, *, *, strides=[4800, 300, 1], requires_grad=1, device=cpu) = onnx::ReduceSum[keepdims=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/ReduceSum\"](%/transformer/decoder/layers.1/cross_attn/Mul_6_output_0, %onnx::ReduceSum_3159), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_47_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_47\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.1/cross_attn/Mul_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Mul_7\"](%/transformer/decoder/layers.1/cross_attn/Gather_2_output_0, %/transformer/decoder/layers.1/cross_attn/Constant_47_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.1/cross_attn/Constant_48_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Constant_48\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3503 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/cross_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Unsqueeze_10\"](%/transformer/decoder/layers.1/cross_attn/Mul_7_output_0, %onnx::Unsqueeze_3503), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3505 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.1/cross_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.1/cross_attn/Unsqueeze_11\"](%/transformer/decoder/layers.1/cross_attn/Gather_1_output_0, %onnx::Unsqueeze_3505), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.1/cross_attn/Concat_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Concat_7\"](%/transformer/decoder/layers.1/cross_attn/Constant_48_output_0, %/transformer/decoder/layers.1/cross_attn/Unsqueeze_10_output_0, %/transformer/decoder/layers.1/cross_attn/Unsqueeze_11_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.1/cross_attn/Reshape_7_output_0 : Float(*, *, *, strides=[76800, 300, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.1/cross_attn/Reshape_7\"](%/transformer/decoder/layers.1/cross_attn/ReduceSum_output_0, %/transformer/decoder/layers.1/cross_attn/Concat_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.1/cross_attn/Transpose_3_output_0 : Float(*, *, *, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/transformer/decoder/layers.1/cross_attn/Transpose_3\"](%/transformer/decoder/layers.1/cross_attn/Reshape_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:50:0\n  %/transformer/decoder/layers.1/cross_attn/output_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.1/cross_attn/output_proj/MatMul\"](%/transformer/decoder/layers.1/cross_attn/Transpose_3_output_0, %onnx::MatMul_4972), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::output_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.1/cross_attn/output_proj/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/cross_attn/output_proj/Add\"](%transformer.decoder.layers.1.cross_attn.output_proj.bias, %/transformer/decoder/layers.1/cross_attn/output_proj/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::output_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.1/Add_3_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/Add_3\"](%/transformer/decoder/layers.1/norm1/LayerNormalization_output_0, %/transformer/decoder/layers.1/cross_attn/output_proj/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:528:0\n  %/transformer/decoder/layers.1/norm2/LayerNormalization_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/transformer/decoder/layers.1/norm2/LayerNormalization\"](%/transformer/decoder/layers.1/Add_3_output_0, %transformer.decoder.layers.1.norm2.weight, %transformer.decoder.layers.1.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/transformer/decoder/layers.1/linear1/MatMul_output_0 : Float(*, *, 2048, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.1/linear1/MatMul\"](%/transformer/decoder/layers.1/norm2/LayerNormalization_output_0, %onnx::MatMul_4973), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.linear.Linear::linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.1/linear1/Add_output_0 : Float(*, *, 2048, strides=[614400, 2048, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/linear1/Add\"](%transformer.decoder.layers.1.linear1.bias, %/transformer/decoder/layers.1/linear1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.linear.Linear::linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.1/Relu_output_0 : Float(*, *, 2048, strides=[614400, 2048, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/transformer/decoder/layers.1/Relu\"](%/transformer/decoder/layers.1/linear1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n  %/transformer/decoder/layers.1/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.1/linear2/MatMul\"](%/transformer/decoder/layers.1/Relu_output_0, %onnx::MatMul_4974), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.linear.Linear::linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.1/linear2/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/linear2/Add\"](%transformer.decoder.layers.1.linear2.bias, %/transformer/decoder/layers.1/linear2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.linear.Linear::linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.1/Add_4_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.1/Add_4\"](%/transformer/decoder/layers.1/norm2/LayerNormalization_output_0, %/transformer/decoder/layers.1/linear2/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:531:0\n  %/transformer/decoder/layers.1/norm3/LayerNormalization_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/transformer/decoder/layers.1/norm3/LayerNormalization\"](%/transformer/decoder/layers.1/Add_4_output_0, %transformer.decoder.layers.1.norm3.weight, %transformer.decoder.layers.1.norm3.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/transformer/decoder/layers.2/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/Add\"](%/transformer/decoder/layers.1/norm3/LayerNormalization_output_0, %/transformer/decoder/ref_point_head/layers.1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:499:0\n  %/transformer/decoder/layers.2/self_attn/Transpose_output_0 : Float(*, *, 256, strides=[256, 76800, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.2/self_attn/Transpose\"](%/transformer/decoder/layers.2/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1344:0\n  %/transformer/decoder/layers.2/self_attn/Transpose_1_output_0 : Float(*, *, 256, strides=[256, 76800, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.2/self_attn/Transpose_1\"](%/transformer/decoder/layers.1/norm3/LayerNormalization_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1344:0\n  %/transformer/decoder/layers.2/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/self_attn/Shape\"](%/transformer/decoder/layers.2/self_attn/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.2/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.2/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Gather\"](%/transformer/decoder/layers.2/self_attn/Shape_output_0, %/transformer/decoder/layers.2/self_attn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.2/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/self_attn/Shape_1\"](%/transformer/decoder/layers.2/self_attn/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.2/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.2/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Gather_1\"](%/transformer/decoder/layers.2/self_attn/Shape_1_output_0, %/transformer/decoder/layers.2/self_attn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.2/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/self_attn/Shape_2\"](%/transformer/decoder/layers.2/self_attn/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.2/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.2/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Gather_2\"](%/transformer/decoder/layers.2/self_attn/Shape_2_output_0, %/transformer/decoder/layers.2/self_attn/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.2/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.2/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/layers.2/self_attn/Div\"](%/transformer/decoder/layers.2/self_attn/Gather_2_output_0, %/transformer/decoder/layers.2/self_attn/Constant_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.2/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/transformer/decoder/layers.2/self_attn/Cast\"](%/transformer/decoder/layers.2/self_attn/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.2/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/transformer/decoder/layers.2/self_attn/Cast_1\"](%/transformer/decoder/layers.2/self_attn/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.2/self_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.2/self_attn/MatMul\"](%/transformer/decoder/layers.2/self_attn/Transpose_output_0, %onnx::MatMul_4995), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.2/self_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/self_attn/Add\"](%onnx::Add_4990, %/transformer/decoder/layers.2/self_attn/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.2/self_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.2/self_attn/MatMul_1\"](%/transformer/decoder/layers.2/self_attn/Transpose_output_0, %onnx::MatMul_4996), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.2/self_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/self_attn/Add_1\"](%onnx::Add_4992, %/transformer/decoder/layers.2/self_attn/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.2/self_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.2/self_attn/MatMul_2\"](%/transformer/decoder/layers.2/self_attn/Transpose_1_output_0, %onnx::MatMul_4997), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.2/self_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/self_attn/Add_2\"](%onnx::Add_4994, %/transformer/decoder/layers.2/self_attn/MatMul_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.2/self_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.2/self_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.2/self_attn/Mul\"](%/transformer/decoder/layers.2/self_attn/Gather_1_output_0, %/transformer/decoder/layers.2/self_attn/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %onnx::Unsqueeze_3585 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze\"](%/transformer/decoder/layers.2/self_attn/Gather_output_0, %onnx::Unsqueeze_3585), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3587 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_1\"](%/transformer/decoder/layers.2/self_attn/Mul_output_0, %onnx::Unsqueeze_3587), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3589 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_2\"](%/transformer/decoder/layers.2/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3589), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.2/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Concat\"](%/transformer/decoder/layers.2/self_attn/Unsqueeze_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_1_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.2/self_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Reshape\"](%/transformer/decoder/layers.2/self_attn/Add_output_0, %/transformer/decoder/layers.2/self_attn/Concat_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.2/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.2/self_attn/Transpose_2\"](%/transformer/decoder/layers.2/self_attn/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.2/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/self_attn/Shape_3\"](%/transformer/decoder/layers.2/self_attn/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.2/self_attn/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.2/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Gather_3\"](%/transformer/decoder/layers.2/self_attn/Shape_3_output_0, %/transformer/decoder/layers.2/self_attn/Constant_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %onnx::Unsqueeze_3597 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_3\"](%/transformer/decoder/layers.2/self_attn/Gather_3_output_0, %onnx::Unsqueeze_3597), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3599 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_4\"](%/transformer/decoder/layers.2/self_attn/Mul_output_0, %onnx::Unsqueeze_3599), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3601 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_5\"](%/transformer/decoder/layers.2/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3601), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.2/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Concat_1\"](%/transformer/decoder/layers.2/self_attn/Unsqueeze_3_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_4_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.2/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Reshape_1\"](%/transformer/decoder/layers.2/self_attn/Add_1_output_0, %/transformer/decoder/layers.2/self_attn/Concat_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.2/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.2/self_attn/Transpose_3\"](%/transformer/decoder/layers.2/self_attn/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.2/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/self_attn/Shape_4\"](%/transformer/decoder/layers.2/self_attn/Add_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.2/self_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.2/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Gather_4\"](%/transformer/decoder/layers.2/self_attn/Shape_4_output_0, %/transformer/decoder/layers.2/self_attn/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %onnx::Unsqueeze_3609 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_6\"](%/transformer/decoder/layers.2/self_attn/Gather_4_output_0, %onnx::Unsqueeze_3609), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3611 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_7\"](%/transformer/decoder/layers.2/self_attn/Mul_output_0, %onnx::Unsqueeze_3611), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3613 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_8\"](%/transformer/decoder/layers.2/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3613), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.2/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Concat_2\"](%/transformer/decoder/layers.2/self_attn/Unsqueeze_6_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_7_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.2/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Reshape_2\"](%/transformer/decoder/layers.2/self_attn/Add_2_output_0, %/transformer/decoder/layers.2/self_attn/Concat_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.2/self_attn/Transpose_4_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.2/self_attn/Transpose_4\"](%/transformer/decoder/layers.2/self_attn/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.2/self_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/self_attn/Shape_5\"](%/transformer/decoder/layers.2/self_attn/Transpose_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n  %/transformer/decoder/layers.2/self_attn/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant_7\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n  %/transformer/decoder/layers.2/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Gather_5\"](%/transformer/decoder/layers.2/self_attn/Shape_5_output_0, %/transformer/decoder/layers.2/self_attn/Constant_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n  %onnx::Unsqueeze_3621 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_9\"](%/transformer/decoder/layers.2/self_attn/Gather_1_output_0, %onnx::Unsqueeze_3621), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.2/self_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant_8\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3625 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_10\"](%/transformer/decoder/layers.2/self_attn/Gather_output_0, %onnx::Unsqueeze_3625), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3627 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_11\"](%/transformer/decoder/layers.2/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3627), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.2/self_attn/Concat_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Concat_3\"](%/transformer/decoder/layers.2/self_attn/Unsqueeze_9_output_0, %/transformer/decoder/layers.2/self_attn/Constant_8_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_10_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_11_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n  %/transformer/decoder/layers.2/self_attn/Reshape_3_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Reshape_3\"](%/transformer/decoder/layers.2/self_attn/Transpose_2_output_0, %/transformer/decoder/layers.2/self_attn/Concat_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n  %onnx::Unsqueeze_3631 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_12\"](%/transformer/decoder/layers.2/self_attn/Gather_1_output_0, %onnx::Unsqueeze_3631), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.2/self_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant_9\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3635 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_13\"](%/transformer/decoder/layers.2/self_attn/Gather_5_output_0, %onnx::Unsqueeze_3635), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3637 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_14\"](%/transformer/decoder/layers.2/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3637), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.2/self_attn/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Concat_4\"](%/transformer/decoder/layers.2/self_attn/Unsqueeze_12_output_0, %/transformer/decoder/layers.2/self_attn/Constant_9_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_13_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_14_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n  %onnx::Unsqueeze_3640 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_15\"](%/transformer/decoder/layers.2/self_attn/Gather_1_output_0, %onnx::Unsqueeze_3640), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.2/self_attn/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant_10\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3644 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_16\"](%/transformer/decoder/layers.2/self_attn/Gather_5_output_0, %onnx::Unsqueeze_3644), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3646 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_17\"](%/transformer/decoder/layers.2/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3646), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.2/self_attn/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Concat_5\"](%/transformer/decoder/layers.2/self_attn/Unsqueeze_15_output_0, %/transformer/decoder/layers.2/self_attn/Constant_10_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_16_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_17_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n  %/transformer/decoder/layers.2/self_attn/Reshape_4_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Reshape_4\"](%/transformer/decoder/layers.2/self_attn/Transpose_3_output_0, %/transformer/decoder/layers.2/self_attn/Concat_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n  %/transformer/decoder/layers.2/self_attn/Reshape_5_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Reshape_5\"](%/transformer/decoder/layers.2/self_attn/Transpose_4_output_0, %/transformer/decoder/layers.2/self_attn/Concat_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n  %/transformer/decoder/layers.2/self_attn/Shape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/self_attn/Shape_6\"](%/transformer/decoder/layers.2/self_attn/Reshape_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant_11\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant_12\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.2/self_attn/Slice\"](%/transformer/decoder/layers.2/self_attn/Shape_6_output_0, %/transformer/decoder/layers.2/self_attn/Constant_11_output_0, %/transformer/decoder/layers.2/self_attn/Constant_12_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Cast_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/decoder/layers.2/self_attn/Cast_2\"](%/transformer/decoder/layers.2/self_attn/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/transformer/decoder/layers.2/self_attn/Sqrt\"](%/transformer/decoder/layers.2/self_attn/Cast_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Constant_13_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant_13\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Div_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/layers.2/self_attn/Div_1\"](%/transformer/decoder/layers.2/self_attn/Constant_13_output_0, %/transformer/decoder/layers.2/self_attn/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Cast_3_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/decoder/layers.2/self_attn/Cast_3\"](%/transformer/decoder/layers.2/self_attn/Div_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Transpose_5_output_0 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/transformer/decoder/layers.2/self_attn/Transpose_5\"](%/transformer/decoder/layers.2/self_attn/Reshape_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/transformer/decoder/layers.2/self_attn/Sqrt_1\"](%/transformer/decoder/layers.2/self_attn/Cast_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Mul_1_output_0 : Float(*, *, *, *, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.2/self_attn/Mul_1\"](%/transformer/decoder/layers.2/self_attn/Reshape_3_output_0, %/transformer/decoder/layers.2/self_attn/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/transformer/decoder/layers.2/self_attn/Sqrt_2\"](%/transformer/decoder/layers.2/self_attn/Cast_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Mul_2_output_0 : Float(*, *, *, *, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.2/self_attn/Mul_2\"](%/transformer/decoder/layers.2/self_attn/Transpose_5_output_0, %/transformer/decoder/layers.2/self_attn/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/MatMul_3_output_0 : Float(*, *, *, *, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.2/self_attn/MatMul_3\"](%/transformer/decoder/layers.2/self_attn/Mul_1_output_0, %/transformer/decoder/layers.2/self_attn/Mul_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Softmax_output_0 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/transformer/decoder/layers.2/self_attn/Softmax\"](%/transformer/decoder/layers.2/self_attn/MatMul_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/MatMul_4_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.2/self_attn/MatMul_4\"](%/transformer/decoder/layers.2/self_attn/Softmax_output_0, %/transformer/decoder/layers.2/self_attn/Reshape_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.2/self_attn/Transpose_6_output_0 : Float(*, *, *, *, strides=[256, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[2, 0, 1, 3], onnx_name=\"/transformer/decoder/layers.2/self_attn/Transpose_6\"](%/transformer/decoder/layers.2/self_attn/MatMul_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %/transformer/decoder/layers.2/self_attn/Mul_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.2/self_attn/Mul_3\"](%/transformer/decoder/layers.2/self_attn/Gather_1_output_0, %/transformer/decoder/layers.2/self_attn/Gather_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %onnx::Unsqueeze_3670 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_18\"](%/transformer/decoder/layers.2/self_attn/Mul_3_output_0, %onnx::Unsqueeze_3670), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3672 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_19\"](%/transformer/decoder/layers.2/self_attn/Gather_2_output_0, %onnx::Unsqueeze_3672), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.2/self_attn/Concat_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Concat_6\"](%/transformer/decoder/layers.2/self_attn/Unsqueeze_18_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_19_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %/transformer/decoder/layers.2/self_attn/Reshape_6_output_0 : Float(*, *, strides=[256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Reshape_6\"](%/transformer/decoder/layers.2/self_attn/Transpose_6_output_0, %/transformer/decoder/layers.2/self_attn/Concat_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %/transformer/decoder/layers.2/self_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/transformer/decoder/layers.2/self_attn/Gemm\"](%/transformer/decoder/layers.2/self_attn/Reshape_6_output_0, %transformer.decoder.layers.2.self_attn.out_proj.weight, %transformer.decoder.layers.2.self_attn.out_proj.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6417:0\n  %/transformer/decoder/layers.2/self_attn/Shape_7_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/self_attn/Shape_7\"](%/transformer/decoder/layers.2/self_attn/Gemm_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.2/self_attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/self_attn/Constant_14\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.2/self_attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Gather_6\"](%/transformer/decoder/layers.2/self_attn/Shape_7_output_0, %/transformer/decoder/layers.2/self_attn/Constant_14_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %onnx::Unsqueeze_3680 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_20\"](%/transformer/decoder/layers.2/self_attn/Gather_output_0, %onnx::Unsqueeze_3680), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3682 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_21\"](%/transformer/decoder/layers.2/self_attn/Gather_1_output_0, %onnx::Unsqueeze_3682), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3684 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/self_attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/self_attn/Unsqueeze_22\"](%/transformer/decoder/layers.2/self_attn/Gather_6_output_0, %onnx::Unsqueeze_3684), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.2/self_attn/Concat_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Concat_7\"](%/transformer/decoder/layers.2/self_attn/Unsqueeze_20_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_21_output_0, %/transformer/decoder/layers.2/self_attn/Unsqueeze_22_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.2/self_attn/Reshape_7_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/self_attn/Reshape_7\"](%/transformer/decoder/layers.2/self_attn/Gemm_output_0, %/transformer/decoder/layers.2/self_attn/Concat_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.2/self_attn/Transpose_7_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.2/self_attn/Transpose_7\"](%/transformer/decoder/layers.2/self_attn/Reshape_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1395:0\n  %/transformer/decoder/layers.2/Add_1_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/Add_1\"](%/transformer/decoder/layers.1/norm3/LayerNormalization_output_0, %/transformer/decoder/layers.2/self_attn/Transpose_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:514:0\n  %/transformer/decoder/layers.2/norm1/LayerNormalization_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/transformer/decoder/layers.2/norm1/LayerNormalization\"](%/transformer/decoder/layers.2/Add_1_output_0, %transformer.decoder.layers.2.norm1.weight, %transformer.decoder.layers.2.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/transformer/decoder/layers.2/Add_2_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/Add_2\"](%/transformer/decoder/layers.2/norm1/LayerNormalization_output_0, %/transformer/decoder/ref_point_head/layers.1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:479:0\n  %/transformer/decoder/layers.2/cross_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Shape\"](%/transformer/decoder/layers.2/Add_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:112:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:112:0\n  %/transformer/decoder/layers.2/cross_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Gather\"](%/transformer/decoder/layers.2/cross_attn/Shape_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:112:0\n  %/transformer/decoder/layers.2/cross_attn/value_proj/MatMul_output_0 : Float(1, 1296, 256, strides=[331776, 256, 1], device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.2/cross_attn/value_proj/MatMul\"](%/transformer/Concat_1_output_0, %onnx::MatMul_5001), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::value_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.2/cross_attn/value_proj/Add_output_0 : Float(1, 1296, 256, strides=[331776, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/cross_attn/value_proj/Add\"](%transformer.decoder.layers.2.cross_attn.value_proj.bias, %/transformer/decoder/layers.2/cross_attn/value_proj/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::value_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.2/cross_attn/sampling_offsets/MatMul_output_0 : Float(*, *, 64, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.2/cross_attn/sampling_offsets/MatMul\"](%/transformer/decoder/layers.2/Add_2_output_0, %onnx::MatMul_5002), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::sampling_offsets # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.2/cross_attn/sampling_offsets/Add_output_0 : Float(*, *, 64, strides=[19200, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/cross_attn/sampling_offsets/Add\"](%transformer.decoder.layers.2.cross_attn.sampling_offsets.bias, %/transformer/decoder/layers.2/cross_attn/sampling_offsets/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::sampling_offsets # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3703 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/cross_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Unsqueeze\"](%/transformer/decoder/layers.2/cross_attn/Gather_output_0, %onnx::Unsqueeze_3703), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.2/cross_attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.2/cross_attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.2/cross_attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.2/cross_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.2/cross_attn/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Concat\"](%/transformer/decoder/layers.2/cross_attn/Constant_2_output_0, %/transformer/decoder/layers.2/cross_attn/Unsqueeze_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_3_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_4_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_5_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:120:0\n  %/transformer/decoder/layers.2/cross_attn/Reshape_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Reshape\"](%/transformer/decoder/layers.2/cross_attn/sampling_offsets/Add_output_0, %/transformer/decoder/layers.2/cross_attn/Concat_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:120:0\n  %/transformer/decoder/layers.2/cross_attn/attention_weights/MatMul_output_0 : Float(*, *, 32, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.2/cross_attn/attention_weights/MatMul\"](%/transformer/decoder/layers.2/Add_2_output_0, %onnx::MatMul_5008), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::attention_weights # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.2/cross_attn/attention_weights/Add_output_0 : Float(*, *, 32, strides=[9600, 32, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/cross_attn/attention_weights/Add\"](%transformer.decoder.layers.2.cross_attn.attention_weights.bias, %/transformer/decoder/layers.2/cross_attn/attention_weights/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::attention_weights # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_7\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3720 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/cross_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Unsqueeze_1\"](%/transformer/decoder/layers.2/cross_attn/Gather_output_0, %onnx::Unsqueeze_3720), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.2/cross_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_8\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.2/cross_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_9\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.2/cross_attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Concat_1\"](%/transformer/decoder/layers.2/cross_attn/Constant_7_output_0, %/transformer/decoder/layers.2/cross_attn/Unsqueeze_1_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_8_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_9_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:121:0\n  %/transformer/decoder/layers.2/cross_attn/Reshape_1_output_0 : Float(1, *, 16, 2, strides=[9600, 32, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Reshape_1\"](%/transformer/decoder/layers.2/cross_attn/attention_weights/Add_output_0, %/transformer/decoder/layers.2/cross_attn/Concat_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:121:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_10\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.2/cross_attn/Div_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Div\"](%/transformer/decoder/layers.2/cross_attn/Reshape_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_10_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.2/cross_attn/Mul_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Mul\"](%/transformer/decoder/layers.2/cross_attn/Div_output_0, %/transformer/decoder/layers.0/cross_attn/Slice_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_11_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_11\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.2/cross_attn/Mul_1_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Mul_1\"](%/transformer/decoder/layers.2/cross_attn/Mul_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_11_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.2/cross_attn/Add_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Add\"](%/transformer/decoder/layers.0/cross_attn/Slice_output_0, %/transformer/decoder/layers.2/cross_attn/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:129:0\n  %/transformer/decoder/layers.2/cross_attn/Softmax_output_0 : Float(1, *, 16, 2, strides=[9600, 32, 2, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Softmax\"](%/transformer/decoder/layers.2/cross_attn/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2140:0\n  %/transformer/decoder/layers.2/cross_attn/Transpose_output_0 : Float(1, 256, 1296, strides=[331776, 1296, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/transformer/decoder/layers.2/cross_attn/Transpose\"](%/transformer/decoder/layers.2/cross_attn/value_proj/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:136:0\n  %/transformer/decoder/layers.2/cross_attn/Reshape_2_output_0 : Float(1, 16, 16, 1296, strides=[331776, 20736, 1296, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Reshape_2\"](%/transformer/decoder/layers.2/cross_attn/Transpose_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:136:0\n  %/transformer/decoder/layers.2/cross_attn/Shape_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Shape_1\"](%/transformer/decoder/layers.2/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_12_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_12\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.2/cross_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Gather_1\"](%/transformer/decoder/layers.2/cross_attn/Shape_1_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_12_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.2/cross_attn/Shape_2_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Shape_2\"](%/transformer/decoder/layers.2/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_13_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_13\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.2/cross_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Gather_2\"](%/transformer/decoder/layers.2/cross_attn/Shape_2_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_13_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.2/cross_attn/Shape_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Shape_3\"](%/transformer/decoder/layers.2/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_14\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.2/cross_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Gather_3\"](%/transformer/decoder/layers.2/cross_attn/Shape_3_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_14_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.2/cross_attn/Shape_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Shape_4\"](%/transformer/decoder/layers.2/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={4}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_15\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.2/cross_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Gather_4\"](%/transformer/decoder/layers.2/cross_attn/Shape_4_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_15_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_16\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Split_output_0 : Long(1, 2, strides=[2, 1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Split\"](%/transformer/Constant_4_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_16_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_17\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Squeeze_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Squeeze\"](%/transformer/decoder/layers.2/cross_attn/Split_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_17_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 1  1 [ CPULongType{2} ], onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_18\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Split_1_output_0 : Long(1, strides=[1], device=cpu), %/transformer/decoder/layers.2/cross_attn/Split_1_output_1 : Long(1, strides=[1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Split_1\"](%/transformer/decoder/layers.2/cross_attn/Squeeze_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_18_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_19\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Squeeze_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Squeeze_1\"](%/transformer/decoder/layers.2/cross_attn/Split_1_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_19_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_20\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Squeeze_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Squeeze_2\"](%/transformer/decoder/layers.2/cross_attn/Split_1_output_1, %/transformer/decoder/layers.2/cross_attn/Constant_20_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Mul_2\"](%/transformer/decoder/layers.2/cross_attn/Squeeze_1_output_0, %/transformer/decoder/layers.2/cross_attn/Squeeze_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:33:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_21\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.2/cross_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Unsqueeze_2\"](%/transformer/decoder/layers.2/cross_attn/Mul_2_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_21_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_22\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_23\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_24\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.2/cross_attn/Add_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Add_1\"](%/transformer/decoder/layers.2/cross_attn/Constant_24_output_0, %/transformer/decoder/layers.2/cross_attn/Unsqueeze_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.2/cross_attn/Slice_output_0 : Float(1, 16, 16, *, strides=[331776, 20736, 1296, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Slice\"](%/transformer/decoder/layers.2/cross_attn/Reshape_2_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_22_output_0, %/transformer/decoder/layers.2/cross_attn/Add_1_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_23_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_25_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_25\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.2/cross_attn/Mul_3_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Mul_3\"](%/transformer/decoder/layers.2/cross_attn/Add_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_25_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_26_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_26\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.2/cross_attn/Sub_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Sub\"](%/transformer/decoder/layers.2/cross_attn/Mul_3_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_26_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_27\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Split_2_output_0 : Long(1, 2, strides=[2, 1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Split_2\"](%/transformer/Constant_4_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_27_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_28\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Squeeze_3_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Squeeze_3\"](%/transformer/decoder/layers.2/cross_attn/Split_2_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_28_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_29_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 1  1 [ CPULongType{2} ], onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_29\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Split_3_output_0 : Long(1, strides=[1], device=cpu), %/transformer/decoder/layers.2/cross_attn/Split_3_output_1 : Long(1, strides=[1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Split_3\"](%/transformer/decoder/layers.2/cross_attn/Squeeze_3_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_29_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_30\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Squeeze_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Squeeze_4\"](%/transformer/decoder/layers.2/cross_attn/Split_3_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_30_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_31\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Squeeze_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Squeeze_5\"](%/transformer/decoder/layers.2/cross_attn/Split_3_output_1, %/transformer/decoder/layers.2/cross_attn/Constant_31_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_32_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_32\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %/transformer/decoder/layers.2/cross_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Mul_4\"](%/transformer/decoder/layers.2/cross_attn/Constant_32_output_0, %/transformer/decoder/layers.2/cross_attn/Gather_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %onnx::Unsqueeze_3787 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/cross_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Unsqueeze_3\"](%/transformer/decoder/layers.2/cross_attn/Mul_4_output_0, %onnx::Unsqueeze_3787), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.2/cross_attn/Constant_33_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_33\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3791 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/cross_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Unsqueeze_4\"](%/transformer/decoder/layers.2/cross_attn/Squeeze_4_output_0, %onnx::Unsqueeze_3791), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3793 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/cross_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Unsqueeze_5\"](%/transformer/decoder/layers.2/cross_attn/Squeeze_5_output_0, %onnx::Unsqueeze_3793), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.2/cross_attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Concat_2\"](%/transformer/decoder/layers.2/cross_attn/Unsqueeze_3_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_33_output_0, %/transformer/decoder/layers.2/cross_attn/Unsqueeze_4_output_0, %/transformer/decoder/layers.2/cross_attn/Unsqueeze_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %/transformer/decoder/layers.2/cross_attn/Reshape_3_output_0 : Float(*, *, *, *, strides=[20736, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Reshape_3\"](%/transformer/decoder/layers.2/cross_attn/Slice_output_0, %/transformer/decoder/layers.2/cross_attn/Concat_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %/transformer/decoder/layers.2/cross_attn/Gather_5_output_0 : Float(1, *, 16, 2, 2, strides=[19200, 64, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=3, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Gather_5\"](%/transformer/decoder/layers.2/cross_attn/Sub_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.2/cross_attn/Transpose_1_output_0 : Float(1, 16, *, 2, 2, strides=[19200, 4, 64, 2, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name=\"/transformer/decoder/layers.2/cross_attn/Transpose_1\"](%/transformer/decoder/layers.2/cross_attn/Gather_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.2/cross_attn/Shape_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Shape_5\"](%/transformer/decoder/layers.2/cross_attn/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_34\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_35\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_36\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.2/cross_attn/Slice_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Slice_1\"](%/transformer/decoder/layers.2/cross_attn/Shape_5_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_35_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_36_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_34_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_37\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_38\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_39_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={5}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_39\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.2/cross_attn/Slice_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Slice_2\"](%/transformer/decoder/layers.2/cross_attn/Shape_5_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_38_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_39_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_37_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_40\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.2/cross_attn/Concat_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Concat_3\"](%/transformer/decoder/layers.2/cross_attn/Slice_1_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_40_output_0, %/transformer/decoder/layers.2/cross_attn/Slice_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.2/cross_attn/Reshape_4_output_0 : Float(*, *, *, *, strides=[4, 64, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Reshape_4\"](%/transformer/decoder/layers.2/cross_attn/Transpose_1_output_0, %/transformer/decoder/layers.2/cross_attn/Concat_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.2/cross_attn/GridSample_output_0 : Float(*, *, *, *, strides=[9600, 600, 2, 1], requires_grad=1, device=cpu) = onnx::GridSample[align_corners=0, mode=\"bilinear\", padding_mode=\"zeros\", onnx_name=\"/transformer/decoder/layers.2/cross_attn/GridSample\"](%/transformer/decoder/layers.2/cross_attn/Reshape_3_output_0, %/transformer/decoder/layers.2/cross_attn/Reshape_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5023:0\n  %/transformer/decoder/layers.2/cross_attn/Transpose_2_output_0 : Float(1, 16, *, 2, strides=[9600, 2, 32, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/transformer/decoder/layers.2/cross_attn/Transpose_2\"](%/transformer/decoder/layers.2/cross_attn/Softmax_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %/transformer/decoder/layers.2/cross_attn/Mul_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Mul_5\"](%/transformer/decoder/layers.2/cross_attn/Gather_3_output_0, %/transformer/decoder/layers.2/cross_attn/Gather_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %onnx::Unsqueeze_3814 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/cross_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Unsqueeze_6\"](%/transformer/decoder/layers.2/cross_attn/Mul_4_output_0, %onnx::Unsqueeze_3814), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.2/cross_attn/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_41\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3818 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/cross_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Unsqueeze_7\"](%/transformer/decoder/layers.2/cross_attn/Gather_1_output_0, %onnx::Unsqueeze_3818), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3820 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/cross_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Unsqueeze_8\"](%/transformer/decoder/layers.2/cross_attn/Mul_5_output_0, %onnx::Unsqueeze_3820), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.2/cross_attn/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Concat_4\"](%/transformer/decoder/layers.2/cross_attn/Unsqueeze_6_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_41_output_0, %/transformer/decoder/layers.2/cross_attn/Unsqueeze_7_output_0, %/transformer/decoder/layers.2/cross_attn/Unsqueeze_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %/transformer/decoder/layers.2/cross_attn/Reshape_5_output_0 : Float(*, *, *, *, strides=[2, 9600, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Reshape_5\"](%/transformer/decoder/layers.2/cross_attn/Transpose_2_output_0, %/transformer/decoder/layers.2/cross_attn/Concat_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_42\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.2/cross_attn/Unsqueeze_9_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Unsqueeze_9\"](%/transformer/decoder/layers.2/cross_attn/GridSample_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_42_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.2/cross_attn/Concat_5_output_0 : Float(*, *, *, 1, *, strides=[9600, 600, 2, 2, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=-2, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Concat_5\"](%/transformer/decoder/layers.2/cross_attn/Unsqueeze_9_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.2/cross_attn/Shape_6_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Shape_6\"](%/transformer/decoder/layers.2/cross_attn/Concat_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_43_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_43\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_44_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_44\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_45_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_45\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.2/cross_attn/Slice_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Slice_3\"](%/transformer/decoder/layers.2/cross_attn/Shape_6_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_44_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_45_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_43_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_46\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.2/cross_attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Concat_6\"](%/transformer/decoder/layers.2/cross_attn/Slice_3_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_46_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.2/cross_attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[9600, 600, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Reshape_6\"](%/transformer/decoder/layers.2/cross_attn/Concat_5_output_0, %/transformer/decoder/layers.2/cross_attn/Concat_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.2/cross_attn/Mul_6_output_0 : Float(*, *, *, *, strides=[9600, 600, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Mul_6\"](%/transformer/decoder/layers.2/cross_attn/Reshape_6_output_0, %/transformer/decoder/layers.2/cross_attn/Reshape_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.2/cross_attn/ReduceSum_output_0 : Float(*, *, *, strides=[4800, 300, 1], requires_grad=1, device=cpu) = onnx::ReduceSum[keepdims=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/ReduceSum\"](%/transformer/decoder/layers.2/cross_attn/Mul_6_output_0, %onnx::ReduceSum_3159), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_47_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_47\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.2/cross_attn/Mul_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Mul_7\"](%/transformer/decoder/layers.2/cross_attn/Gather_2_output_0, %/transformer/decoder/layers.2/cross_attn/Constant_47_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.2/cross_attn/Constant_48_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Constant_48\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3841 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/cross_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Unsqueeze_10\"](%/transformer/decoder/layers.2/cross_attn/Mul_7_output_0, %onnx::Unsqueeze_3841), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_3843 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.2/cross_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.2/cross_attn/Unsqueeze_11\"](%/transformer/decoder/layers.2/cross_attn/Gather_1_output_0, %onnx::Unsqueeze_3843), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.2/cross_attn/Concat_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Concat_7\"](%/transformer/decoder/layers.2/cross_attn/Constant_48_output_0, %/transformer/decoder/layers.2/cross_attn/Unsqueeze_10_output_0, %/transformer/decoder/layers.2/cross_attn/Unsqueeze_11_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.2/cross_attn/Reshape_7_output_0 : Float(*, *, *, strides=[76800, 300, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.2/cross_attn/Reshape_7\"](%/transformer/decoder/layers.2/cross_attn/ReduceSum_output_0, %/transformer/decoder/layers.2/cross_attn/Concat_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.2/cross_attn/Transpose_3_output_0 : Float(*, *, *, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/transformer/decoder/layers.2/cross_attn/Transpose_3\"](%/transformer/decoder/layers.2/cross_attn/Reshape_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:50:0\n  %/transformer/decoder/layers.2/cross_attn/output_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.2/cross_attn/output_proj/MatMul\"](%/transformer/decoder/layers.2/cross_attn/Transpose_3_output_0, %onnx::MatMul_5015), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::output_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.2/cross_attn/output_proj/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/cross_attn/output_proj/Add\"](%transformer.decoder.layers.2.cross_attn.output_proj.bias, %/transformer/decoder/layers.2/cross_attn/output_proj/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::output_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.2/Add_3_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/Add_3\"](%/transformer/decoder/layers.2/norm1/LayerNormalization_output_0, %/transformer/decoder/layers.2/cross_attn/output_proj/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:528:0\n  %/transformer/decoder/layers.2/norm2/LayerNormalization_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/transformer/decoder/layers.2/norm2/LayerNormalization\"](%/transformer/decoder/layers.2/Add_3_output_0, %transformer.decoder.layers.2.norm2.weight, %transformer.decoder.layers.2.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/transformer/decoder/layers.2/linear1/MatMul_output_0 : Float(*, *, 2048, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.2/linear1/MatMul\"](%/transformer/decoder/layers.2/norm2/LayerNormalization_output_0, %onnx::MatMul_5016), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.linear.Linear::linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.2/linear1/Add_output_0 : Float(*, *, 2048, strides=[614400, 2048, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/linear1/Add\"](%transformer.decoder.layers.2.linear1.bias, %/transformer/decoder/layers.2/linear1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.linear.Linear::linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.2/Relu_output_0 : Float(*, *, 2048, strides=[614400, 2048, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/transformer/decoder/layers.2/Relu\"](%/transformer/decoder/layers.2/linear1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n  %/transformer/decoder/layers.2/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.2/linear2/MatMul\"](%/transformer/decoder/layers.2/Relu_output_0, %onnx::MatMul_5017), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.linear.Linear::linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.2/linear2/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/linear2/Add\"](%transformer.decoder.layers.2.linear2.bias, %/transformer/decoder/layers.2/linear2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.linear.Linear::linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.2/Add_4_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.2/Add_4\"](%/transformer/decoder/layers.2/norm2/LayerNormalization_output_0, %/transformer/decoder/layers.2/linear2/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:531:0\n  %/transformer/decoder/layers.2/norm3/LayerNormalization_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/transformer/decoder/layers.2/norm3/LayerNormalization\"](%/transformer/decoder/layers.2/Add_4_output_0, %transformer.decoder.layers.2.norm3.weight, %transformer.decoder.layers.2.norm3.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.2/torch.nn.modules.normalization.LayerNorm::norm3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/transformer/decoder/Constant_73_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/Constant_73\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:392:0\n  %/transformer/decoder/Mul_4_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/Mul_4\"](%/transformer/decoder/ref_point_head/layers.1/Add_output_0, %/transformer/decoder/Constant_73_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:392:0\n  %/transformer/decoder/layers.3/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/Add\"](%/transformer/decoder/layers.2/norm3/LayerNormalization_output_0, %/transformer/decoder/Mul_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:499:0\n  %/transformer/decoder/layers.3/self_attn/Transpose_output_0 : Float(*, *, 256, strides=[256, 76800, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.3/self_attn/Transpose\"](%/transformer/decoder/layers.3/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1344:0\n  %/transformer/decoder/layers.3/self_attn/Transpose_1_output_0 : Float(*, *, 256, strides=[256, 76800, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.3/self_attn/Transpose_1\"](%/transformer/decoder/layers.2/norm3/LayerNormalization_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1344:0\n  %/transformer/decoder/layers.3/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/self_attn/Shape\"](%/transformer/decoder/layers.3/self_attn/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.3/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.3/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Gather\"](%/transformer/decoder/layers.3/self_attn/Shape_output_0, %/transformer/decoder/layers.3/self_attn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.3/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/self_attn/Shape_1\"](%/transformer/decoder/layers.3/self_attn/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.3/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.3/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Gather_1\"](%/transformer/decoder/layers.3/self_attn/Shape_1_output_0, %/transformer/decoder/layers.3/self_attn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.3/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/self_attn/Shape_2\"](%/transformer/decoder/layers.3/self_attn/Transpose_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.3/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.3/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Gather_2\"](%/transformer/decoder/layers.3/self_attn/Shape_2_output_0, %/transformer/decoder/layers.3/self_attn/Constant_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n  %/transformer/decoder/layers.3/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.3/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/layers.3/self_attn/Div\"](%/transformer/decoder/layers.3/self_attn/Gather_2_output_0, %/transformer/decoder/layers.3/self_attn/Constant_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.3/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/transformer/decoder/layers.3/self_attn/Cast\"](%/transformer/decoder/layers.3/self_attn/Div_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.3/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/transformer/decoder/layers.3/self_attn/Cast_1\"](%/transformer/decoder/layers.3/self_attn/Cast_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n  %/transformer/decoder/layers.3/self_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.3/self_attn/MatMul\"](%/transformer/decoder/layers.3/self_attn/Transpose_output_0, %onnx::MatMul_5038), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.3/self_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/self_attn/Add\"](%onnx::Add_5033, %/transformer/decoder/layers.3/self_attn/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.3/self_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.3/self_attn/MatMul_1\"](%/transformer/decoder/layers.3/self_attn/Transpose_output_0, %onnx::MatMul_5039), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.3/self_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/self_attn/Add_1\"](%onnx::Add_5035, %/transformer/decoder/layers.3/self_attn/MatMul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.3/self_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.3/self_attn/MatMul_2\"](%/transformer/decoder/layers.3/self_attn/Transpose_1_output_0, %onnx::MatMul_5040), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.3/self_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/self_attn/Add_2\"](%onnx::Add_5037, %/transformer/decoder/layers.3/self_attn/MatMul_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5648:0\n  %/transformer/decoder/layers.3/self_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.3/self_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.3/self_attn/Mul\"](%/transformer/decoder/layers.3/self_attn/Gather_1_output_0, %/transformer/decoder/layers.3/self_attn/Constant_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %onnx::Unsqueeze_3925 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze\"](%/transformer/decoder/layers.3/self_attn/Gather_output_0, %onnx::Unsqueeze_3925), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3927 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_1\"](%/transformer/decoder/layers.3/self_attn/Mul_output_0, %onnx::Unsqueeze_3927), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3929 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_2\"](%/transformer/decoder/layers.3/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3929), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.3/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Concat\"](%/transformer/decoder/layers.3/self_attn/Unsqueeze_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_1_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.3/self_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Reshape\"](%/transformer/decoder/layers.3/self_attn/Add_output_0, %/transformer/decoder/layers.3/self_attn/Concat_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.3/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.3/self_attn/Transpose_2\"](%/transformer/decoder/layers.3/self_attn/Reshape_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n  %/transformer/decoder/layers.3/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/self_attn/Shape_3\"](%/transformer/decoder/layers.3/self_attn/Add_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.3/self_attn/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.3/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Gather_3\"](%/transformer/decoder/layers.3/self_attn/Shape_3_output_0, %/transformer/decoder/layers.3/self_attn/Constant_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %onnx::Unsqueeze_3937 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_3\"](%/transformer/decoder/layers.3/self_attn/Gather_3_output_0, %onnx::Unsqueeze_3937), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3939 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_4\"](%/transformer/decoder/layers.3/self_attn/Mul_output_0, %onnx::Unsqueeze_3939), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3941 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_5\"](%/transformer/decoder/layers.3/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3941), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.3/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Concat_1\"](%/transformer/decoder/layers.3/self_attn/Unsqueeze_3_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_4_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.3/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Reshape_1\"](%/transformer/decoder/layers.3/self_attn/Add_1_output_0, %/transformer/decoder/layers.3/self_attn/Concat_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.3/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.3/self_attn/Transpose_3\"](%/transformer/decoder/layers.3/self_attn/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n  %/transformer/decoder/layers.3/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/self_attn/Shape_4\"](%/transformer/decoder/layers.3/self_attn/Add_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.3/self_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.3/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Gather_4\"](%/transformer/decoder/layers.3/self_attn/Shape_4_output_0, %/transformer/decoder/layers.3/self_attn/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %onnx::Unsqueeze_3949 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_6\"](%/transformer/decoder/layers.3/self_attn/Gather_4_output_0, %onnx::Unsqueeze_3949), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3951 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_7\"](%/transformer/decoder/layers.3/self_attn/Mul_output_0, %onnx::Unsqueeze_3951), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3953 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_8\"](%/transformer/decoder/layers.3/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3953), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.3/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Concat_2\"](%/transformer/decoder/layers.3/self_attn/Unsqueeze_6_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_7_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.3/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Reshape_2\"](%/transformer/decoder/layers.3/self_attn/Add_2_output_0, %/transformer/decoder/layers.3/self_attn/Concat_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.3/self_attn/Transpose_4_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.3/self_attn/Transpose_4\"](%/transformer/decoder/layers.3/self_attn/Reshape_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n  %/transformer/decoder/layers.3/self_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/self_attn/Shape_5\"](%/transformer/decoder/layers.3/self_attn/Transpose_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n  %/transformer/decoder/layers.3/self_attn/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant_7\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n  %/transformer/decoder/layers.3/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Gather_5\"](%/transformer/decoder/layers.3/self_attn/Shape_5_output_0, %/transformer/decoder/layers.3/self_attn/Constant_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n  %onnx::Unsqueeze_3961 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_9\"](%/transformer/decoder/layers.3/self_attn/Gather_1_output_0, %onnx::Unsqueeze_3961), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.3/self_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant_8\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3965 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_10\"](%/transformer/decoder/layers.3/self_attn/Gather_output_0, %onnx::Unsqueeze_3965), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3967 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_11\"](%/transformer/decoder/layers.3/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3967), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.3/self_attn/Concat_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Concat_3\"](%/transformer/decoder/layers.3/self_attn/Unsqueeze_9_output_0, %/transformer/decoder/layers.3/self_attn/Constant_8_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_10_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_11_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n  %/transformer/decoder/layers.3/self_attn/Reshape_3_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Reshape_3\"](%/transformer/decoder/layers.3/self_attn/Transpose_2_output_0, %/transformer/decoder/layers.3/self_attn/Concat_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n  %onnx::Unsqueeze_3971 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_12\"](%/transformer/decoder/layers.3/self_attn/Gather_1_output_0, %onnx::Unsqueeze_3971), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.3/self_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant_9\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3975 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_13\"](%/transformer/decoder/layers.3/self_attn/Gather_5_output_0, %onnx::Unsqueeze_3975), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3977 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_14\"](%/transformer/decoder/layers.3/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3977), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.3/self_attn/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Concat_4\"](%/transformer/decoder/layers.3/self_attn/Unsqueeze_12_output_0, %/transformer/decoder/layers.3/self_attn/Constant_9_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_13_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_14_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n  %onnx::Unsqueeze_3980 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_15\"](%/transformer/decoder/layers.3/self_attn/Gather_1_output_0, %onnx::Unsqueeze_3980), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.3/self_attn/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant_10\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3984 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_16\"](%/transformer/decoder/layers.3/self_attn/Gather_5_output_0, %onnx::Unsqueeze_3984), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_3986 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_17\"](%/transformer/decoder/layers.3/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3986), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.3/self_attn/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Concat_5\"](%/transformer/decoder/layers.3/self_attn/Unsqueeze_15_output_0, %/transformer/decoder/layers.3/self_attn/Constant_10_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_16_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_17_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n  %/transformer/decoder/layers.3/self_attn/Reshape_4_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Reshape_4\"](%/transformer/decoder/layers.3/self_attn/Transpose_3_output_0, %/transformer/decoder/layers.3/self_attn/Concat_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n  %/transformer/decoder/layers.3/self_attn/Reshape_5_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Reshape_5\"](%/transformer/decoder/layers.3/self_attn/Transpose_4_output_0, %/transformer/decoder/layers.3/self_attn/Concat_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n  %/transformer/decoder/layers.3/self_attn/Shape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/self_attn/Shape_6\"](%/transformer/decoder/layers.3/self_attn/Reshape_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant_11\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant_12\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.3/self_attn/Slice\"](%/transformer/decoder/layers.3/self_attn/Shape_6_output_0, %/transformer/decoder/layers.3/self_attn/Constant_11_output_0, %/transformer/decoder/layers.3/self_attn/Constant_12_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Cast_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/decoder/layers.3/self_attn/Cast_2\"](%/transformer/decoder/layers.3/self_attn/Slice_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/transformer/decoder/layers.3/self_attn/Sqrt\"](%/transformer/decoder/layers.3/self_attn/Cast_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Constant_13_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant_13\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Div_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/layers.3/self_attn/Div_1\"](%/transformer/decoder/layers.3/self_attn/Constant_13_output_0, %/transformer/decoder/layers.3/self_attn/Sqrt_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Cast_3_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name=\"/transformer/decoder/layers.3/self_attn/Cast_3\"](%/transformer/decoder/layers.3/self_attn/Div_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Transpose_5_output_0 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/transformer/decoder/layers.3/self_attn/Transpose_5\"](%/transformer/decoder/layers.3/self_attn/Reshape_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/transformer/decoder/layers.3/self_attn/Sqrt_1\"](%/transformer/decoder/layers.3/self_attn/Cast_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Mul_1_output_0 : Float(*, *, *, *, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.3/self_attn/Mul_1\"](%/transformer/decoder/layers.3/self_attn/Reshape_3_output_0, %/transformer/decoder/layers.3/self_attn/Sqrt_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name=\"/transformer/decoder/layers.3/self_attn/Sqrt_2\"](%/transformer/decoder/layers.3/self_attn/Cast_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Mul_2_output_0 : Float(*, *, *, *, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.3/self_attn/Mul_2\"](%/transformer/decoder/layers.3/self_attn/Transpose_5_output_0, %/transformer/decoder/layers.3/self_attn/Sqrt_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/MatMul_3_output_0 : Float(*, *, *, *, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.3/self_attn/MatMul_3\"](%/transformer/decoder/layers.3/self_attn/Mul_1_output_0, %/transformer/decoder/layers.3/self_attn/Mul_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Softmax_output_0 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/transformer/decoder/layers.3/self_attn/Softmax\"](%/transformer/decoder/layers.3/self_attn/MatMul_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/MatMul_4_output_0 : Float(*, *, *, *, strides=[256, 32, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.3/self_attn/MatMul_4\"](%/transformer/decoder/layers.3/self_attn/Softmax_output_0, %/transformer/decoder/layers.3/self_attn/Reshape_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n  %/transformer/decoder/layers.3/self_attn/Transpose_6_output_0 : Float(*, *, *, *, strides=[256, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[2, 0, 1, 3], onnx_name=\"/transformer/decoder/layers.3/self_attn/Transpose_6\"](%/transformer/decoder/layers.3/self_attn/MatMul_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %/transformer/decoder/layers.3/self_attn/Mul_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.3/self_attn/Mul_3\"](%/transformer/decoder/layers.3/self_attn/Gather_1_output_0, %/transformer/decoder/layers.3/self_attn/Gather_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %onnx::Unsqueeze_4010 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_18\"](%/transformer/decoder/layers.3/self_attn/Mul_3_output_0, %onnx::Unsqueeze_4010), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_4012 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_19\"](%/transformer/decoder/layers.3/self_attn/Gather_2_output_0, %onnx::Unsqueeze_4012), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.3/self_attn/Concat_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Concat_6\"](%/transformer/decoder/layers.3/self_attn/Unsqueeze_18_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_19_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %/transformer/decoder/layers.3/self_attn/Reshape_6_output_0 : Float(*, *, strides=[256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Reshape_6\"](%/transformer/decoder/layers.3/self_attn/Transpose_6_output_0, %/transformer/decoder/layers.3/self_attn/Concat_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n  %/transformer/decoder/layers.3/self_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/transformer/decoder/layers.3/self_attn/Gemm\"](%/transformer/decoder/layers.3/self_attn/Reshape_6_output_0, %transformer.decoder.layers.3.self_attn.out_proj.weight, %transformer.decoder.layers.3.self_attn.out_proj.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6417:0\n  %/transformer/decoder/layers.3/self_attn/Shape_7_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/self_attn/Shape_7\"](%/transformer/decoder/layers.3/self_attn/Gemm_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.3/self_attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/self_attn/Constant_14\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.3/self_attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Gather_6\"](%/transformer/decoder/layers.3/self_attn/Shape_7_output_0, %/transformer/decoder/layers.3/self_attn/Constant_14_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %onnx::Unsqueeze_4020 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_20\"](%/transformer/decoder/layers.3/self_attn/Gather_output_0, %onnx::Unsqueeze_4020), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_4022 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_21\"](%/transformer/decoder/layers.3/self_attn/Gather_1_output_0, %onnx::Unsqueeze_4022), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %onnx::Unsqueeze_4024 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/self_attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/self_attn/Unsqueeze_22\"](%/transformer/decoder/layers.3/self_attn/Gather_6_output_0, %onnx::Unsqueeze_4024), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn\n  %/transformer/decoder/layers.3/self_attn/Concat_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Concat_7\"](%/transformer/decoder/layers.3/self_attn/Unsqueeze_20_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_21_output_0, %/transformer/decoder/layers.3/self_attn/Unsqueeze_22_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.3/self_attn/Reshape_7_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/self_attn/Reshape_7\"](%/transformer/decoder/layers.3/self_attn/Gemm_output_0, %/transformer/decoder/layers.3/self_attn/Concat_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n  %/transformer/decoder/layers.3/self_attn/Transpose_7_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/transformer/decoder/layers.3/self_attn/Transpose_7\"](%/transformer/decoder/layers.3/self_attn/Reshape_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1395:0\n  %/transformer/decoder/layers.3/Add_1_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/Add_1\"](%/transformer/decoder/layers.2/norm3/LayerNormalization_output_0, %/transformer/decoder/layers.3/self_attn/Transpose_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:514:0\n  %/transformer/decoder/layers.3/norm1/LayerNormalization_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/transformer/decoder/layers.3/norm1/LayerNormalization\"](%/transformer/decoder/layers.3/Add_1_output_0, %transformer.decoder.layers.3.norm1.weight, %transformer.decoder.layers.3.norm1.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/transformer/decoder/layers.3/Add_2_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/Add_2\"](%/transformer/decoder/layers.3/norm1/LayerNormalization_output_0, %/transformer/decoder/Mul_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:479:0\n  %/transformer/decoder/layers.3/cross_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Shape\"](%/transformer/decoder/layers.3/Add_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:112:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:112:0\n  %/transformer/decoder/layers.3/cross_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Gather\"](%/transformer/decoder/layers.3/cross_attn/Shape_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:112:0\n  %/transformer/decoder/layers.3/cross_attn/value_proj/MatMul_output_0 : Float(1, 1296, 256, strides=[331776, 256, 1], device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.3/cross_attn/value_proj/MatMul\"](%/transformer/Concat_1_output_0, %onnx::MatMul_5044), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::value_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.3/cross_attn/value_proj/Add_output_0 : Float(1, 1296, 256, strides=[331776, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/cross_attn/value_proj/Add\"](%transformer.decoder.layers.3.cross_attn.value_proj.bias, %/transformer/decoder/layers.3/cross_attn/value_proj/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::value_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.3/cross_attn/sampling_offsets/MatMul_output_0 : Float(*, *, 64, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.3/cross_attn/sampling_offsets/MatMul\"](%/transformer/decoder/layers.3/Add_2_output_0, %onnx::MatMul_5045), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::sampling_offsets # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.3/cross_attn/sampling_offsets/Add_output_0 : Float(*, *, 64, strides=[19200, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/cross_attn/sampling_offsets/Add\"](%transformer.decoder.layers.3.cross_attn.sampling_offsets.bias, %/transformer/decoder/layers.3/cross_attn/sampling_offsets/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::sampling_offsets # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_4043 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/cross_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Unsqueeze\"](%/transformer/decoder/layers.3/cross_attn/Gather_output_0, %onnx::Unsqueeze_4043), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.3/cross_attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.3/cross_attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.3/cross_attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.3/cross_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.3/cross_attn/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Concat\"](%/transformer/decoder/layers.3/cross_attn/Constant_2_output_0, %/transformer/decoder/layers.3/cross_attn/Unsqueeze_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_3_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_4_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_5_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:120:0\n  %/transformer/decoder/layers.3/cross_attn/Reshape_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Reshape\"](%/transformer/decoder/layers.3/cross_attn/sampling_offsets/Add_output_0, %/transformer/decoder/layers.3/cross_attn/Concat_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:120:0\n  %/transformer/decoder/layers.3/cross_attn/attention_weights/MatMul_output_0 : Float(*, *, 32, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.3/cross_attn/attention_weights/MatMul\"](%/transformer/decoder/layers.3/Add_2_output_0, %onnx::MatMul_5051), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::attention_weights # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.3/cross_attn/attention_weights/Add_output_0 : Float(*, *, 32, strides=[9600, 32, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/cross_attn/attention_weights/Add\"](%transformer.decoder.layers.3.cross_attn.attention_weights.bias, %/transformer/decoder/layers.3/cross_attn/attention_weights/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::attention_weights # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_7\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_4060 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/cross_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Unsqueeze_1\"](%/transformer/decoder/layers.3/cross_attn/Gather_output_0, %onnx::Unsqueeze_4060), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.3/cross_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_8\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.3/cross_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_9\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.3/cross_attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Concat_1\"](%/transformer/decoder/layers.3/cross_attn/Constant_7_output_0, %/transformer/decoder/layers.3/cross_attn/Unsqueeze_1_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_8_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_9_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:121:0\n  %/transformer/decoder/layers.3/cross_attn/Reshape_1_output_0 : Float(1, *, 16, 2, strides=[9600, 32, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Reshape_1\"](%/transformer/decoder/layers.3/cross_attn/attention_weights/Add_output_0, %/transformer/decoder/layers.3/cross_attn/Concat_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:121:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_10\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.3/cross_attn/Div_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Div\"](%/transformer/decoder/layers.3/cross_attn/Reshape_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_10_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.3/cross_attn/Mul_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Mul\"](%/transformer/decoder/layers.3/cross_attn/Div_output_0, %/transformer/decoder/layers.0/cross_attn/Slice_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_11_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_11\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.3/cross_attn/Mul_1_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Mul_1\"](%/transformer/decoder/layers.3/cross_attn/Mul_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_11_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:130:0\n  %/transformer/decoder/layers.3/cross_attn/Add_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Add\"](%/transformer/decoder/layers.0/cross_attn/Slice_output_0, %/transformer/decoder/layers.3/cross_attn/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:129:0\n  %/transformer/decoder/layers.3/cross_attn/Softmax_output_0 : Float(1, *, 16, 2, strides=[9600, 32, 2, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Softmax\"](%/transformer/decoder/layers.3/cross_attn/Reshape_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2140:0\n  %/transformer/decoder/layers.3/cross_attn/Transpose_output_0 : Float(1, 256, 1296, strides=[331776, 1296, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/transformer/decoder/layers.3/cross_attn/Transpose\"](%/transformer/decoder/layers.3/cross_attn/value_proj/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:136:0\n  %/transformer/decoder/layers.3/cross_attn/Reshape_2_output_0 : Float(1, 16, 16, 1296, strides=[331776, 20736, 1296, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Reshape_2\"](%/transformer/decoder/layers.3/cross_attn/Transpose_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/modules/ms_deform_attn.py:136:0\n  %/transformer/decoder/layers.3/cross_attn/Shape_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Shape_1\"](%/transformer/decoder/layers.3/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_12_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_12\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.3/cross_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Gather_1\"](%/transformer/decoder/layers.3/cross_attn/Shape_1_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_12_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.3/cross_attn/Shape_2_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Shape_2\"](%/transformer/decoder/layers.3/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_13_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_13\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.3/cross_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Gather_2\"](%/transformer/decoder/layers.3/cross_attn/Shape_2_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_13_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.3/cross_attn/Shape_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Shape_3\"](%/transformer/decoder/layers.3/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_14\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.3/cross_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Gather_3\"](%/transformer/decoder/layers.3/cross_attn/Shape_3_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_14_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.3/cross_attn/Shape_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Shape_4\"](%/transformer/decoder/layers.3/cross_attn/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={4}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_15\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.3/cross_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Gather_4\"](%/transformer/decoder/layers.3/cross_attn/Shape_4_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_15_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:32:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_16\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Split_output_0 : Long(1, 2, strides=[2, 1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Split\"](%/transformer/Constant_4_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_16_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_17\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Squeeze_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Squeeze\"](%/transformer/decoder/layers.3/cross_attn/Split_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_17_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 1  1 [ CPULongType{2} ], onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_18\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Split_1_output_0 : Long(1, strides=[1], device=cpu), %/transformer/decoder/layers.3/cross_attn/Split_1_output_1 : Long(1, strides=[1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Split_1\"](%/transformer/decoder/layers.3/cross_attn/Squeeze_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_18_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_19\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Squeeze_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Squeeze_1\"](%/transformer/decoder/layers.3/cross_attn/Split_1_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_19_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_20\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Squeeze_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Squeeze_2\"](%/transformer/decoder/layers.3/cross_attn/Split_1_output_1, %/transformer/decoder/layers.3/cross_attn/Constant_20_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Mul_2\"](%/transformer/decoder/layers.3/cross_attn/Squeeze_1_output_0, %/transformer/decoder/layers.3/cross_attn/Squeeze_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:33:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_21\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.3/cross_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Unsqueeze_2\"](%/transformer/decoder/layers.3/cross_attn/Mul_2_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_21_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_22\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_23\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_24\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.3/cross_attn/Add_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Add_1\"](%/transformer/decoder/layers.3/cross_attn/Constant_24_output_0, %/transformer/decoder/layers.3/cross_attn/Unsqueeze_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.3/cross_attn/Slice_output_0 : Float(1, 16, 16, *, strides=[331776, 20736, 1296, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Slice\"](%/transformer/decoder/layers.3/cross_attn/Reshape_2_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_22_output_0, %/transformer/decoder/layers.3/cross_attn/Add_1_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_23_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1028:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_25_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_25\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.3/cross_attn/Mul_3_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Mul_3\"](%/transformer/decoder/layers.3/cross_attn/Add_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_25_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_26_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_26\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.3/cross_attn/Sub_output_0 : Float(1, *, 16, 1, 2, 2, strides=[19200, 64, 4, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Sub\"](%/transformer/decoder/layers.3/cross_attn/Mul_3_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_26_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:34:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_27\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Split_2_output_0 : Long(1, 2, strides=[2, 1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Split_2\"](%/transformer/Constant_4_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_27_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_28\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Squeeze_3_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Squeeze_3\"](%/transformer/decoder/layers.3/cross_attn/Split_2_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_28_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_29_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 1  1 [ CPULongType{2} ], onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_29\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Split_3_output_0 : Long(1, strides=[1], device=cpu), %/transformer/decoder/layers.3/cross_attn/Split_3_output_1 : Long(1, strides=[1], device=cpu) = onnx::Split[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Split_3\"](%/transformer/decoder/layers.3/cross_attn/Squeeze_3_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_29_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_30\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Squeeze_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Squeeze_4\"](%/transformer/decoder/layers.3/cross_attn/Split_3_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_30_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_31\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Squeeze_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Squeeze_5\"](%/transformer/decoder/layers.3/cross_attn/Split_3_output_1, %/transformer/decoder/layers.3/cross_attn/Constant_31_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1164:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_32_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_32\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %/transformer/decoder/layers.3/cross_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Mul_4\"](%/transformer/decoder/layers.3/cross_attn/Constant_32_output_0, %/transformer/decoder/layers.3/cross_attn/Gather_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %onnx::Unsqueeze_4127 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/cross_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Unsqueeze_3\"](%/transformer/decoder/layers.3/cross_attn/Mul_4_output_0, %onnx::Unsqueeze_4127), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.3/cross_attn/Constant_33_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_33\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_4131 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/cross_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Unsqueeze_4\"](%/transformer/decoder/layers.3/cross_attn/Squeeze_4_output_0, %onnx::Unsqueeze_4131), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_4133 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/cross_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Unsqueeze_5\"](%/transformer/decoder/layers.3/cross_attn/Squeeze_5_output_0, %onnx::Unsqueeze_4133), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.3/cross_attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Concat_2\"](%/transformer/decoder/layers.3/cross_attn/Unsqueeze_3_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_33_output_0, %/transformer/decoder/layers.3/cross_attn/Unsqueeze_4_output_0, %/transformer/decoder/layers.3/cross_attn/Unsqueeze_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %/transformer/decoder/layers.3/cross_attn/Reshape_3_output_0 : Float(*, *, *, *, strides=[20736, 1296, 36, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Reshape_3\"](%/transformer/decoder/layers.3/cross_attn/Slice_output_0, %/transformer/decoder/layers.3/cross_attn/Concat_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:38:0\n  %/transformer/decoder/layers.3/cross_attn/Gather_5_output_0 : Float(1, *, 16, 2, 2, strides=[19200, 64, 4, 2, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=3, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Gather_5\"](%/transformer/decoder/layers.3/cross_attn/Sub_output_0, %/backbone/backbone.0/encoder/encoder/embeddings/Constant_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.3/cross_attn/Transpose_1_output_0 : Float(1, 16, *, 2, 2, strides=[19200, 4, 64, 2, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name=\"/transformer/decoder/layers.3/cross_attn/Transpose_1\"](%/transformer/decoder/layers.3/cross_attn/Gather_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.3/cross_attn/Shape_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Shape_5\"](%/transformer/decoder/layers.3/cross_attn/Transpose_1_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_34\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_35\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_36\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.3/cross_attn/Slice_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Slice_1\"](%/transformer/decoder/layers.3/cross_attn/Shape_5_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_35_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_36_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_34_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_37\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_38\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_39_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={5}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_39\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.3/cross_attn/Slice_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Slice_2\"](%/transformer/decoder/layers.3/cross_attn/Shape_5_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_38_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_39_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_37_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_40\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.3/cross_attn/Concat_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Concat_3\"](%/transformer/decoder/layers.3/cross_attn/Slice_1_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_40_output_0, %/transformer/decoder/layers.3/cross_attn/Slice_2_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.3/cross_attn/Reshape_4_output_0 : Float(*, *, *, *, strides=[4, 64, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Reshape_4\"](%/transformer/decoder/layers.3/cross_attn/Transpose_1_output_0, %/transformer/decoder/layers.3/cross_attn/Concat_3_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:40:0\n  %/transformer/decoder/layers.3/cross_attn/GridSample_output_0 : Float(*, *, *, *, strides=[9600, 600, 2, 1], requires_grad=1, device=cpu) = onnx::GridSample[align_corners=0, mode=\"bilinear\", padding_mode=\"zeros\", onnx_name=\"/transformer/decoder/layers.3/cross_attn/GridSample\"](%/transformer/decoder/layers.3/cross_attn/Reshape_3_output_0, %/transformer/decoder/layers.3/cross_attn/Reshape_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5023:0\n  %/transformer/decoder/layers.3/cross_attn/Transpose_2_output_0 : Float(1, 16, *, 2, strides=[9600, 2, 32, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/transformer/decoder/layers.3/cross_attn/Transpose_2\"](%/transformer/decoder/layers.3/cross_attn/Softmax_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %/transformer/decoder/layers.3/cross_attn/Mul_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Mul_5\"](%/transformer/decoder/layers.3/cross_attn/Gather_3_output_0, %/transformer/decoder/layers.3/cross_attn/Gather_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %onnx::Unsqueeze_4154 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/cross_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Unsqueeze_6\"](%/transformer/decoder/layers.3/cross_attn/Mul_4_output_0, %onnx::Unsqueeze_4154), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.3/cross_attn/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_41\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_4158 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/cross_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Unsqueeze_7\"](%/transformer/decoder/layers.3/cross_attn/Gather_1_output_0, %onnx::Unsqueeze_4158), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_4160 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/cross_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Unsqueeze_8\"](%/transformer/decoder/layers.3/cross_attn/Mul_5_output_0, %onnx::Unsqueeze_4160), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.3/cross_attn/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Concat_4\"](%/transformer/decoder/layers.3/cross_attn/Unsqueeze_6_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_41_output_0, %/transformer/decoder/layers.3/cross_attn/Unsqueeze_7_output_0, %/transformer/decoder/layers.3/cross_attn/Unsqueeze_8_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %/transformer/decoder/layers.3/cross_attn/Reshape_5_output_0 : Float(*, *, *, *, strides=[2, 9600, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Reshape_5\"](%/transformer/decoder/layers.3/cross_attn/Transpose_2_output_0, %/transformer/decoder/layers.3/cross_attn/Concat_4_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:46:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_42\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.3/cross_attn/Unsqueeze_9_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Unsqueeze_9\"](%/transformer/decoder/layers.3/cross_attn/GridSample_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_42_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.3/cross_attn/Concat_5_output_0 : Float(*, *, *, 1, *, strides=[9600, 600, 2, 2, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=-2, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Concat_5\"](%/transformer/decoder/layers.3/cross_attn/Unsqueeze_9_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.3/cross_attn/Shape_6_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Shape_6\"](%/transformer/decoder/layers.3/cross_attn/Concat_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_43_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_43\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_44_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_44\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_45_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_45\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.3/cross_attn/Slice_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Slice_3\"](%/transformer/decoder/layers.3/cross_attn/Shape_6_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_44_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_45_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_43_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_46\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.3/cross_attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Concat_6\"](%/transformer/decoder/layers.3/cross_attn/Slice_3_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_46_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.3/cross_attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[9600, 600, 2, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Reshape_6\"](%/transformer/decoder/layers.3/cross_attn/Concat_5_output_0, %/transformer/decoder/layers.3/cross_attn/Concat_6_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:48:0\n  %/transformer/decoder/layers.3/cross_attn/Mul_6_output_0 : Float(*, *, *, *, strides=[9600, 600, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Mul_6\"](%/transformer/decoder/layers.3/cross_attn/Reshape_6_output_0, %/transformer/decoder/layers.3/cross_attn/Reshape_5_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.3/cross_attn/ReduceSum_output_0 : Float(*, *, *, strides=[4800, 300, 1], requires_grad=1, device=cpu) = onnx::ReduceSum[keepdims=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/ReduceSum\"](%/transformer/decoder/layers.3/cross_attn/Mul_6_output_0, %onnx::ReduceSum_3159), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_47_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_47\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.3/cross_attn/Mul_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Mul_7\"](%/transformer/decoder/layers.3/cross_attn/Gather_2_output_0, %/transformer/decoder/layers.3/cross_attn/Constant_47_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.3/cross_attn/Constant_48_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Constant_48\"](), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_4181 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/cross_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Unsqueeze_10\"](%/transformer/decoder/layers.3/cross_attn/Mul_7_output_0, %onnx::Unsqueeze_4181), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %onnx::Unsqueeze_4183 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %/transformer/decoder/layers.3/cross_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/transformer/decoder/layers.3/cross_attn/Unsqueeze_11\"](%/transformer/decoder/layers.3/cross_attn/Gather_1_output_0, %onnx::Unsqueeze_4183), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn\n  %/transformer/decoder/layers.3/cross_attn/Concat_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Concat_7\"](%/transformer/decoder/layers.3/cross_attn/Constant_48_output_0, %/transformer/decoder/layers.3/cross_attn/Unsqueeze_10_output_0, %/transformer/decoder/layers.3/cross_attn/Unsqueeze_11_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.3/cross_attn/Reshape_7_output_0 : Float(*, *, *, strides=[76800, 300, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/transformer/decoder/layers.3/cross_attn/Reshape_7\"](%/transformer/decoder/layers.3/cross_attn/ReduceSum_output_0, %/transformer/decoder/layers.3/cross_attn/Concat_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:49:0\n  %/transformer/decoder/layers.3/cross_attn/Transpose_3_output_0 : Float(*, *, *, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/transformer/decoder/layers.3/cross_attn/Transpose_3\"](%/transformer/decoder/layers.3/cross_attn/Reshape_7_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn # /usr/local/lib/python3.11/dist-packages/rfdetr/models/ops/functions/ms_deform_attn_func.py:50:0\n  %/transformer/decoder/layers.3/cross_attn/output_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.3/cross_attn/output_proj/MatMul\"](%/transformer/decoder/layers.3/cross_attn/Transpose_3_output_0, %onnx::MatMul_5058), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::output_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.3/cross_attn/output_proj/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/cross_attn/output_proj/Add\"](%transformer.decoder.layers.3.cross_attn.output_proj.bias, %/transformer/decoder/layers.3/cross_attn/output_proj/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/rfdetr.models.ops.modules.ms_deform_attn.MSDeformAttn::cross_attn/torch.nn.modules.linear.Linear::output_proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.3/Add_3_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/Add_3\"](%/transformer/decoder/layers.3/norm1/LayerNormalization_output_0, %/transformer/decoder/layers.3/cross_attn/output_proj/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:528:0\n  %/transformer/decoder/layers.3/norm2/LayerNormalization_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/transformer/decoder/layers.3/norm2/LayerNormalization\"](%/transformer/decoder/layers.3/Add_3_output_0, %transformer.decoder.layers.3.norm2.weight, %transformer.decoder.layers.3.norm2.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/transformer/decoder/layers.3/linear1/MatMul_output_0 : Float(*, *, 2048, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.3/linear1/MatMul\"](%/transformer/decoder/layers.3/norm2/LayerNormalization_output_0, %onnx::MatMul_5059), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.linear.Linear::linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.3/linear1/Add_output_0 : Float(*, *, 2048, strides=[614400, 2048, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/linear1/Add\"](%transformer.decoder.layers.3.linear1.bias, %/transformer/decoder/layers.3/linear1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.linear.Linear::linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.3/Relu_output_0 : Float(*, *, 2048, strides=[614400, 2048, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/transformer/decoder/layers.3/Relu\"](%/transformer/decoder/layers.3/linear1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n  %/transformer/decoder/layers.3/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/transformer/decoder/layers.3/linear2/MatMul\"](%/transformer/decoder/layers.3/Relu_output_0, %onnx::MatMul_5060), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.linear.Linear::linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.3/linear2/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/linear2/Add\"](%transformer.decoder.layers.3.linear2.bias, %/transformer/decoder/layers.3/linear2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.linear.Linear::linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/transformer/decoder/layers.3/Add_4_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/transformer/decoder/layers.3/Add_4\"](%/transformer/decoder/layers.3/norm2/LayerNormalization_output_0, %/transformer/decoder/layers.3/linear2/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3 # /usr/local/lib/python3.11/dist-packages/rfdetr/models/transformer.py:531:0\n  %/transformer/decoder/layers.3/norm3/LayerNormalization_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/transformer/decoder/layers.3/norm3/LayerNormalization\"](%/transformer/decoder/layers.3/Add_4_output_0, %transformer.decoder.layers.3.norm3.weight, %transformer.decoder.layers.3.norm3.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/rfdetr.models.transformer.TransformerDecoderLayer::layers.3/torch.nn.modules.normalization.LayerNorm::norm3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/transformer/decoder/norm/LayerNormalization_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/transformer/decoder/norm/LayerNormalization\"](%/transformer/decoder/layers.3/norm3/LayerNormalization_output_0, %transformer.decoder.norm.weight, %transformer.decoder.norm.bias), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.transformer.Transformer::transformer/rfdetr.models.transformer.TransformerDecoder::decoder/torch.nn.modules.normalization.LayerNorm::norm # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n  %/bbox_embed/layers.0/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/bbox_embed/layers.0/MatMul\"](%/transformer/decoder/norm/LayerNormalization_output_0, %onnx::MatMul_5061), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.lwdetr.MLP::bbox_embed/torch.nn.modules.linear.Linear::layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/bbox_embed/layers.0/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/bbox_embed/layers.0/Add\"](%bbox_embed.layers.0.bias, %/bbox_embed/layers.0/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.lwdetr.MLP::bbox_embed/torch.nn.modules.linear.Linear::layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/bbox_embed/Relu_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/bbox_embed/Relu\"](%/bbox_embed/layers.0/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.lwdetr.MLP::bbox_embed # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n  %/bbox_embed/layers.1/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name=\"/bbox_embed/layers.1/MatMul\"](%/bbox_embed/Relu_output_0, %onnx::MatMul_5062), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.lwdetr.MLP::bbox_embed/torch.nn.modules.linear.Linear::layers.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/bbox_embed/layers.1/Add_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/bbox_embed/layers.1/Add\"](%bbox_embed.layers.1.bias, %/bbox_embed/layers.1/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.lwdetr.MLP::bbox_embed/torch.nn.modules.linear.Linear::layers.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/bbox_embed/Relu_1_output_0 : Float(*, *, 256, strides=[76800, 256, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/bbox_embed/Relu_1\"](%/bbox_embed/layers.1/Add_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.lwdetr.MLP::bbox_embed # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n  %/bbox_embed/layers.2/MatMul_output_0 : Float(*, *, 4, device=cpu) = onnx::MatMul[onnx_name=\"/bbox_embed/layers.2/MatMul\"](%/bbox_embed/Relu_1_output_0, %onnx::MatMul_5063), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.lwdetr.MLP::bbox_embed/torch.nn.modules.linear.Linear::layers.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/bbox_embed/layers.2/Add_output_0 : Float(*, *, 4, strides=[1200, 4, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/bbox_embed/layers.2/Add\"](%bbox_embed.layers.2.bias, %/bbox_embed/layers.2/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/rfdetr.models.lwdetr.MLP::bbox_embed/torch.nn.modules.linear.Linear::layers.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Constant_1_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_1\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_2\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_3\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Slice_output_0 : Float(*, *, 2, strides=[1200, 4, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/Slice\"](%/bbox_embed/layers.2/Add_output_0, %/Constant_1_output_0, %/Constant_2_output_0, %/Constant_output_0, %/Constant_3_output_0), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_4\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_5\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/Constant_6\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_7\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Slice_1_output_0 : Float(1, *, 2, strides=[1200, 4, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/Slice_1\"](%/transformer/Concat_11_output_0, %/Constant_5_output_0, %/Constant_6_output_0, %/Constant_4_output_0, %/Constant_7_output_0), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Mul_output_0 : Float(*, *, 2, strides=[600, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/Mul\"](%/Slice_output_0, %/Slice_1_output_0), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_8\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_9\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_10\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_11\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Slice_2_output_0 : Float(1, *, 2, strides=[1200, 4, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/Slice_2\"](%/transformer/Concat_11_output_0, %/Constant_9_output_0, %/Constant_10_output_0, %/Constant_8_output_0, %/Constant_11_output_0), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Add_output_0 : Float(*, *, 2, strides=[600, 2, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add\"](%/Mul_output_0, %/Slice_2_output_0), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:211:0\n  %/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_12\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:212:0\n  %/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_13\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:212:0\n  %/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/Constant_14\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:212:0\n  %/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_15\"](), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:212:0\n  %/Slice_3_output_0 : Float(*, *, 2, strides=[1200, 4, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/Slice_3\"](%/bbox_embed/layers.2/Add_output_0, %/Constant_13_output_0, %/Constant_14_output_0, %/Constant_12_output_0, %/Constant_15_output_0), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:212:0\n  %/Exp_output_0 : Float(*, *, 2, strides=[600, 2, 1], requires_grad=1, device=cpu) = onnx::Exp[onnx_name=\"/Exp\"](%/Slice_3_output_0), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:212:0\n  %/Mul_1_output_0 : Float(*, *, 2, strides=[600, 2, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/Mul_1\"](%/Exp_output_0, %/Slice_1_output_0), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:212:0\n  %dets : Float(*, *, 4, strides=[1200, 4, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat\"](%/Add_output_0, %/Mul_1_output_0), scope: rfdetr.models.lwdetr.LWDETR:: # /usr/local/lib/python3.11/dist-packages/rfdetr/models/lwdetr.py:213:0\n  %/class_embed/MatMul_output_0 : Float(*, *, 13, device=cpu) = onnx::MatMul[onnx_name=\"/class_embed/MatMul\"](%/transformer/decoder/norm/LayerNormalization_output_0, %onnx::MatMul_5080), scope: rfdetr.models.lwdetr.LWDETR::/torch.nn.modules.linear.Linear::class_embed # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  %labels : Float(*, *, 13, strides=[3900, 13, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/class_embed/Add\"](%class_embed.bias, %/class_embed/MatMul_output_0), scope: rfdetr.models.lwdetr.LWDETR::/torch.nn.modules.linear.Linear::class_embed # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n  return (%dets, %labels)\n\n\nSuccessfully exported ONNX model: output/inference_model.onnx\nSuccessfully exported ONNX model to: output/inference_model.onnx\nONNX export completed successfully\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Uploading the onnx model","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/working","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-24T18:22:36.275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:48:38.508828Z","iopub.execute_input":"2025-09-26T08:48:38.509549Z","iopub.status.idle":"2025-09-26T08:48:38.517206Z","shell.execute_reply.started":"2025-09-26T08:48:38.509523Z","shell.execute_reply":"2025-09-26T08:48:38.516622Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\napi = HfApi(token=user_secrets.get_secret(\"HF_TOKEN\"))\napi.upload_folder(\n    folder_path=\"/kaggle/working/output\",\n    repo_id=\"hasnatz/v-safe-rf-detr\",\n    repo_type=\"model\",\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T19:08:52.241887Z","iopub.execute_input":"2025-09-24T19:08:52.242608Z","iopub.status.idle":"2025-09-24T19:08:56.165997Z","shell.execute_reply.started":"2025-09-24T19:08:52.242584Z","shell.execute_reply":"2025-09-24T19:08:56.165476Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Uploading...:   0%|          | 0.00/128M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71f98d6417054e71a838b92a891e46fb"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/hasnatz/v-safe-rf-detr/commit/1a1a8a7caedcd53d891e86bdd42a1143481e9a2d', commit_message='Upload folder using huggingface_hub', commit_description='', oid='1a1a8a7caedcd53d891e86bdd42a1143481e9a2d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/hasnatz/v-safe-rf-detr', endpoint='https://huggingface.co', repo_type='model', repo_id='hasnatz/v-safe-rf-detr'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"### Uploading the checkpoint (optional)","metadata":{}},{"cell_type":"code","source":"!cp /kaggle/input/rf_detr_medium_training/checkpoint_best_total.pth /kaggle/working/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:47:11.433393Z","iopub.execute_input":"2025-09-26T08:47:11.434299Z","iopub.status.idle":"2025-09-26T08:47:13.230878Z","shell.execute_reply.started":"2025-09-26T08:47:11.434263Z","shell.execute_reply":"2025-09-26T08:47:13.229831Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!mv /kaggle/working/checkpoint_best_total.pth /kaggle/working/inference_model.pth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:47:58.080262Z","iopub.execute_input":"2025-09-26T08:47:58.081024Z","iopub.status.idle":"2025-09-26T08:47:58.204162Z","shell.execute_reply.started":"2025-09-26T08:47:58.080988Z","shell.execute_reply":"2025-09-26T08:47:58.203102Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\napi = HfApi(token=user_secrets.get_secret(\"HF_TOKEN\")) #don't forget to use you api token\napi.upload_folder(\n    folder_path=\"/kaggle/working\",\n    repo_id=\"hasnatz/v-safe-rf-detr\", #your repo. id\n    repo_type=\"model\",\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:48:42.201170Z","iopub.execute_input":"2025-09-26T08:48:42.201460Z","iopub.status.idle":"2025-09-26T08:48:47.478809Z","shell.execute_reply.started":"2025-09-26T08:48:42.201437Z","shell.execute_reply":"2025-09-26T08:48:47.478194Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Uploading...:   0%|          | 0.00/134M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47db5ed61da3425d940c011f9aa43da3"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/hasnatz/v-safe-rf-detr/commit/8c2ca95396d3e7b6ee02b16e0af78e80dd1f22a6', commit_message='Upload folder using huggingface_hub', commit_description='', oid='8c2ca95396d3e7b6ee02b16e0af78e80dd1f22a6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/hasnatz/v-safe-rf-detr', endpoint='https://huggingface.co', repo_type='model', repo_id='hasnatz/v-safe-rf-detr'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}